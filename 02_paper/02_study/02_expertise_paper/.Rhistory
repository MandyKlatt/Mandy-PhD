# filter
df_aoi %>%
filter(TOI == "Letter_search") %>%
dplyr::select (
TOI,
Group,
Participant,
Duration_of_interval,
starts_with("Total_duration_of_fixations"),
starts_with("Number_of_fixations")
) -> df_letter
View(df_letter)
# filter
df_aoi %>%
filter(TOI == "Letter_search") %>%
dplyr::select (
TOI,
Group,
Participant,
Duration_of_interval) -> df_letter
# filter
df_aoi %>%
filter(TOI == "Letter_search") %>%
dplyr::select (
TOI,
Group,
Participant,
Duration_of_interval) %>%
mutate(Duration_of_interval_sec =
round(Duration_of_interval/1000, digits = 2)
) -> df_letter
View(df_letter)
# N, M, SD, min & max
letter.table <-
df_letter %>%
group_by(Group) %>%
summarise(
N = n(),
"M" = round(mean(Duration_of_interval_sec), digits = 2),
"SD" = round(sd(Duration_of_interval_sec), digits = 2),
"Min" = round(min(Duration_of_interval_sec), digits = 2),
"Max" = round(max(Duration_of_interval_sec), digits = 2)
)
knitr::kable(letter.table,
caption = "N, M, SD, min & max letter search in seconds")
# LETTER SEARCH
# t-test for expertise differences
t.test(
x = df_letter$Duration_of_interval_sec[df_letter$Group == "Expert"],
y = df_letter$Duration_of_interval_sec[df_letter$Group == "Novice"],
var.equal = TRUE
)
# NUMBER OF FIXATIONS PER MINUTE (micro-teaching unit)
# effect size for expertise differences
d_number_all <- CohenD(
x = df_letter$Duration_of_interval_sec[df_letter$Group == "Expert"],
y = df_letter$Duration_of_interval_sec[df_letter$Group == "Novice"],
na.rm = TRUE
)
round(d_number_letter, 2)
# NUMBER OF FIXATIONS PER MINUTE (micro-teaching unit)
# effect size for expertise differences
d_letter <- CohenD(
x = df_letter$Duration_of_interval_sec[df_letter$Group == "Expert"],
y = df_letter$Duration_of_interval_sec[df_letter$Group == "Novice"],
na.rm = TRUE
)
round(d_letter, 2)
# N, M, SD, min & max
letter.table <-
df_letter %>%
group_by(Group) %>%
summarise(
N = n(),
"M" = round(mean(Duration_of_interval_sec), digits = 2),
"SD" = round(sd(Duration_of_interval_sec), digits = 2),
"Min" = round(min(Duration_of_interval_sec), digits = 2),
"Max" = round(max(Duration_of_interval_sec), digits = 2)
)
knitr::kable(letter.table,
caption = "N, M, SD, min & max letter search in seconds")
# filter
df_aoi %>%
filter(TOI == "Letter_search") %>%
dplyr::select (
TOI,
Group,
Participant,
Duration_of_interval) %>%
mutate(Duration_of_interval_sec =
round(Duration_of_interval/1000, digits = 2)
) -> df_letter
# install.packages("needs")
# suppress "summarize" info.
# if this line is ommitted, each table using the summarize function will be accompanied with a warning from the console
options(dplyr.summarise.inform = FALSE)
library(needs)
needs(tidyverse,
lubridate,
viridis,
grid,
gridExtra,
cowplot,
readxl,
ARTofR,
moments,
ltm,
sjPlot,
kableExtra,
xtable,
DescTools,
formattable,
psych,
apaTables,
rstatix)
# demo data
df_demo <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(!LI06_05 == 201,
!LI06_05 == 223) %>% # exclude participant due to missing eye tracking data
transmute(Participant = LI06_05,
`Teaching Experience` = LI04_01,
)
# average duration, number fixation, GRI (micro-teaching unit)
df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select(
Duration_of_interval,
Participant,
starts_with("Total_duration_of_fixations"),
starts_with("Number_of_fixations"),
starts_with("Average_duration"),
!"Total_duration_of_fixations.Disruptive_Person",
!"Number_of_fixations.Disruptive_Person",
!"Average_duration_of_fixations.Disruptive_Person"
) %>%
rowwise() %>%
transmute(
Participant = Participant,
Duration_of_interval = Duration_of_interval,
Duration_of_interval_min = round(Duration_of_interval/60000, digits = 2),
Sum_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
Sum_average_duration_fixation = sum(c_across(starts_with("Average_duration")), na.rm = TRUE),
Sum_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
Average_duration_mtu = round(Sum_duration_fixation / Sum_number_fixation, digits = 0),
Number_fixation_min_mtu = round(Sum_number_fixation / Duration_of_interval_min, digits = 0),
GRI_mtu = round(Average_duration_mtu / Number_fixation_min_mtu, digits = 2)
) %>%
drop_na() %>%
dplyr::select(Participant,
Number_fixation_min_mtu,
Average_duration_mtu,
GRI_mtu) -> df_aoi_numb_dur
# average duration, number fixation, GRI (AOI student)
df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select (
Participant,
Duration_of_interval,
"Total_duration_of_fixations.Anna",
"Total_duration_of_fixations.Bianca",
"Total_duration_of_fixations.Carl(a)",
"Number_of_fixations.Anna",
"Number_of_fixations.Bianca",
"Number_of_fixations.Carl(a)"
) %>%
rowwise() %>%
transmute(
Participant = Participant,
Duration_of_interval = Duration_of_interval,
Duration_of_interval_min = round(Duration_of_interval/60000, digits = 2),
Stud_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
Stud_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
Stud_number_fixation_min = round(Duration_of_interval_min / Stud_number_fixation, digits = 2),
Average_duration_stud = round(Stud_duration_fixation / Stud_number_fixation, digits = 0),
GRI_stud = round(Average_duration_stud / Stud_number_fixation, digits = 2)
) %>%
dplyr::select(Participant,
Stud_number_fixation_min,
Average_duration_stud,
GRI_stud) -> df_aoi_stud
# average duration, number fixation, GRI (AOI disruptive person)
df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select(Participant,
"Total_duration_of_fixations.Disruptive_Person",
"Number_of_fixations.Disruptive_Person"
) %>%
rowwise() %>%
mutate(
Average_duration_disrup = round(
Total_duration_of_fixations.Disruptive_Person / Number_of_fixations.Disruptive_Person,
digits = 0),
GRI_disrup = round(
Average_duration_disrup / Number_of_fixations.Disruptive_Person, digits = 2)) %>%
dplyr::select(Participant,
Number_of_fixations.Disruptive_Person,
Average_duration_disrup,
GRI_disrup
) -> df_aoi_disrup
df_aoi %>%
filter(TOI %in% c("Chatting_with_neighbour",
"Clicking_pen",
"Drawing",
"Drumming_with_hands",
"Head_on_table",
"Heckling",
"Looking_at_phone",
"Snipping_with_fingers",
"Whispering"
)
) %>%
dplyr::select(Participant,
TOI,
Time_to_first_fixation.Disruptive_Person,
) %>%
rowwise() %>%
drop_na() %>%
group_by(Participant) %>%
filter(!Time_to_first_fixation.Disruptive_Person == 0, # exclude all participants with 0 msec
!Time_to_first_fixation.Disruptive_Person > 30000) %>% # cut-off 30sec
summarise(N = n(),
Time_to_first_fixation.Disruptive_Person_Sum = sum(Time_to_first_fixation.Disruptive_Person/N)
) %>%
mutate(Group = ifelse(Participant < 200, "Novice", "Expert"),
Sum_disruptions = sum(N),
Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person_Sum / 1000,
digits = 2)) -> df_ttff_disrup # changing milliseconds into seconds
# rating scales
df_sri <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
filter(
!ID %in% c(201,
223),
!disruption_appraisal == -100,
!confidence_appraisal == -100,
!disruption_appraisal == -99,
!confidence_appraisal == -99,
!disruption_appraisal == -88,
!confidence_appraisal == -88,
!prevalence_rating == -100,
!prevalence_rating == -99,
!prevalence_rating == -88
) %>%
rename(Participant = ID) %>%
group_by(Participant) %>%
summarise(
Mean_disrupption_appraisal = round(mean(disruption_appraisal), 2),
Mean_confidence_appraisal = round(mean(confidence_appraisal), 2),
Mean_prevalence_rating = round(mean(prevalence_rating), 2)
)%>%
dplyr::select(Participant,
Mean_disrupption_appraisal,
Mean_confidence_appraisal)
# sjt
df_sjt <-
read_excel("./data/SJT.xlsx") %>%
dplyr::select(UI06_05, # Participant
SJT_AL_gek, # Monitoring
SJT_ST_gek, # Managing momentum
SJT_R_gek, # Rules and routines
SJT_KF_gek) %>% # All
filter(!UI06_05 %in% c(201, 223)) %>%  # exclude ID with no eye tracking data
transmute(
Participant = UI06_05,
SJT_Monitoring = round(SJT_AL_gek, 2),
SJT_All = round(SJT_KF_gek, 2),
) %>%
arrange(Participant)
# classroom questionnaire
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
dplyr::select(LI06_05, LM01_01:LM01_08, # classroom management
LP01_01:LP01_08) %>% # non- & paraverbal communication
filter(!LI06_05 %in% c(201, 223)) %>% # exclude ID with no eye tracking data
rename(Participant = LI06_05) %>%
group_by(Participant) %>%
transmute(
Participant = Participant,
"Quest_All" = round(mean(c_across(starts_with(
"L"
)), na.rm = TRUE), 2),
"Quest_classroom_management" = round(mean(c_across(starts_with(
"LM"
)), na.rm = TRUE), 2),
"Quest_non_paraverbal_communication" = round(mean(c_across(starts_with(
"LP"
)), na.rm = TRUE), 2)
)
# create a big data frame with all measures
# put all data frames into list
df_list <- list(df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_aoi_disrup,
df_ttff_disrup,
df_sri,
df_sjt,
df_quest)
# merge all data frames in list
df_merge <-
df_list %>% reduce(full_join, by='Participant') %>%
# filter(`Teaching Experience` > 0) %>%
dplyr::select(Stud_number_fixation_min,
Average_duration_stud,
Number_of_fixations.Disruptive_Person,
Average_duration_disrup,
Disrup_time_fixation_sec,
GRI_mtu,
SJT_All,
SJT_Monitoring,
Quest_All
)
View(df_sri)
# merge all data frames in list
df_merge <-
df_list %>% reduce(full_join, by='Participant') %>%
# filter(`Teaching Experience` > 0) %>%
dplyr::select(GRI_mtu,
SJT_All,
Quest_All,
Mean_disruption_appraisal,
Mean_confidence_appraisal
)
# rating scales
df_sri <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
filter(
!ID %in% c(201,
223),
!disruption_appraisal == -100,
!confidence_appraisal == -100,
!disruption_appraisal == -99,
!confidence_appraisal == -99,
!disruption_appraisal == -88,
!confidence_appraisal == -88,
!prevalence_rating == -100,
!prevalence_rating == -99,
!prevalence_rating == -88
) %>%
rename(Participant = ID) %>%
group_by(Participant) %>%
summarise(
Mean_disrupption_appraisal = round(mean(disruption_appraisal), 2),
Mean_confidence_appraisal = round(mean(confidence_appraisal), 2),
Mean_prevalence_rating = round(mean(prevalence_rating), 2)
)%>%
dplyr::select(Participant,
Mean_disruption_appraisal,
Mean_confidence_appraisal)
# merge all data frames in list
df_merge <-
df_list %>% reduce(full_join, by='Participant') %>%
# filter(`Teaching Experience` > 0) %>%
dplyr::select(GRI_mtu,
SJT_All,
Quest_All,
Mean_disruption_appraisal,
Mean_confidence_appraisal
)
# rating scales
df_sri <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
filter(
!ID %in% c(201,
223),
!disruption_appraisal == -100,
!confidence_appraisal == -100,
!disruption_appraisal == -99,
!confidence_appraisal == -99,
!disruption_appraisal == -88,
!confidence_appraisal == -88,
!prevalence_rating == -100,
!prevalence_rating == -99,
!prevalence_rating == -88
) %>%
rename(Participant = ID) %>%
group_by(Participant) %>%
summarise(
Mean_disrupption_appraisal = round(mean(disruption_appraisal), 2),
Mean_confidence_appraisal = round(mean(confidence_appraisal), 2),
Mean_prevalence_rating = round(mean(prevalence_rating), 2)
)%>%
dplyr::select(Participant,
Mean_disruption_appraisal,
Mean_confidence_appraisal)
# rating scales
df_sri <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
filter(
!ID %in% c(201,
223),
!disruption_appraisal == -100,
!confidence_appraisal == -100,
!disruption_appraisal == -99,
!confidence_appraisal == -99,
!disruption_appraisal == -88,
!confidence_appraisal == -88,
!prevalence_rating == -100,
!prevalence_rating == -99,
!prevalence_rating == -88
) %>%
rename(Participant = ID) %>%
group_by(Participant) %>%
summarise(
Mean_disrupption_appraisal = round(mean(disruption_appraisal), 2),
Mean_confidence_appraisal = round(mean(confidence_appraisal), 2),
Mean_prevalence_rating = round(mean(prevalence_rating), 2)
)%>%
dplyr::select(Participant,
Mean_disruption_appraisal,
Mean_confidence_appraisal)
# rating scales
df_sri <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
filter(
!ID %in% c(201,
223),
!disruption_appraisal == -100,
!confidence_appraisal == -100,
!disruption_appraisal == -99,
!confidence_appraisal == -99,
!disruption_appraisal == -88,
!confidence_appraisal == -88,
!prevalence_rating == -100,
!prevalence_rating == -99,
!prevalence_rating == -88
) %>%
rename(Participant = ID) %>%
group_by(Participant) %>%
summarise(
Mean_disruption_appraisal = round(mean(disruption_appraisal), 2),
Mean_confidence_appraisal = round(mean(confidence_appraisal), 2),
Mean_prevalence_rating = round(mean(prevalence_rating), 2)
)%>%
dplyr::select(Participant,
Mean_disruption_appraisal,
Mean_confidence_appraisal)
# sjt
df_sjt <-
read_excel("./data/SJT.xlsx") %>%
dplyr::select(UI06_05, # Participant
SJT_AL_gek, # Monitoring
SJT_ST_gek, # Managing momentum
SJT_R_gek, # Rules and routines
SJT_KF_gek) %>% # All
filter(!UI06_05 %in% c(201, 223)) %>%  # exclude ID with no eye tracking data
transmute(
Participant = UI06_05,
SJT_Monitoring = round(SJT_AL_gek, 2),
SJT_All = round(SJT_KF_gek, 2),
) %>%
arrange(Participant)
# classroom questionnaire
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
dplyr::select(LI06_05, LM01_01:LM01_08, # classroom management
LP01_01:LP01_08) %>% # non- & paraverbal communication
filter(!LI06_05 %in% c(201, 223)) %>% # exclude ID with no eye tracking data
rename(Participant = LI06_05) %>%
group_by(Participant) %>%
transmute(
Participant = Participant,
"Quest_All" = round(mean(c_across(starts_with(
"L"
)), na.rm = TRUE), 2),
"Quest_classroom_management" = round(mean(c_across(starts_with(
"LM"
)), na.rm = TRUE), 2),
"Quest_non_paraverbal_communication" = round(mean(c_across(starts_with(
"LP"
)), na.rm = TRUE), 2)
)
# create a big data frame with all measures
# put all data frames into list
df_list <- list(df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_aoi_disrup,
df_ttff_disrup,
df_sri,
df_sjt,
df_quest)
# merge all data frames in list
df_merge <-
df_list %>% reduce(full_join, by='Participant') %>%
# filter(`Teaching Experience` > 0) %>%
dplyr::select(GRI_mtu,
SJT_All,
Quest_All,
Mean_disruption_appraisal,
Mean_confidence_appraisal
)
# create a correlation matrix
cor_tab <-
df_merge %>%
cor(method = "pearson") %>%
round(., digits = 2)
View(cor_tab)
# p-value for GRI x STJ_All
cor.test(df_merge$GRI_mtu, df_merge$SJT_All)
# p-value for GRI x Quest_All
cor.test(df_merge$GRI_mtu, df_merge$Quest_All)
# p-value for GRI x Disruption Rating
cor.test(df_merge$GRI_mtu, df_merge$Mean_disruption_appraisal)
# p-value for GRI x Confidence Rating
cor.test(df_merge$GRI_mtu, df_merge$Mean_confidence_appraisal)
# p-value for GRI x Teaching Experience
cor.test(df_merge_experts$GRI_mtu, df_merge_experts$`Teaching Experience`)
