# cor_matrix_experts <- as.data.frame(cor_results_experts$r)  # Extract correlation coefficients
# p_matrix_experts <- as.data.frame(cor_results_experts$P)   # Extract p-values
#
# # Reshape data into tidy format for Experts
# correlation_pvalues_experts <- cor_matrix_experts %>%
#   rownames_to_column(var = "Variable1") %>%
#   pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
#   left_join(
#     p_matrix_experts %>%
#       rownames_to_column(var = "Variable1") %>%
#       pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
#     by = c("Variable1", "Variable2")
#   ) %>%
#   mutate(
#     Correlation = round(Correlation, 2),
#     P_value = round(P_value, 2),
#     APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
#   )
#
# # Create an APA-style table for Experts
# correlation_table_experts <- correlation_pvalues_experts %>%
#   select(Variable1, Variable2, APA_Format) %>%
#   pivot_wider(
#     names_from = Variable2,
#     values_from = APA_Format
#   )
#
# # Display the Experts table
# kable(correlation_table_experts, format = "html", caption = "Correlation Table: Experts") %>%
#   kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
#
#
# # 5. Correlation Analysis: Novices ---------------------------------------------
#
# # Filter data for Novices (Participants with ID < 200)
# df_novices <- df_merge %>%
#   filter(Participant < 200) %>%
#   select(-`Teaching Experience`,
#          -Participant)
#
# # Compute correlation coefficients and p-values for Novices
# cor_results_novices <- rcorr(as.matrix(df_novices))
# cor_matrix_novices <- as.data.frame(cor_results_novices$r)  # Extract correlation coefficients
# p_matrix_novices <- as.data.frame(cor_results_novices$P)   # Extract p-values
#
# # Reshape data into tidy format for Novices
# correlation_pvalues_novices <- cor_matrix_novices %>%
#   rownames_to_column(var = "Variable1") %>%
#   pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
#   left_join(
#     p_matrix_novices %>%
#       rownames_to_column(var = "Variable1") %>%
#       pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
#     by = c("Variable1", "Variable2")
#   ) %>%
#   mutate(
#     Correlation = round(Correlation, 2),
#     P_value = round(P_value, 2),
#     APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
#   )
#
# # Create an APA-style table for Novices
# correlation_table_novices <- correlation_pvalues_novices %>%
#   select(Variable1, Variable2, APA_Format) %>%
#   pivot_wider(
#     names_from = Variable2,
#     values_from = APA_Format
#   )
#
# # Display the Novices table
# kable(correlation_table_novices, format = "html", caption = "Correlation Table: Novices") %>%
#   kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
cor_flextable_experienced
cor_flextable_inexperienced
cor_flextable_experienced
# install.packages("needs")
# suppress "summarize" info.
# if this line is ommitted, each table using the summarize function will be accompanied with a warning from the console
options(dplyr.summarise.inform = FALSE)
library(needs)
needs(
tidyverse,     # A collection of packages (e.g., ggplot2, dplyr, tidyr) for data manipulation, visualization, and general workflows.
lubridate,     # For working with dates and times (e.g., parsing, manipulation, arithmetic).
viridis,       # Provides colorblind-friendly color palettes for plots and visualizations.
grid,          # A base R package for low-level grid graphics, useful for customizing complex plots.
gridExtra,     # Extends grid by allowing multiple grid-based plots to be arranged into a single layout.
cowplot,       # Simplifies creating publication-quality multi-panel plots, often combined with ggplot2.
readxl,        # For reading Excel files (.xls, .xlsx) into R without requiring external dependencies.
ARTofR,        # For applying aligned rank transform (ART) to factorial data for nonparametric analysis.
moments,       # Provides functions to compute statistical moments (e.g., skewness, kurtosis).
ltm,           # Used for latent trait models, including item response theory (IRT) analysis.
sjPlot,        # A package to create publication-ready tables and visualizations for statistical models.
kableExtra,    # Enhances the `knitr::kable()` function for producing polished and customizable tables in R Markdown.
xtable,        # Converts R objects to LaTeX/HTML tables, especially useful for integration with Sweave/knitr.
DescTools,     # A toolbox of descriptive statistics, effect size calculations, and data manipulation utilities.
formattable,   # Allows creation of "formattable" data frames with customized formatting for reporting.
psych,         # Provides tools for psychological research, including reliability analysis and descriptive statistics.
apaTables,     # Simplifies the creation of APA-style tables for inclusion in papers or reports.
rstatix,       # User-friendly pipe-compatible functions for common statistical tests and effect sizes.
effsize,       # Computes effect sizes (e.g., Cohen's d) for t-tests and other statistical comparisons.
knitr,         # Enables dynamic reporting by weaving R code and outputs into documents (e.g., R Markdown).
papaja,        # Helps produce APA-style manuscripts directly from R Markdown.
afex,          # Performs ANOVAs, including mixed-designs and generalized linear models, with a focus on user-friendliness.
emmeans,       # Computes estimated marginal means (or least-squares means) for post-hoc comparisons in models.
corrplot,      # Visualize correlation matrices in a visually appealing way.
flextable,     # Allows for creating customizable and professional tables
officer        # Enables integration of tables and content into Microsoft Office documents like Word and PowerPoint
)
# Step 1: List all .tsv files in the "data" folder that contain "interval_complete"
file_names <- list.files(path = "data", pattern = "interval_complete.tsv", full.names = TRUE)
# Step 2: Read and bind all .tsv files into a single tibble
df_aoi <- file_names %>%
map_dfr(~ read_tsv(.x, locale = locale(decimal_mark = ",")) %>%
select(
Group,
Participant,
TOI,
Duration_of_interval,
Start_of_interval,
starts_with("Total_duration_of_fixations"),
starts_with("Average_duration_of_fixations"),
starts_with("Number_of_fixations"),
starts_with("Time_to_first_fixation")
))
# Step 3: Extract only the participant's ID number (3 digits) and assign group based on Participant ID
df_aoi <- df_aoi %>%
mutate(
Participant = as.numeric(str_extract(Participant, "\\d{3}")),
Group = case_when(  # Assign group based on Participant ID
Participant > 200 ~ "Expert",
Participant < 200 ~ "Novice",
TRUE ~ NA_character_  # In case there's any other value or missing
)
)
# Step 4: Exclude invalid participant ID 223
df_aoi <- df_aoi %>%
filter(Participant != 223)
# 1. Load and Prepare Data -----------------------------------------------
# Demo Data --------------------------------------------
df_demo <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(!LI06_05 %in% c(201, 223)) %>%  # Exclude participants without eye-tracking data
transmute(
Participant = LI06_05,
# `Teaching Experience` = LI04_01
) %>%
arrange(Participant)
# ET-Measures (Micro-Teaching Unit) - Exclude Disruptive Student --------------------------------------------
df_aoi_numb_dur <- df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select(
Participant,
starts_with("Total_duration_of_fixations"),
starts_with("Number_of_fixations"),
starts_with("Average_duration"),
Duration_of_interval  # Ensure this variable is included
) %>%
dplyr::select(
-contains("Disruptive_Person")  # Exclude Disruptive Student
) %>%
rowwise() %>%
transmute(
Participant,
Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
Number_fixation_min_mtu = round(sum(c_across(starts_with("Number_of")), na.rm = TRUE) /
Duration_of_interval_min, 0),
Average_duration_mtu = round(sum(c_across(starts_with("Total_duration")), na.rm = TRUE) /
sum(c_across(starts_with("Number_of")), na.rm = TRUE), 0),
GRI = round(Average_duration_mtu / Number_fixation_min_mtu, 2)
) %>%
select(Participant,
Number_fixation_min_mtu,
Average_duration_mtu,
GRI) %>%
arrange(Participant)
# ET-Measures (AOI Students) - Exclude Disruptive Student --------------------------------------------
df_aoi_stud <- df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select (
Group,
Duration_of_interval,
Participant,
"Total_duration_of_fixations.Anna",
"Total_duration_of_fixations.Bianca",
"Total_duration_of_fixations.Carl(a)",
"Number_of_fixations.Anna",
"Number_of_fixations.Bianca",
"Number_of_fixations.Carl(a)"
) %>%
rowwise() %>%
transmute(
Group = as_factor(Group),
Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),
Participant = Participant,
Stud_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
Stud_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
Stud_number_fixation_min = round(Stud_number_fixation / Duration_of_interval_min, 2),
Average_duration_stud = round(Stud_duration_fixation / Stud_number_fixation, 0)
) %>%
select(Participant,
Stud_number_fixation_min,
) %>%
arrange(Participant) %>%
drop_na()
# ET-Measures (AOI Disruptive Student) --------------------------------------------
# Time to first fixation on AOI Disruptive Student --------------------------------------------
# Define disruptions and categories
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")
# Step 1: Data Preparation
df_ttff_disrup <- df_aoi %>%
filter(TOI %in% c(verbal_disruptions, physical_disruptions, lack_of_eagerness)) %>%
dplyr::select(
Participant,
TOI,
Time_to_first_fixation.Disruptive_Person
) %>%
mutate(
Group = ifelse(Participant < 200, "Novice", "Expert"),  # Assigning Group based on Participant
Disruption_Category = case_when(
TOI %in% verbal_disruptions ~ "Verbal disruptions",
TOI %in% physical_disruptions ~ "Physical disruptions",
TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
TRUE ~ NA_character_
)
) %>%
filter(!is.na(Disruption_Category)) %>% # Keep only rows with valid categories
drop_na()
# Apply final filtering
df_ttff_disrup <- df_ttff_disrup %>%
filter(
Time_to_first_fixation.Disruptive_Person > 0, # Exclude zero fixation times
Time_to_first_fixation.Disruptive_Person <= 30000 # Cut-off at 30 seconds
) %>%
mutate(
Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person / 1000, 2),
log_Disrup_time_fixation_sec = round(log(Disrup_time_fixation_sec), 2) # Log-transformed variable
)
# Summarize the log-transformed variable by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
group_by(Participant) %>%
summarise(
log_Disrup_time_fixation_sec = round(mean(log_Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average log time to first fixation per participant
.groups = "drop"
)
# SRI Rating Data --------------------------------------------
# Data Import and Preprocessing ------------------------------------------
df_sri <- read_excel("data/Coding_SRI.xlsx") %>%
filter(
!ID %in% c(201, 223),  # Removing invalid IDs
!disruption_appraisal %in% c(-100, -99, -88),  # Removing invalid disruption appraisals
!confidence_appraisal %in% c(-100, -99, -88),  # Removing invalid confidence appraisals
!prevalence_rating %in% c(-100, -99, -88)  # Removing invalid prevalence ratings
) %>%
mutate(
Participant = ID,  # Keep ID as is for Participant column
Disruption_Rating = as.numeric(disruption_appraisal),
Confidence_Rating = as.numeric(confidence_appraisal)
)%>%
select(Participant,
Disruption_Rating,
Confidence_Rating) %>% # Remove the original ID column after renaming
arrange(Participant) %>%
group_by(Participant) %>%
summarise(
Disruption_Rating = round(mean(Disruption_Rating, na.rm = TRUE), 2),
Confidence_Rating = round(mean(Confidence_Rating, na.rm = TRUE), 2)
)
# Situational Judgment Test (SJT) --------------------------------------------
df_sjt <- read_excel("./data/SJT.xlsx") %>%
filter(!UI06_05 %in% c(201, 223)) %>%
transmute(
Participant = UI06_05,
SJT_All = round(SJT_KF_gek, 2),
SJT_Monitoring = round(SJT_AL_gek, 2)
) %>%
arrange(Participant)
# Self-Evaluation Data --------------------------------------------
# Data Import and Preparation
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs
mutate(
Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Define groups
Participant = LI06_05  # Create a new Participant column
) %>%
arrange(Participant) %>%
select(
Participant,
Group,
starts_with("LM01"),  # Classroom Management and Disruption Handling
starts_with("LP01")   # Presence
) %>%
na.omit()  # Remove rows with missing values
# Summarize the scales to an overall mean per participant
df_quest_summary <- df_quest %>%
mutate(
# Calculate the overall self-evaluation mean across all classroom management and presence subscales
Self_Eval_Overall = round(rowMeans(select(., starts_with("LM01"), starts_with("LP01")), na.rm = TRUE), 2)
) %>%
select(Participant, Self_Eval_Overall) %>%  # Keep only the overall self-evaluation score
arrange(Participant)
# 2. Combine All Data ---------------------------------------------------
# Ensure Participant is consistent across all dataframes
df_demo <- df_demo %>% mutate(Participant = as.numeric(Participant))
df_aoi_numb_dur <- df_aoi_numb_dur %>% mutate(Participant = as.numeric(Participant))
df_aoi_stud <- df_aoi_stud %>% mutate(Participant = as.numeric(Participant))
df_ttff_disrup_participant_summary <- df_ttff_disrup_participant_summary %>% mutate(Participant = as.numeric(Participant))
df_sri <- df_sri %>% mutate(Participant = as.numeric(Participant))
df_sjt <- df_sjt %>% mutate(Participant = as.numeric(Participant))
df_quest_summary <- df_quest_summary %>% mutate(Participant = as.numeric(Participant))
# Merge the dataframes
df_list <- list(
df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_ttff_disrup_participant_summary,
df_sri,
df_sjt,
df_quest_summary
)
# Combine all dataframes by Participant
df_merge <- reduce(df_list, full_join, by = "Participant")
# Load required libraries
library(tidyverse)
library(Hmisc)
library(knitr)
library(kableExtra)
# Separate Data by Experience Level
# Experienced teachers (ID > 200)
df_correlation_experienced <- df_merge %>%
filter(Participant > 200) %>%
select(
Number_fixation_min_mtu,
Average_duration_mtu,
GRI,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
SJT_All,
Self_Eval_Overall
) %>%
drop_na()
# Inexperienced teachers (ID < 200)
df_correlation_inexperienced <- df_merge %>%
filter(Participant < 200) %>%
select(
Average_duration_mtu,
Number_fixation_min_mtu,
GRI,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
Self_Eval_Overall,
SJT_All
) %>%
drop_na()
# Compute Correlations for Experienced Teachers
cor_results_experienced <- rcorr(as.matrix(df_correlation_experienced))
cor_matrix_experienced <- cor_results_experienced$r
p_matrix_experienced <- cor_results_experienced$P
# Compute Correlations for Inexperienced Teachers
cor_results_inexperienced <- rcorr(as.matrix(df_correlation_inexperienced))
cor_matrix_inexperienced <- cor_results_inexperienced$r
p_matrix_inexperienced <- cor_results_inexperienced$P
# Reshape correlation coefficients and p-values into a tidy format for experienced teachers
correlation_pvalues_experienced <- as.data.frame(as.table(cor_matrix_experienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix_experienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%
mutate(
Correlation = round(Correlation, 2),
P_value = round(P_value, 3),
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
)
# Reshape correlation coefficients and p-values into a tidy format for inexperienced teachers
correlation_pvalues_inexperienced <- as.data.frame(as.table(cor_matrix_inexperienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix_inexperienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%
mutate(
Correlation = round(Correlation, 2),
P_value = round(P_value, 3),
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
)
# Create correlation tables for both groups
correlation_table_experienced <- correlation_pvalues_experienced %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(names_from = Variable2, values_from = APA_Format)
correlation_table_inexperienced <- correlation_pvalues_inexperienced %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(names_from = Variable2, values_from = APA_Format)
# Ensure Variable1 is a factor to maintain order
correlation_table_experienced$Variable1 <- factor(correlation_table_experienced$Variable1, levels = unique(correlation_table_experienced$Variable1))
correlation_table_inexperienced$Variable1 <- factor(correlation_table_inexperienced$Variable1, levels = unique(correlation_table_inexperienced$Variable1))
# Convert to flextable for APA formatting
cor_flextable_experienced <- correlation_table_experienced %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 1: Correlation Table for Experienced Teachers")
cor_flextable_inexperienced <- correlation_table_inexperienced %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 2: Correlation Table for Inexperienced Teachers")
# Define relevant columns for correlation analysis
correlation_columns <- c(
"Number_fixation_min_mtu",
"Average_duration_mtu",
"GRI",
"Stud_number_fixation_min",
"log_Disrup_time_fixation_sec",
"Disruption_Rating",
"Confidence_Rating",
"SJT_All",
"Self_Eval_Overall"
)
# Drop rows with missing values
df_correlation_all <- df_merge %>%
select(all_of(correlation_columns)) %>%
drop_na()
# Compute Pearson correlation matrix
cor_results_all <- rcorr(as.matrix(df_correlation_all))
# Extract correlation coefficients and p-values
cor_matrix_all <- cor_results_all$r
p_matrix_all <- cor_results_all$P
# Convert correlation and p-value matrices into a tidy format
correlation_pvalues_all <- as.data.frame(as.table(cor_matrix_all)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix_all)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%
mutate(
Correlation = round(Correlation, 2),
P_value = round(P_value, 3),
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
)
# Reshape into a correlation table format
correlation_table_all <- correlation_pvalues_all %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(names_from = Variable2, values_from = APA_Format)
# Ensure Variable1 is a factor to maintain order
correlation_table_all$Variable1 <- factor(correlation_table_all$Variable1, levels = unique(correlation_table_all$Variable1))
# Create APA-styled table
cor_flextable_all <- correlation_table_all %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table: Correlation Table for All Participants")
# Print the table
cor_flextable_all
# Define relevant columns for correlation analysis
correlation_columns <- c(
"GRI",
"Stud_number_fixation_min",
"log_Disrup_time_fixation_sec",
"Disruption_Rating",
"Confidence_Rating",
"SJT_All",
"Self_Eval_Overall"
)
# Drop rows with missing values
df_correlation_all <- df_merge %>%
select(all_of(correlation_columns)) %>%
drop_na()
# Compute Pearson correlation matrix
cor_results_all <- rcorr(as.matrix(df_correlation_all))
# Extract correlation coefficients and p-values
cor_matrix_all <- cor_results_all$r
p_matrix_all <- cor_results_all$P
# Convert correlation and p-value matrices into a tidy format
correlation_pvalues_all <- as.data.frame(as.table(cor_matrix_all)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix_all)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%
mutate(
Correlation = round(Correlation, 2),
P_value = round(P_value, 3),
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
)
# Reshape into a correlation table format
correlation_table_all <- correlation_pvalues_all %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(names_from = Variable2, values_from = APA_Format)
# Ensure Variable1 is a factor to maintain order
correlation_table_all$Variable1 <- factor(correlation_table_all$Variable1, levels = unique(correlation_table_all$Variable1))
# Create APA-styled table
cor_flextable_all <- correlation_table_all %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table: Correlation Table for All Participants")
# Print the table
cor_flextable_all
