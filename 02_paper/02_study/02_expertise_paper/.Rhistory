knitr::kable(
post_hoc_results_disruption,
caption = "Post-Hoc Pairwise Comparisons for Disruption Categories (Including Effect Sizes)",
col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
digits = 2
) %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
# # Normality Tests (Shapiro-Wilk)
# normality_tests <- df_ttff_disrup %>%
#   group_by(Group) %>%
#   summarise(
#     Shapiro_Wilk_p = round(shapiro.test(Disrup_time_fixation_sec)$p.value, 2),
#     .groups = "drop"
#   )
#
# kable(
#   normality_tests,
#   caption = "Shapiro-Wilk Test for Normality by Group",
#   col.names = c("Group", "Shapiro-Wilk p-value"),
#   row.names = FALSE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
#
# # Mann-Whitney U-Test and Effect Size
# mann_whitney_test <- wilcox.test(Disrup_time_fixation_sec ~ Group, data = df_ttff_disrup, exact = FALSE)
#
# # Effect Size Calculation for Mann-Whitney (r)
# n1 <- nrow(df_ttff_disrup %>% filter(Group == "Novice"))
# n2 <- nrow(df_ttff_disrup %>% filter(Group == "Expert"))
# r_effect <- abs(mann_whitney_test$statistic - (n1 * n2 / 2)) / sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
#
# mann_whitney_results <- data.frame(
#   "Test" = "Mann-Whitney U",
#   "W" = round(mann_whitney_test$statistic, 2),
#   "p-value" = round(mann_whitney_test$p.value, 2),
#   "Effect Size (r)" = round(r_effect, 3)
# )
#
# kable(
#   mann_whitney_results,
#   caption = "Mann-Whitney U-Test Results for Time to First Fixation",
#   row.names = FALSE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
#
# # Kruskal-Wallis Test and Pairwise Comparisons
# kruskal_test <- kruskal.test(Disrup_time_fixation_sec ~ Disruption_Category, data = df_ttff_disrup)
#
# kruskal_results <- data.frame(
#   "Test" = "Kruskal-Wallis",
#   "Chi-squared" = round(kruskal_test$statistic, 2),
#   "df" = kruskal_test$parameter,
#   "p-value" = round(kruskal_test$p.value, 2)
# )
#
# kable(
#   kruskal_results,
#   caption = "Kruskal-Wallis Test Results for Differences Between Disruption Categories",
#   row.names = FALSE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
#
# # Pairwise Wilcoxon test with Bonferroni correction
# pairwise_wilcox <- pairwise.wilcox.test(
#   x = df_ttff_disrup$Disrup_time_fixation_sec,
#   g = df_ttff_disrup$Disruption_Category,
#   p.adjust.method = "bonferroni"
# )
#
# # Extract and round the p-values to 3 decimal places
# pairwise_results <- as.data.frame(pairwise_wilcox$p.value) %>%
#   mutate(across(everything(), ~ round(., 2)))
#
# # Display the results with rounded p-values
# kable(
#   pairwise_results,
#   caption = "Pairwise Wilcoxon Test Results (Bonferroni Corrected)",
#   row.names = TRUE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
# Define disruptions and categories
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")
# Step 1: Data Preparation
df_ttff_disrup <- df_aoi %>%
filter(TOI %in% c(verbal_disruptions, physical_disruptions, lack_of_eagerness)) %>%
dplyr::select(
Participant,
TOI,
Time_to_first_fixation.Disruptive_Person
) %>%
mutate(
Group = ifelse(Participant < 200, "Novice", "Expert"),  # Assigning Group based on Participant
Disruption_Category = case_when(
TOI %in% verbal_disruptions ~ "Verbal disruptions",
TOI %in% physical_disruptions ~ "Physical disruptions",
TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
TRUE ~ NA_character_
)
) %>%
filter(!is.na(Disruption_Category)) %>% # Keep only rows with valid categories
drop_na()
# Apply final filtering
df_ttff_disrup <- df_ttff_disrup %>%
filter(
Time_to_first_fixation.Disruptive_Person > 0, # Exclude zero fixation times
Time_to_first_fixation.Disruptive_Person <= 30000 # Cut-off at 30 seconds
) %>%
mutate(
Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person / 1000, 2),
log_Disrup_time_fixation_sec = round(log(Disrup_time_fixation_sec), 2) # Log-transformed variable
)
# Summarize the log-transformed variable by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
group_by(Participant, Group) %>%
summarise(
log_Disrup_time_fixation_sec = round(mean(log_Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average log time to first fixation per participant
.groups = "drop"
)
# SRI Rating Data --------------------------------------------
# Data Import and Preprocessing ------------------------------------------
df_sri <- read_excel("data/Coding_SRI.xlsx") %>%
filter(
!ID %in% c(201, 223),  # Removing invalid IDs
!disruption_appraisal %in% c(-100, -99, -88),  # Removing invalid disruption appraisals
!confidence_appraisal %in% c(-100, -99, -88),  # Removing invalid confidence appraisals
!prevalence_rating %in% c(-100, -99, -88)  # Removing invalid prevalence ratings
) %>%
mutate(
Group = ifelse(ID < 200, "Novice", "Expert"),  # Create a Group column based on ID
Participant = ID,  # Keep ID as is for Participant column
Disruption_Rating = as.numeric(disruption_appraisal),
Confidence_Rating = as.numeric(confidence_appraisal),
Prevalence_Rating = as.numeric(prevalence_rating)
) %>%
select(-ID) %>% # Remove the original ID column after renaming
arrange(Participant)
# Step 1: Summarize appraisals for each disruption
df_sri_disrup_summary <- df_sri %>%
filter(event %in% c(verbal_disruptions, lack_of_eagerness)) %>%
group_by(Participant, event) %>%
summarise(
Disruption_Appraisal_Mean = mean(disruption_appraisal, na.rm = TRUE),
Confidence_Appraisal_Mean = mean(confidence_appraisal, na.rm = TRUE),
.groups = "drop"
) %>%
pivot_wider(
names_from = event,
values_from = c(Disruption_Appraisal_Mean, Confidence_Appraisal_Mean),
names_sep = "_"
) %>%
mutate(across(everything(), ~ replace_na(., 0))) %>%   # Replace missing values with 0
arrange(Participant)
# Step 2: Summarize overall appraisals by Participant
df_sri_clean <- df_sri %>%
group_by(Participant) %>%
summarise(
Disruption_Rating = round(mean(Disruption_Appraisal, na.rm = TRUE), 2),
Confidence_Rating = round(mean(Confidence_Appraisal, na.rm = TRUE), 2),
.groups = "drop"
) %>%
arrange(Participant)
# Step 1: Summarize appraisals for each disruption
df_sri_disrup_summary <- df_sri %>%
filter(event %in% c(verbal_disruptions, lack_of_eagerness)) %>%
group_by(Participant, event) %>%
summarise(
Disruption_Appraisal_Mean = mean(disruption_appraisal, na.rm = TRUE),
Confidence_Appraisal_Mean = mean(confidence_appraisal, na.rm = TRUE),
.groups = "drop"
) %>%
pivot_wider(
names_from = event,
values_from = c(Disruption_Appraisal_Mean, Confidence_Appraisal_Mean),
names_sep = "_"
) %>%
mutate(across(everything(), ~ replace_na(., 0))) %>%   # Replace missing values with 0
arrange(Participant)
# Step 2: Summarize overall appraisals by Participant
df_sri_clean <- df_sri %>%
group_by(Participant) %>%
summarise(
Disruption_Rating = round(mean(Disruption_Rating, na.rm = TRUE), 2),
Confidence_Rating = round(mean(Disruption_Rating, na.rm = TRUE), 2),
.groups = "drop"
) %>%
arrange(Participant)
# Combine both summaries (disruption-specific and overall)
df_sri_combined <- full_join(df_sri_clean, df_sri_disrup_summary, by = "Participant")
# Situational Judgment Test (SJT) --------------------------------------------
df_sjt <- read_excel("./data/SJT.xlsx") %>%
filter(!UI06_05 %in% c(201, 223)) %>%
transmute(
Participant = UI06_05,
SJT_All = round(SJT_KF_gek, 2),
SJT_Monitoring = round(SJT_AL_gek, 2)
) %>%
arrange(Participant)
# Self-Evaluation Data --------------------------------------------
# Data Import and Preparation
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs
mutate(
Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Define groups
Participant = LI06_05  # Create a new Participant column
) %>%
arrange(Participant) %>%
select(
Participant,
Group,
starts_with("LM01"),  # Classroom Management and Disruption Handling
starts_with("LP01")   # Presence
) %>%
na.omit()  # Remove rows with missing values
# Summarize the scales to an overall mean per participant
df_quest_summary <- df_quest %>%
mutate(
# Calculate the overall self-evaluation mean across all classroom management and presence subscales
Self_Eval_Overall = round(rowMeans(select(., starts_with("LM01"), starts_with("LP01")), na.rm = TRUE), 2)
) %>%
select(Participant, Self_Eval_Overall) %>%  # Keep only the overall self-evaluation score
arrange(Participant)
# Ensure Participant is consistent across all dataframes
df_demo <- df_demo %>% mutate(Participant = as.numeric(Participant))
df_aoi_numb_dur <- df_aoi_numb_dur %>% mutate(Participant = as.numeric(Participant))
df_aoi_stud <- df_aoi_stud %>% mutate(Participant = as.numeric(Participant))
df_ttff_disrup_participant_summary <- df_ttff_disrup_participant_summary %>% mutate(Participant = as.numeric(Participant))
df_sri_combined <- df_sri_combined %>% mutate(Participant = as.numeric(Participant))
df_sjt <- df_sjt %>% mutate(Participant = as.numeric(Participant))
df_quest_summary <- df_quest_summary %>% mutate(Participant = as.numeric(Participant))
# Merge the dataframes
df_list <- list(
df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_ttff_disrup_participant_summary,
df_sri_combined,
df_sjt,
df_quest_summary
)
# Combine all dataframes by Participant
df_merge <- reduce(df_list, full_join, by = "Participant")
# Load required libraries
library(tidyverse)
library(knitr)
library(knitr)
library(kableExtra)
# Compute correlation coefficients and p-values for the full dataset
cor_results <- rcorr(as.matrix(df_correlation))
cor_matrix <- as.data.frame(cor_results$r)  # Extract correlation coefficients
p_matrix <- as.data.frame(cor_results$P)   # Extract p-values
# Reshape correlation coefficients and p-values into a tidy format
correlation_pvalues <- cor_matrix %>%
rownames_to_column(var = "Variable1") %>%
pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
left_join(
p_matrix %>%
rownames_to_column(var = "Variable1") %>%
pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
by = c("Variable1", "Variable2")
) %>%
mutate(
Correlation = round(Correlation, 2),  # Round correlation coefficients
P_value = round(P_value, 2),          # Round p-values
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))  # Format APA style
)
# Create an APA-style table
correlation_table <- correlation_pvalues %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(
names_from = Variable2,
values_from = APA_Format
)
# Display the table
kable(correlation_table, format = "html", caption = "Correlation Table: Overall") %>%
kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
View(df_ttff_disrup_participant_summary)
# Summarize the log-transformed variable by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
group_by(Participant) %>%
summarise(
log_Disrup_time_fixation_sec = round(mean(log_Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average log time to first fixation per participant
.groups = "drop"
)
# Merge the dataframes
df_list <- list(
df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_ttff_disrup_participant_summary,
df_sri_combined,
df_sjt,
df_quest_summary
)
# Combine all dataframes by Participant
df_merge <- reduce(df_list, full_join, by = "Participant")
# Load required libraries
library(tidyverse)
library(Hmisc)
library(Hmisc)
library(knitr)
library(kableExtra)
df_correlation <- df_merge %>%
select(
Number_fixation_min_mtu,
Average_duration_mtu,
GRI_mtu,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
SJT_All,
Self_Eval_Overall
)
# Compute correlation coefficients and p-values for the full dataset
cor_results <- rcorr(as.matrix(df_correlation))
cor_matrix <- as.data.frame(cor_results$r)  # Extract correlation coefficients
p_matrix <- as.data.frame(cor_results$P)   # Extract p-values
# Reshape correlation coefficients and p-values into a tidy format
correlation_pvalues <- cor_matrix %>%
rownames_to_column(var = "Variable1") %>%
pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
left_join(
p_matrix %>%
rownames_to_column(var = "Variable1") %>%
pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
by = c("Variable1", "Variable2")
) %>%
mutate(
Correlation = round(Correlation, 2),  # Round correlation coefficients
P_value = round(P_value, 2),          # Round p-values
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))  # Format APA style
)
# Create an APA-style table
correlation_table <- correlation_pvalues %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(
names_from = Variable2,
values_from = APA_Format
)
# Display the table
kable(correlation_table, format = "html", caption = "Correlation Table: Overall") %>%
kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
# 5. Save the table as a Word document --------------------------------------
doc <- read_docx() %>%
body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
body_add_flextable(cor_flextable)
# 3. Reshape correlation coefficients and p-values into a tidy format -----
correlation_pvalues <- cor_matrix %>%
rownames_to_column(var = "Variable1") %>%
pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
left_join(
p_matrix %>%
rownames_to_column(var = "Variable1") %>%
pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
by = c("Variable1", "Variable2")
) %>%
mutate(
Correlation = round(Correlation, 2),  # Round correlation coefficients
P_value = round(P_value, 2),          # Round p-values
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))  # Format in APA style
)
# 4. Create an APA-style correlation table --------------------------------------------
correlation_table <- correlation_pvalues %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(
names_from = Variable2,
values_from = APA_Format
)
# Convert to flextable for APA formatting
cor_flextable <- correlation_table %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Correlation Table: Research Question 5 (APA format)")
# 5. Save the table as a Word document --------------------------------------
doc <- read_docx() %>%
body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
body_add_flextable(cor_flextable)
# Save the document
save_as_docx(doc, path = "Correlation_Table_APA.docx")
# Output confirmation message
print("Correlation table saved as 'Correlation_Table_APA.docx'")
library(officer)
library(flextable)
# 3. Correlation Analysis: Overall ---------------------------------------------
# 1. Select relevant variables for correlation analysis --------------------
df_correlation <- df_merge %>%
select(
Number_fixation_min_mtu,
Average_duration_mtu,
GRI_mtu,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
SJT_All,
Self_Eval_Overall
) %>%
drop_na()  # Remove rows with missing values for accurate correlation
# 2. Compute correlation coefficients and p-values ------------------------
cor_results <- rcorr(as.matrix(df_correlation))
cor_matrix <- cor_results$r  # Extract correlation coefficients
p_matrix <- cor_results$P    # Extract p-values
# 3. Reshape correlation coefficients and p-values into a tidy format -----
correlation_pvalues <- as.data.frame(as.table(cor_matrix)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%  # Remove redundant self-correlations
mutate(
Correlation = round(Correlation, 2),  # Round correlation coefficients
P_value = round(P_value, 3),          # Round p-values
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))  # APA formatting
)
# 4. Create an APA-style correlation table --------------------------------------------
correlation_table <- correlation_pvalues %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(
names_from = Variable2,
values_from = APA_Format
)
# Ensure Variable1 is a factor to maintain order
correlation_table$Variable1 <- factor(correlation_table$Variable1, levels = unique(correlation_table$Variable1))
# Convert to flextable for APA formatting
cor_flextable <- correlation_table %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 1: Correlation Table (APA Format)")
# 5. Save the table as a Word document --------------------------------------
doc <- read_docx() %>%
body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
body_add_flextable(cor_flextable)
# Save the document
save_as_docx(doc, path = "Correlation_Table_APA.docx")
# Output confirmation message
print("Correlation table successfully saved as 'Correlation_Table_APA.docx'")
correlation_table
cor_flextable
# 5. Save the table as a Word document --------------------------------------
doc <- read_docx() %>%
body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
body_add_flextable(cor_flextable)
# Convert to flextable for APA formatting
cor_flextable <- correlation_table %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 1: Correlation Table (APA Format)")
# 5. Save the table as a Word document --------------------------------------
doc <- read_docx() %>%
body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
body_add_flextable(cor_flextable)
# Save the document
save_as_docx(doc, path = "Correlation_Table_APA.docx")
cor_flextable
correlation_table
# Ensure Variable1 is a factor to maintain order
correlation_table$Variable1 <- factor(correlation_table$Variable1, levels = unique(correlation_table$Variable1))
# Convert to flextable for APA formatting
cor_flextable <- correlation_table %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 1: Correlation Table (APA Format)")
# Ensure Variable1 is a factor to maintain order
correlation_table$Variable1 <- factor(correlation_table$Variable1, levels = unique(correlation_table$Variable1))
# Convert to flextable for APA formatting
cor_flextable <- correlation_table %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 1: Correlation Table (APA Format)")
# Load required libraries
library(officer)
library(flextable)
# Ensure flextable is properly formatted
cor_flextable <- cor_flextable %>%
fontsize(size = 11, part = "all") %>%  # Set font size
bold(part = "header") %>%  # Make headers bold
align(align = "center", part = "all") %>%  # Center align the text
width(width = 1.5)  # Adjust column width
# Print table to check before saving (Debugging Step)
print(cor_flextable)
# 5. Save the table as a Word document --------------------------------------
doc <- read_docx() %>%
body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
body_add_par("", style = "Normal") %>%  # Add a blank space before the table
body_add_flextable(cor_flextable) %>%
body_add_par("", style = "Normal")  # Add blank space after the table
# Save the document
docx_path <- "Correlation_Table_APA.docx"
save_as_docx(doc, path = docx_path)
# Verify the file was created
if (file.exists(docx_path)) {
print(paste("✅ Correlation table successfully saved as:", docx_path))
} else {
print("❌ ERROR: Word document could not be saved. Check file permissions.")
}
cor_flextable
setwd("~/GitHub/Mandy-PhD/02_paper/02_study/02_expertise_paper")
# Define the full file path explicitly
docx_path <- file.path(getwd(), "Correlation_Table_APA.docx")
# Save the document
save_as_docx(doc, path = docx_path)
cor_flextable
correlation_table
