drop_na()
# Apply final filtering
df_ttff_disrup <- df_ttff_disrup %>%
filter(
Time_to_first_fixation.Disruptive_Person > 0, # Exclude zero fixation times
Time_to_first_fixation.Disruptive_Person <= 30000 # Cut-off at 30 seconds
) %>%
mutate(
Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person / 1000, 2),
log_Disrup_time_fixation_sec = round(log(Disrup_time_fixation_sec), 2) # Log-transformed variable
)
# Summarize the log-transformed variable by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
group_by(Participant) %>%
summarise(
log_Disrup_time_fixation_sec = round(mean(log_Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average log time to first fixation per participant
.groups = "drop"
)
# SRI Rating Data --------------------------------------------
# Data Import and Preprocessing ------------------------------------------
df_sri <- read_excel("data/Coding_SRI.xlsx") %>%
filter(
!ID %in% c(201, 223),  # Removing invalid IDs
!disruption_appraisal %in% c(-100, -99, -88),  # Removing invalid disruption appraisals
!confidence_appraisal %in% c(-100, -99, -88),  # Removing invalid confidence appraisals
!prevalence_rating %in% c(-100, -99, -88)  # Removing invalid prevalence ratings
) %>%
mutate(
Participant = ID,  # Keep ID as is for Participant column
Disruption_Rating = as.numeric(disruption_appraisal),
Confidence_Rating = as.numeric(confidence_appraisal)
)%>%
select(Participant,
Disruption_Rating,
Confidence_Rating) %>% # Remove the original ID column after renaming
arrange(Participant) %>%
group_by(Participant) %>%
summarise(
Disruption_Rating = round(mean(Disruption_Rating, na.rm = TRUE), 2),
Confidence_Rating = round(mean(Disruption_Rating, na.rm = TRUE), 2)
)
# Situational Judgment Test (SJT) --------------------------------------------
df_sjt <- read_excel("./data/SJT.xlsx") %>%
filter(!UI06_05 %in% c(201, 223)) %>%
transmute(
Participant = UI06_05,
SJT_All = round(SJT_KF_gek, 2),
SJT_Monitoring = round(SJT_AL_gek, 2)
) %>%
arrange(Participant)
# Self-Evaluation Data --------------------------------------------
# Data Import and Preparation
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs
mutate(
Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Define groups
Participant = LI06_05  # Create a new Participant column
) %>%
arrange(Participant) %>%
select(
Participant,
Group,
starts_with("LM01"),  # Classroom Management and Disruption Handling
starts_with("LP01")   # Presence
) %>%
na.omit()  # Remove rows with missing values
# Summarize the scales to an overall mean per participant
df_quest_summary <- df_quest %>%
mutate(
# Calculate the overall self-evaluation mean across all classroom management and presence subscales
Self_Eval_Overall = round(rowMeans(select(., starts_with("LM01"), starts_with("LP01")), na.rm = TRUE), 2)
) %>%
select(Participant, Self_Eval_Overall) %>%  # Keep only the overall self-evaluation score
arrange(Participant)
# 2. Combine All Data ---------------------------------------------------
# Ensure Participant is consistent across all dataframes
df_demo <- df_demo %>% mutate(Participant = as.numeric(Participant))
df_aoi_numb_dur <- df_aoi_numb_dur %>% mutate(Participant = as.numeric(Participant))
df_aoi_stud <- df_aoi_stud %>% mutate(Participant = as.numeric(Participant))
df_ttff_disrup_participant_summary <- df_ttff_disrup_participant_summary %>% mutate(Participant = as.numeric(Participant))
df_sri <- df_sri %>% mutate(Participant = as.numeric(Participant))
df_sjt <- df_sjt %>% mutate(Participant = as.numeric(Participant))
df_quest_summary <- df_quest_summary %>% mutate(Participant = as.numeric(Participant))
# Merge the dataframes
df_list <- list(
df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_ttff_disrup_participant_summary,
df_sri,
df_sjt,
df_quest_summary
)
# Combine all dataframes by Participant
df_merge <- reduce(df_list, full_join, by = "Participant")
# Load required libraries
library(tidyverse)
library(Hmisc)
library(knitr)
library(kableExtra)
# Separate Data by Experience Level
# Experienced teachers (ID > 200)
df_correlation_experienced <- df_merge %>%
filter(Participant > 200) %>%
select(
Number_fixation_min_mtu,
Average_duration_mtu,
GRI,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
SJT_All,
Self_Eval_Overall
) %>%
drop_na()
# Inexperienced teachers (ID < 200)
df_correlation_inexperienced <- df_merge %>%
filter(Participant < 200) %>%
select(
Number_fixation_min_mtu,
Average_duration_mtu,
GRI,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
SJT_All,
Self_Eval_Overall
View(df_sri)
) %>%
View(df_sri)
# 1. Load and Prepare Data -----------------------------------------------
# Demo Data --------------------------------------------
df_demo <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(!LI06_05 %in% c(201, 223)) %>%  # Exclude participants without eye-tracking data
transmute(
Participant = LI06_05,
# `Teaching Experience` = LI04_01
) %>%
arrange(Participant)
# ET-Measures (Micro-Teaching Unit) - Exclude Disruptive Student --------------------------------------------
df_aoi_numb_dur <- df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select(
Participant,
starts_with("Total_duration_of_fixations"),
starts_with("Number_of_fixations"),
starts_with("Average_duration"),
Duration_of_interval  # Ensure this variable is included
) %>%
dplyr::select(
-contains("Disruptive_Person")  # Exclude Disruptive Student
) %>%
rowwise() %>%
transmute(
Participant,
Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
Number_fixation_min_mtu = round(sum(c_across(starts_with("Number_of")), na.rm = TRUE) /
Duration_of_interval_min, 0),
Average_duration_mtu = round(sum(c_across(starts_with("Total_duration")), na.rm = TRUE) /
sum(c_across(starts_with("Number_of")), na.rm = TRUE), 0),
GRI = round(Average_duration_mtu / Number_fixation_min_mtu, 2)
) %>%
select(Participant,
Number_fixation_min_mtu,
Average_duration_mtu,
GRI) %>%
arrange(Participant)
# ET-Measures (AOI Students) - Exclude Disruptive Student --------------------------------------------
df_aoi_stud <- df_aoi %>%
filter(TOI == "Lesson") %>%
dplyr::select (
Group,
Duration_of_interval,
Participant,
"Total_duration_of_fixations.Anna",
"Total_duration_of_fixations.Bianca",
"Total_duration_of_fixations.Carl(a)",
"Number_of_fixations.Anna",
"Number_of_fixations.Bianca",
"Number_of_fixations.Carl(a)"
) %>%
rowwise() %>%
transmute(
Group = as_factor(Group),
Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),
Participant = Participant,
Stud_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
Stud_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
Stud_number_fixation_min = round(Stud_number_fixation / Duration_of_interval_min, 2),
Average_duration_stud = round(Stud_duration_fixation / Stud_number_fixation, 0)
) %>%
select(Participant,
Stud_number_fixation_min,
) %>%
arrange(Participant) %>%
drop_na()
# ET-Measures (AOI Disruptive Student) --------------------------------------------
# Time to first fixation on AOI Disruptive Student --------------------------------------------
# Define disruptions and categories
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")
# Step 1: Data Preparation
df_ttff_disrup <- df_aoi %>%
filter(TOI %in% c(verbal_disruptions, physical_disruptions, lack_of_eagerness)) %>%
dplyr::select(
Participant,
TOI,
Time_to_first_fixation.Disruptive_Person
) %>%
mutate(
Group = ifelse(Participant < 200, "Novice", "Expert"),  # Assigning Group based on Participant
Disruption_Category = case_when(
TOI %in% verbal_disruptions ~ "Verbal disruptions",
TOI %in% physical_disruptions ~ "Physical disruptions",
TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
TRUE ~ NA_character_
)
) %>%
filter(!is.na(Disruption_Category)) %>% # Keep only rows with valid categories
drop_na()
# Apply final filtering
df_ttff_disrup <- df_ttff_disrup %>%
filter(
Time_to_first_fixation.Disruptive_Person > 0, # Exclude zero fixation times
Time_to_first_fixation.Disruptive_Person <= 30000 # Cut-off at 30 seconds
) %>%
mutate(
Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person / 1000, 2),
log_Disrup_time_fixation_sec = round(log(Disrup_time_fixation_sec), 2) # Log-transformed variable
)
# Summarize the log-transformed variable by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
group_by(Participant) %>%
summarise(
log_Disrup_time_fixation_sec = round(mean(log_Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average log time to first fixation per participant
.groups = "drop"
)
# SRI Rating Data --------------------------------------------
# Data Import and Preprocessing ------------------------------------------
df_sri <- read_excel("data/Coding_SRI.xlsx") %>%
filter(
!ID %in% c(201, 223),  # Removing invalid IDs
!disruption_appraisal %in% c(-100, -99, -88),  # Removing invalid disruption appraisals
!confidence_appraisal %in% c(-100, -99, -88),  # Removing invalid confidence appraisals
!prevalence_rating %in% c(-100, -99, -88)  # Removing invalid prevalence ratings
) %>%
mutate(
Participant = ID,  # Keep ID as is for Participant column
Disruption_Rating = as.numeric(disruption_appraisal),
Confidence_Rating = as.numeric(confidence_appraisal)
)%>%
select(Participant,
Disruption_Rating,
Confidence_Rating) %>% # Remove the original ID column after renaming
arrange(Participant) %>%
group_by(Participant) %>%
summarise(
Disruption_Rating = round(mean(Disruption_Rating, na.rm = TRUE), 2),
Confidence_Rating = round(mean(Confidence_Rating, na.rm = TRUE), 2)
)
# Situational Judgment Test (SJT) --------------------------------------------
df_sjt <- read_excel("./data/SJT.xlsx") %>%
filter(!UI06_05 %in% c(201, 223)) %>%
transmute(
Participant = UI06_05,
SJT_All = round(SJT_KF_gek, 2),
SJT_Monitoring = round(SJT_AL_gek, 2)
) %>%
arrange(Participant)
# Self-Evaluation Data --------------------------------------------
# Data Import and Preparation
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs
mutate(
Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Define groups
Participant = LI06_05  # Create a new Participant column
) %>%
arrange(Participant) %>%
select(
Participant,
Group,
starts_with("LM01"),  # Classroom Management and Disruption Handling
starts_with("LP01")   # Presence
) %>%
na.omit()  # Remove rows with missing values
# Summarize the scales to an overall mean per participant
df_quest_summary <- df_quest %>%
mutate(
# Calculate the overall self-evaluation mean across all classroom management and presence subscales
Self_Eval_Overall = round(rowMeans(select(., starts_with("LM01"), starts_with("LP01")), na.rm = TRUE), 2)
) %>%
select(Participant, Self_Eval_Overall) %>%  # Keep only the overall self-evaluation score
arrange(Participant)
# 2. Combine All Data ---------------------------------------------------
# Ensure Participant is consistent across all dataframes
df_demo <- df_demo %>% mutate(Participant = as.numeric(Participant))
df_aoi_numb_dur <- df_aoi_numb_dur %>% mutate(Participant = as.numeric(Participant))
df_aoi_stud <- df_aoi_stud %>% mutate(Participant = as.numeric(Participant))
df_ttff_disrup_participant_summary <- df_ttff_disrup_participant_summary %>% mutate(Participant = as.numeric(Participant))
df_sri <- df_sri %>% mutate(Participant = as.numeric(Participant))
df_sjt <- df_sjt %>% mutate(Participant = as.numeric(Participant))
df_quest_summary <- df_quest_summary %>% mutate(Participant = as.numeric(Participant))
# Merge the dataframes
df_list <- list(
df_demo,
df_aoi_numb_dur,
df_aoi_stud,
df_ttff_disrup_participant_summary,
df_sri,
df_sjt,
df_quest_summary
)
# Combine all dataframes by Participant
df_merge <- reduce(df_list, full_join, by = "Participant")
# Load required libraries
library(tidyverse)
library(Hmisc)
library(knitr)
library(kableExtra)
# Separate Data by Experience Level
# Experienced teachers (ID > 200)
df_correlation_experienced <- df_merge %>%
filter(Participant > 200) %>%
select(
Number_fixation_min_mtu,
Average_duration_mtu,
GRI,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
SJT_All,
Self_Eval_Overall
) %>%
drop_na()
# Inexperienced teachers (ID < 200)
df_correlation_inexperienced <- df_merge %>%
filter(Participant < 200) %>%
select(
Average_duration_mtu,
Number_fixation_min_mtu,
GRI,
Stud_number_fixation_min,
log_Disrup_time_fixation_sec,
Disruption_Rating,
Confidence_Rating,
Self_Eval_Overall,
SJT_All
) %>%
drop_na()
# Compute Correlations for Experienced Teachers
cor_results_experienced <- rcorr(as.matrix(df_correlation_experienced))
cor_matrix_experienced <- cor_results_experienced$r
p_matrix_experienced <- cor_results_experienced$P
# Compute Correlations for Inexperienced Teachers
cor_results_inexperienced <- rcorr(as.matrix(df_correlation_inexperienced))
cor_matrix_inexperienced <- cor_results_inexperienced$r
p_matrix_inexperienced <- cor_results_inexperienced$P
# Reshape correlation coefficients and p-values into a tidy format for experienced teachers
correlation_pvalues_experienced <- as.data.frame(as.table(cor_matrix_experienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix_experienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%
mutate(
Correlation = round(Correlation, 2),
P_value = round(P_value, 3),
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
)
# Reshape correlation coefficients and p-values into a tidy format for inexperienced teachers
correlation_pvalues_inexperienced <- as.data.frame(as.table(cor_matrix_inexperienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq) %>%
left_join(
as.data.frame(as.table(p_matrix_inexperienced)) %>%
rename(Variable1 = Var1, Variable2 = Var2, P_value = Freq),
by = c("Variable1", "Variable2")
) %>%
filter(Variable1 != Variable2) %>%
mutate(
Correlation = round(Correlation, 2),
P_value = round(P_value, 3),
APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
)
# Create correlation tables for both groups
correlation_table_experienced <- correlation_pvalues_experienced %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(names_from = Variable2, values_from = APA_Format)
correlation_table_inexperienced <- correlation_pvalues_inexperienced %>%
select(Variable1, Variable2, APA_Format) %>%
pivot_wider(names_from = Variable2, values_from = APA_Format)
# Ensure Variable1 is a factor to maintain order
correlation_table_experienced$Variable1 <- factor(correlation_table_experienced$Variable1, levels = unique(correlation_table_experienced$Variable1))
correlation_table_inexperienced$Variable1 <- factor(correlation_table_inexperienced$Variable1, levels = unique(correlation_table_inexperienced$Variable1))
# Convert to flextable for APA formatting
cor_flextable_experienced <- correlation_table_experienced %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 1: Correlation Table for Experienced Teachers (APA Format)")
cor_flextable_inexperienced <- correlation_table_inexperienced %>%
flextable() %>%
theme_booktabs() %>%
autofit() %>%
set_caption("Table 2: Correlation Table for Inexperienced Teachers (APA Format)")
# # 5. Save the table as a Word document --------------------------------------
# doc <- read_docx() %>%
#   body_add_par("Table 1: Correlation Table (APA Format)", style = "heading 1") %>%
#   body_add_par("", style = "Normal") %>%  # Add a blank space before the table
#   body_add_flextable(cor_flextable) %>%
#   body_add_par("", style = "Normal")  # Add blank space after the table
#
# # Save the document
# docx_path <- "Correlation_Table_APA.docx"
# save_as_docx(doc, path = docx_path)
#
#
# # Define the full file path explicitly
# docx_path <- file.path(getwd(), "Correlation_Table_APA.docx")
#
# # Save the document
# save_as_docx(doc, path = docx_path)
# # 4. Correlation Analysis: Experts ---------------------------------------------
#
# # Filter data for Experts (Participants with ID > 200)
# df_experts <- df_merge %>%
#   filter(Participant > 200) %>%
#   select(-Participant)
#
# # Compute correlation coefficients and p-values for Experts
# cor_results_experts <- rcorr(as.matrix(df_experts))
# cor_matrix_experts <- as.data.frame(cor_results_experts$r)  # Extract correlation coefficients
# p_matrix_experts <- as.data.frame(cor_results_experts$P)   # Extract p-values
#
# # Reshape data into tidy format for Experts
# correlation_pvalues_experts <- cor_matrix_experts %>%
#   rownames_to_column(var = "Variable1") %>%
#   pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
#   left_join(
#     p_matrix_experts %>%
#       rownames_to_column(var = "Variable1") %>%
#       pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
#     by = c("Variable1", "Variable2")
#   ) %>%
#   mutate(
#     Correlation = round(Correlation, 2),
#     P_value = round(P_value, 2),
#     APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
#   )
#
# # Create an APA-style table for Experts
# correlation_table_experts <- correlation_pvalues_experts %>%
#   select(Variable1, Variable2, APA_Format) %>%
#   pivot_wider(
#     names_from = Variable2,
#     values_from = APA_Format
#   )
#
# # Display the Experts table
# kable(correlation_table_experts, format = "html", caption = "Correlation Table: Experts") %>%
#   kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
#
#
# # 5. Correlation Analysis: Novices ---------------------------------------------
#
# # Filter data for Novices (Participants with ID < 200)
# df_novices <- df_merge %>%
#   filter(Participant < 200) %>%
#   select(-`Teaching Experience`,
#          -Participant)
#
# # Compute correlation coefficients and p-values for Novices
# cor_results_novices <- rcorr(as.matrix(df_novices))
# cor_matrix_novices <- as.data.frame(cor_results_novices$r)  # Extract correlation coefficients
# p_matrix_novices <- as.data.frame(cor_results_novices$P)   # Extract p-values
#
# # Reshape data into tidy format for Novices
# correlation_pvalues_novices <- cor_matrix_novices %>%
#   rownames_to_column(var = "Variable1") %>%
#   pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
#   left_join(
#     p_matrix_novices %>%
#       rownames_to_column(var = "Variable1") %>%
#       pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
#     by = c("Variable1", "Variable2")
#   ) %>%
#   mutate(
#     Correlation = round(Correlation, 2),
#     P_value = round(P_value, 2),
#     APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
#   )
#
# # Create an APA-style table for Novices
# correlation_table_novices <- correlation_pvalues_novices %>%
#   select(Variable1, Variable2, APA_Format) %>%
#   pivot_wider(
#     names_from = Variable2,
#     values_from = APA_Format
#   )
#
# # Display the Novices table
# kable(correlation_table_novices, format = "html", caption = "Correlation Table: Novices") %>%
#   kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))
cor_flextable_experienced
cor_flextable_inexperienced
cor_flextable_experienced
