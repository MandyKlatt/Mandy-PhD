---
title: "Through the Eyes of the Teacher - Multimodal Exploration of Expertise Differences in the Perception of Classroom Disruptions in a Laboratory Study"
output: 
  html_document:
    toc: true           # Add a table of contents
    number_sections: true
---

```{r include=FALSE}
# install.packages("needs")

# suppress "summarize" info. 
# if this line is ommitted, each table using the summarize function will be accompanied with a warning from the console
options(dplyr.summarise.inform = FALSE)

library(needs)
needs(
  tidyverse,     # A collection of packages (e.g., ggplot2, dplyr, tidyr) for data manipulation, visualization, and general workflows.
  lubridate,     # For working with dates and times (e.g., parsing, manipulation, arithmetic).
  viridis,       # Provides colorblind-friendly color palettes for plots and visualizations.
  grid,          # A base R package for low-level grid graphics, useful for customizing complex plots.
  gridExtra,     # Extends grid by allowing multiple grid-based plots to be arranged into a single layout.
  cowplot,       # Simplifies creating publication-quality multi-panel plots, often combined with ggplot2.
  readxl,        # For reading Excel files (.xls, .xlsx) into R without requiring external dependencies.
  ARTofR,        # For applying aligned rank transform (ART) to factorial data for nonparametric analysis.
  moments,       # Provides functions to compute statistical moments (e.g., skewness, kurtosis).
  ltm,           # Used for latent trait models, including item response theory (IRT) analysis.
  sjPlot,        # A package to create publication-ready tables and visualizations for statistical models.
  kableExtra,    # Enhances the `knitr::kable()` function for producing polished and customizable tables in R Markdown.
  xtable,        # Converts R objects to LaTeX/HTML tables, especially useful for integration with Sweave/knitr.
  DescTools,     # A toolbox of descriptive statistics, effect size calculations, and data manipulation utilities.
  formattable,   # Allows creation of "formattable" data frames with customized formatting for reporting.
  psych,         # Provides tools for psychological research, including reliability analysis and descriptive statistics.
  apaTables,     # Simplifies the creation of APA-style tables for inclusion in papers or reports.
  rstatix,       # User-friendly pipe-compatible functions for common statistical tests and effect sizes.
  effsize,       # Computes effect sizes (e.g., Cohen's d) for t-tests and other statistical comparisons.
  knitr,         # Enables dynamic reporting by weaving R code and outputs into documents (e.g., R Markdown).
  papaja,        # Helps produce APA-style manuscripts directly from R Markdown.
  afex,          # Performs ANOVAs, including mixed-designs and generalized linear models, with a focus on user-friendliness.
  emmeans,       # Computes estimated marginal means (or least-squares means) for post-hoc comparisons in models.
  corrplot       # Visualize correlation matrices in a visually appealing way.
)

```

## Participants
```{r demographicstable, include = TRUE, echo=FALSE}

# Read and process the data
demo_data <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
  filter(!LI06_05 %in% c(201, 223)) %>%
  transmute(
    Group = ifelse(LI06_05 < 200, "Novice", "Expert"),
    Gender = as.numeric(ifelse(LI02_01_1 == 2, "1", "0")),
    Age = LI03_01,
    `Teaching Experience` = LI04_01,
    School_type = factor(
      replace(LI18, LI18 == 2, 1),
      levels = c(1, 3, 4, 5, -1),
      labels = c("Primary School", "Secondary School", "Special Education", "Vocational School", "Other School Type")
    ),
    Semester = as.numeric(LI11_01),
    Internship = LI13_01,
    `Extracurricular Teaching Experience` = as.numeric(ifelse(LI14 == 1, "1", "0")),
    `Secondary Teaching Activities` = as.numeric(ifelse(LI17 == 1, "1", "0"))
  )

# Calculate summaries used across both tables, handling cases where all values are NA
summary_data <- demo_data %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    `Women in %` = ifelse(all(is.na(Gender)), NA, round(mean(Gender, na.rm = TRUE) * 100, 2)),
    `M Age` = ifelse(all(is.na(Age)), NA, round(mean(Age, na.rm = TRUE), 2)),
    `SD Age` = ifelse(all(is.na(Age)), NA, round(sd(Age, na.rm = TRUE), 2)),
    `Min Age` = ifelse(all(is.na(Age)), NA, min(Age, na.rm = TRUE)),
    `Max Age` = ifelse(all(is.na(Age)), NA, max(Age, na.rm = TRUE)),
    `M Teaching Exp.` = ifelse(all(is.na(`Teaching Experience`)), NA, round(mean(`Teaching Experience`, na.rm = TRUE), 2)),
    `SD Teaching Exp.` = ifelse(all(is.na(`Teaching Experience`)), NA, round(sd(`Teaching Experience`, na.rm = TRUE), 2)),
    `Median Teaching Exp.` = ifelse(all(is.na(`Teaching Experience`)), NA, median(`Teaching Experience`, na.rm = TRUE)),
    `Min Teaching Exp.` = ifelse(all(is.na(`Teaching Experience`)), NA, min(`Teaching Experience`, na.rm = TRUE)),
    `Max Teaching Exp.` = ifelse(all(is.na(`Teaching Experience`)), NA, max(`Teaching Experience`, na.rm = TRUE)),
    `M Semester` = ifelse(all(is.na(Semester)), NA, round(mean(Semester, na.rm = TRUE), 2)),
    `SD Semester` = ifelse(all(is.na(Semester)), NA, round(sd(Semester, na.rm = TRUE), 2)),
    `Min Semester` = ifelse(all(is.na(Semester)), NA, min(Semester, na.rm = TRUE)),
    `Max Semester` = ifelse(all(is.na(Semester)), NA, max(Semester, na.rm = TRUE)),
    `M Internship` = ifelse(all(is.na(Internship)), NA, round(mean(Internship, na.rm = TRUE), 2)),
    `SD Internship` = ifelse(all(is.na(Internship)), NA, round(sd(Internship, na.rm = TRUE), 2)),
    `Min Internship` = ifelse(all(is.na(Internship)), NA, min(Internship, na.rm = TRUE)),
    `Max Internship` = ifelse(all(is.na(Internship)), NA, max(Internship, na.rm = TRUE)),
    `Extracurricular Teaching Experience %` = ifelse(all(is.na(`Extracurricular Teaching Experience`)), NA, round(mean(`Extracurricular Teaching Experience`, na.rm = TRUE) * 100, 2)),
    `Secondary Teaching Activities %` = ifelse(all(is.na(`Secondary Teaching Activities`)), NA, round(mean(`Secondary Teaching Activities`, na.rm = TRUE) * 100, 2))
  )

# Separate the tables from the summarized data
demo_table <- summary_data %>%
  select(Group, N, `Women in %`, `M Age`, `SD Age`, `Min Age`, `Max Age`, 
         `M Teaching Exp.`, `SD Teaching Exp.`, `Median Teaching Exp.`, 
         `Min Teaching Exp.`, `Max Teaching Exp.`)

exp_table <- summary_data %>%
  select(Group, N, `M Teaching Exp.`, `SD Teaching Exp.`, `Median Teaching Exp.`, 
         `Min Teaching Exp.`, `Max Teaching Exp.`, `M Semester`, `SD Semester`, 
         `Min Semester`, `Max Semester`, `M Internship`, `SD Internship`, 
         `Min Internship`, `Max Internship`, `Extracurricular Teaching Experience %`, 
         `Secondary Teaching Activities %`)

# Display APA-style HTML tables
demo_table %>%
  kbl(caption = "Demographic Information & Teaching Experience", format = "html") %>%
  kable_styling(full_width = FALSE, position = "center")

exp_table %>%
  kbl(caption = "Experience Details by Group", format = "html") %>%
  kable_styling(full_width = FALSE, position = "center") %>% 
  scroll_box(width = "100%", height = "400px") # Enables scrolling if needed

```

## Measures

### Eye-Tracking Data
```{r eyetracking_read_in_data, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}

# Step 1: List all .tsv files in the "data" folder that contain "interval_complete"
file_names <- list.files(path = "data", pattern = "interval_complete.tsv", full.names = TRUE)

# Step 2: Read and bind all .tsv files into a single tibble
df_aoi <- file_names %>%
  map_dfr(~ read_tsv(.x, locale = locale(decimal_mark = ",")) %>%
            select(
              Group,
              Participant,
              TOI,
              Duration_of_interval,
              Start_of_interval,
              starts_with("Total_duration_of_fixations"),
              starts_with("Average_duration_of_fixations"),
              starts_with("Number_of_fixations"),
              starts_with("Time_to_first_fixation")
            ))

# Step 3: Extract only the participant's ID number (3 digits) and assign group based on Participant ID
df_aoi <- df_aoi %>%
  mutate(
    Participant = as.numeric(str_extract(Participant, "\\d{3}")),
    Group = case_when(  # Assign group based on Participant ID
      Participant > 200 ~ "Expert",
      Participant < 200 ~ "Novice",
      TRUE ~ NA_character_  # In case there's any other value or missing
    )
  )

# Step 4: Exclude invalid participant ID 223
df_aoi <- df_aoi %>%
  filter(Participant != 223)

```

### Check variables

#### Letter search
```{r letter_search, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### LETTER SEARCH #####################
# 1. Filter and Prepare Data for "Letter Search"
df_letter <- df_aoi %>%
  filter(TOI == "Letter_search", !Participant %in% c(111, 205)) %>%  # Exclude participants with IDs 111 and 205
  select(TOI, Group, Participant, Duration_of_interval) %>%
  mutate(Duration_of_interval_sec = round(Duration_of_interval / 1000, 2))

# 2. Descriptive Statistics: N, Mean (M), SD, Min, Max for "Letter Search" Duration
letter_table <- df_letter %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(Duration_of_interval_sec), 2),
    SD = round(sd(Duration_of_interval_sec), 2),
    Min = round(min(Duration_of_interval_sec), 2),
    Max = round(max(Duration_of_interval_sec), 2)
  )

# Display Descriptive Statistics Table in APA Style
knitr::kable(letter_table, caption = "N, M, SD, Min & Max Letter Search Duration (in seconds)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# 3. Conduct t-Test and Calculate Cohen's d for "Letter Search" Duration
t_test_letter <- t.test(
  Duration_of_interval_sec ~ Group,
  data = df_letter,
  var.equal = TRUE
)

# Calculate Cohen's d for the Effect Size
d_letter <- cohen.d(
  Duration_of_interval_sec ~ Group,
  data = df_letter
)

# 4. Format t-Test and Cohen's d Results for APA Table
t_test_result <- data.frame(
  "Group Comparison" = "Experts vs. Novices",
  "t-value" = round(t_test_letter$statistic, 2),
  "df" = t_test_letter$parameter,
  "p-value" = format.pval(t_test_letter$p.value, digits = 2, eps = .05),
  "Mean Difference" = round(t_test_letter$estimate[1] - t_test_letter$estimate[2], 2),
  "Cohen's d" = round(d_letter$estimate, 2),
  "95% CI (d)" = paste0("[", round(d_letter$conf.int[1], 2), ", ", round(d_letter$conf.int[2], 2), "]")
)

# Display t-Test and Effect Size Results in APA Style
knitr::kable(t_test_result, caption = "t-Test and Effect Size for Letter Search Duration (Experts vs. Novices)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

#### Percentage of fixations on each AOI, relative to the total number of fixations during the entire "Lesson" 
```{r nof_percent, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

# Step 1: Define AOI categories
aoi_columns <- list(
  "AOI_Students" = c(
    "Number_of_fixations.Anna",
    "Number_of_fixations.Bianca",
    "Number_of_fixations.Carl(a)"
  ),
  "AOI_Disruptive_Person" = c("Number_of_fixations.Disruptive_Person"),
  "AOI_Teacher_Material" = c(
    "Number_of_fixations.Board_Screen",
    "Number_of_fixations.Material_Teacher"
  ),
  "AOI_Student_Desk" = c(
    "Number_of_fixations.Nametag_Anna",
    "Number_of_fixations.Nametag_Bianca",
    "Number_of_fixations.Nametag_Carl(a)",
    "Number_of_fixations.Material_Students"
  ),
  "AOI_Classroom_Others" = c("Number_of_fixations.Classroom_Others")
)

# Step 2: Filter data for "Lesson" and select relevant columns
df_fixations <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select(Participant, Group, starts_with("Number_of_fixations"))

# Step 3: Calculate total fixations per participant, excluding "Disruptive Person"
# Extract relevant column names excluding "Disruptive Person"
relevant_columns <- unlist(aoi_columns[c("AOI_Students", "AOI_Teacher_Material", "AOI_Student_Desk", "AOI_Classroom_Others")])

# Calculate row sums for the relevant columns and add as a new column
df_fixations <- df_fixations %>%
  mutate(Total_fixations_excluding_disruptive = rowSums(across(all_of(relevant_columns)), na.rm = TRUE))

# Step 4: Calculate fixation percentages for each AOI based on the adjusted total
aoi_percentages <- df_fixations %>%
  rowwise() %>%
  mutate(
    AOI_Students_pct = sum(c_across(any_of(
      aoi_columns$AOI_Students
    )), na.rm = TRUE) / Total_fixations_excluding_disruptive * 100,
    AOI_Disruptive_Person_pct = sum(c_across(
      any_of(aoi_columns$AOI_Disruptive_Person)
    ), na.rm = TRUE) / (
      Total_fixations_excluding_disruptive + sum(c_across(
        any_of(aoi_columns$AOI_Disruptive_Person)
      ), na.rm = TRUE)
    ) * 100,
    AOI_Teacher_Material_pct = sum(c_across(
      any_of(aoi_columns$AOI_Teacher_Material)
    ), na.rm = TRUE) / Total_fixations_excluding_disruptive * 100,
    AOI_Student_Desk_pct = sum(c_across(any_of(
      aoi_columns$AOI_Student_Desk
    )), na.rm = TRUE) / Total_fixations_excluding_disruptive * 100,
    AOI_Classroom_Others_pct = sum(c_across(
      any_of(aoi_columns$AOI_Classroom_Others)
    ), na.rm = TRUE) / Total_fixations_excluding_disruptive * 100
  ) %>%
  ungroup()

# Step 5: Summarize fixation percentages by Group and arrange in descending order
grouped_aoi_percentages <- aoi_percentages %>%
  group_by(Group) %>%
  summarise(
    Mean_AOI_Students_pct = round(mean(AOI_Students_pct, na.rm = TRUE), 2),
    Mean_AOI_Disruptive_Person_pct = round(mean(AOI_Disruptive_Person_pct, na.rm = TRUE), 2),
    Mean_AOI_Teacher_Material_pct = round(mean(AOI_Teacher_Material_pct, na.rm = TRUE), 2),
    Mean_AOI_Student_Desk_pct = round(mean(AOI_Student_Desk_pct, na.rm = TRUE), 2),
    Mean_AOI_Classroom_Others_pct = round(mean(AOI_Classroom_Others_pct, na.rm = TRUE), 2)
  ) %>%
  pivot_longer(cols = starts_with("Mean_AOI"), names_to = "AOI", values_to = "Fixation_Percentage") %>%
  mutate(AOI = recode(AOI,
                      "Mean_AOI_Students_pct" = "Students",
                      "Mean_AOI_Disruptive_Person_pct" = "Disruptive Person",
                      "Mean_AOI_Teacher_Material_pct" = "Teacher Material",
                      "Mean_AOI_Student_Desk_pct" = "Student Desk",
                      "Mean_AOI_Classroom_Others_pct" = "Classroom/Others")) %>%
  arrange(Group, desc(Fixation_Percentage))

# # Step 6: Display the table with APA style
# kable(grouped_aoi_percentages, 
#       col.names = c("AOI", "Expert (%)", "Novice (%)"),
#       caption = "Average Fixation Percentage per AOI by Group (Novice vs. Expert) - Descending Order") %>%
#   kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
#   add_header_above(c(" " = 1, "Fixation Percentage" = 2)) %>%
#   row_spec(0, bold = TRUE) %>%
#   column_spec(2:3, width = "3em", border_left = TRUE) 

# Step 7: Plot with descending AOI order, y-axis limit set to 100%, and percentage labels inside the bars
percentage_number_fixation <-
  ggplot(grouped_aoi_percentages,
         aes(
           x = reorder(AOI, -Fixation_Percentage),
           y = Fixation_Percentage,
           fill = Group
         )) +
  geom_bar(stat = "identity",
           position = position_dodge(width = 0.8),
           width = 0.7) +
  geom_text(
    aes(label = paste0(Fixation_Percentage, "%")),
    position = position_dodge(width = 0.8),
    vjust = -0.3,
    size = 3
  ) +
  labs(title = "Average Fixation Percentage by AOI and Group (Descending Order)", x = "AOI", y = "Fixation Percentage (%)") +
  scale_fill_brewer(palette = "RdBu") +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  guides(fill = guide_legend(title = "Group")) +
  ylim(0, 100)  # Set y-axis limit to 100%

ggsave(filename = "plots/percentage_number_fixation.svg",
       width = 20,
       height = 12,
       units = "cm")

# Step 8: Perform a t-test between Experts and Novices on the percentage values and calculate Cohen's d
# Define the AOIs you want to analyze with names matching those generated in Step 4
aoi_list <- c("AOI_Students_pct", "AOI_Disruptive_Person_pct", "AOI_Teacher_Material_pct", "AOI_Student_Desk_pct", "AOI_Classroom_Others_pct")

# Initialize an empty data frame to store the results
results <- data.frame()

# Loop over each AOI and calculate t-test and Cohen's d
for (column_name in aoi_list) {
  
  # Ensure that the column exists in the data
  if (column_name %in% names(aoi_percentages)) {
    
    # Filter the data for the current AOI and rename the column to Fixation_Percentage for consistency
    aoi_data <- aoi_percentages %>%
      select(Group, !!sym(column_name)) %>%
      rename(Fixation_Percentage = !!sym(column_name))
    
    # Separate data for each group
    expert_data <- aoi_data$Fixation_Percentage[aoi_data$Group == "Expert"]
    novice_data <- aoi_data$Fixation_Percentage[aoi_data$Group == "Novice"]
    
    # Check if both groups have at least one observation
    if (length(expert_data) > 0 && length(novice_data) > 0) {
      
      # Perform a t-test between Experts and Novices on the current AOI's fixation percentage
      t_test_result <- t.test(expert_data, novice_data, var.equal = TRUE)
      
      # Calculate Cohen's d for the current AOI
      cohen_d_value <- cohen.d(expert_data, novice_data, pooled = TRUE)$estimate
      
      # Format the results for the current AOI and add to the results data frame
      results <- rbind(
        results,
        data.frame(
          "AOI" = gsub("_pct", "", column_name),  # Remove "_pct" suffix for readability
          "Group Comparison" = "Experts vs. Novices",
          "t-value" = round(t_test_result$statistic, 2),
          "df" = t_test_result$parameter,
          "p-value" = format.pval(t_test_result$p.value, digits = 2, eps = .05),
          "Mean Difference" = round(t_test_result$estimate[1] - t_test_result$estimate[2], 2),
          "Cohen's d" = round(cohen_d_value, 2),
          "95% CI (d)" = paste0("[", round(t_test_result$conf.int[1], 2), ", ", round(t_test_result$conf.int[2], 2), "]")
        )
      )
      
    } else {
      # If one group has no data, append N/A values for this AOI
      results <- rbind(
        results,
        data.frame(
          "AOI" = gsub("_pct", "", column_name),  # Remove "_pct" suffix for readability
          "Group Comparison" = "Experts vs. Novices",
          "t-value" = NA,
          "df" = NA,
          "p-value" = NA,
          "Mean Difference" = NA,
          "Cohen's d" = NA,
          "95% CI (d)" = NA
        )
      )
    }
  }
}

# Clean up AOI names for readability in the final table
aoi_name_mapping <- c(
  "AOI_Students" = "Students",
  "AOI_Disruptive_Person" = "Disruptive Person",
  "AOI_Teacher_Material" = "Teacher Material",
  "AOI_Student_Desk" = "Student Desk",
  "AOI_Classroom_Others" = "Classroom/Others"
)
results$AOI <- aoi_name_mapping[results$AOI]

# Display the combined results table in APA style without row names
knitr::kable(results, caption = "t-Test and Effect Size for Fixation Percentage across AOIs (Experts vs. Novices)", row.names = FALSE) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

#### Number of fixations per minute (micro-teaching unit)
```{r nof_all, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### NUMBER OF FIXATIONS PER MINUTE IN MICRO-TEACHING UNIT ########################

# 1. Data Preparation: Filter and Calculate Fixations per Minute in Micro-Teaching Unit
df_aoi_sum <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select(
    Group,
    Participant,
    Duration_of_interval,
    starts_with("Total_duration_of_fixations"),
    starts_with("Number_of_fixations"),
    starts_with("Average_duration"),
    -contains("Disruptive_Person")
  ) %>%
  rowwise() %>%
  transmute(
    Group = Group,
    Participant = Participant,
    Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),
    Sum_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
    Sum_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
    Number_fixation_min_mtu = round(Sum_number_fixation / Duration_of_interval_min, 2),
    Group = as_factor(Group)
  ) %>%
  drop_na()

# 2. Descriptive Statistics Table for Number of Fixations per Minute
nof_table <- df_aoi_sum %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(Number_fixation_min_mtu), 2),
    SD = round(sd(Number_fixation_min_mtu), 2),
    Min = round(min(Number_fixation_min_mtu), 2),
    Max = round(max(Number_fixation_min_mtu), 2)
  )

# Display the descriptive table in APA style
knitr::kable(nof_table, caption = "N, M, SD, Min & Max Number of Fixations per Minute (Micro-Teaching Unit)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# 3. Calculate means and standard deviations for Novice and Expert
mean_novice_mtu <- round(mean(df_aoi_sum$Number_fixation_min_mtu[df_aoi_sum$Group == "Novice"], na.rm = TRUE), 2)
sd_novice_mtu <- round(sd(df_aoi_sum$Number_fixation_min_mtu[df_aoi_sum$Group == "Novice"], na.rm = TRUE), 2)
mean_expert_mtu <- round(mean(df_aoi_sum$Number_fixation_min_mtu[df_aoi_sum$Group == "Expert"], na.rm = TRUE), 2)
sd_expert_mtu <- round(sd(df_aoi_sum$Number_fixation_min_mtu[df_aoi_sum$Group == "Expert"], na.rm = TRUE), 2)

# 4. Perform t-test to get the p-value
t_test_mtu <- t.test(
  Number_fixation_min_mtu ~ Group,
  data = df_aoi_sum,
  var.equal = TRUE
)
p_value_mtu <- round(t_test_mtu$p.value, 2)

# 5. Calculate Cohen's d for effect size using formula syntax
library(effsize)
cohen_d_mtu <- round(cohen.d(Number_fixation_min_mtu ~ Group, data = df_aoi_sum)$estimate, 2)

# 6. Plotting the Number of Fixations per Minute (Micro-Teaching Unit)
y_max_mtu <- max(df_aoi_sum$Number_fixation_min_mtu) * 1.5  

plot_number_group <- df_aoi_sum %>%
  ggplot(mapping = aes(x = Group, y = Number_fixation_min_mtu)) +
  geom_boxplot(mapping = aes(fill = Group), outlier.shape = NA, width = 0.5) +
  geom_jitter(
    width = 0.15, height = 0.1, alpha = 0.5, color = "black", size = 1.5
  ) +
  ylim(0, y_max_mtu) +
  labs(x = "", y = "Number of Fixations per Minute") +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Number of Fixations per Minute\n(Micro-Teaching Unit)") +
  theme_cowplot() +
  theme(legend.position = "none") +
  # Annotations for mean (M) and SD using atop() to place SD below M
  annotate("text", x = 1, y = y_max_mtu * 0.85,
           label = paste0("atop(italic(M) == ", mean_novice_mtu, ", italic(SD) == ", sd_novice_mtu, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  annotate("text", x = 2, y = y_max_mtu * 0.85,
           label = paste0("atop(italic(M) == ", mean_expert_mtu, ", italic(SD) == ", sd_expert_mtu, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  # Add p-value and Cohen's d annotations above the boxplots
  annotate("text", x = 1.5, y = y_max_mtu * 0.95,
           label = paste0("p = ", p_value_mtu, "\nd = ", cohen_d_mtu),
           hjust = 0.5, size = 4, fontface = "italic")

plot_number_group

ggsave(filename = "plots/plot_number_group.svg",
       width = 20,
       height = 12,
       units = "cm")

# 7. Format the t-Test and Cohen's d results for APA Table
t_test_result <- data.frame(
  "Group Comparison" = "Experts vs. Novices",
  "t-value" = round(t_test_mtu$statistic, 2),
  "df" = t_test_mtu$parameter,
  "p-value" = format.pval(t_test_mtu$p.value, digits = 2, eps = .05),
  "Mean Difference" = round(t_test_mtu$estimate[1] - t_test_mtu$estimate[2], 2),
  "Cohen's d" = cohen_d_mtu,
  "95% CI (d)" = paste0("[", round(t_test_mtu$conf.int[1], 2), ", ", round(t_test_mtu$conf.int[2], 2), "]")
)

# Display t-Test and Effect Size results in APA style
knitr::kable(t_test_result, caption = "t-Test and Effect Size for Number of Fixations per Minute (Micro-Teaching Unit)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

#### Number of fixations per minute (AOI students)
```{r nof_students, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### NUMBER OF FIXATIONS (AOI STUDENTS) ########################

# 1. Data Preparation: Filter and Calculate Fixations per Minute on AOI Students
df_aoi_stud <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select (
    Group,
    Duration_of_interval,
    Participant,
    "Total_duration_of_fixations.Anna",
    "Total_duration_of_fixations.Bianca",
    "Total_duration_of_fixations.Carl(a)",
    "Number_of_fixations.Anna",
    "Number_of_fixations.Bianca",
    "Number_of_fixations.Carl(a)"
  ) %>%
  rowwise() %>%
  transmute(
    Group = as_factor(Group),
    Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),
    Participant = Participant,
    Stud_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
    Stud_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
    Stud_number_fixation_min = round(Stud_number_fixation / Duration_of_interval_min, 2),
    Stud_number_fixation_sec = round(Stud_number_fixation / Duration_of_interval_sec, 2),
    Average_duration_stud = round(Stud_duration_fixation / Stud_number_fixation, 0)
  ) %>%
  drop_na()

# 2. Descriptive Statistics: N, Mean (M), SD, Min, Max for Fixations per Minute (AOI Students)
nof_min_stud_table <- df_aoi_stud %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(Stud_number_fixation_min), 2),
    SD = round(sd(Stud_number_fixation_min), 2),
    Min = round(min(Stud_number_fixation_min), 2),
    Max = round(max(Stud_number_fixation_min), 2)
  )

# Display Descriptive Statistics Table in APA Style
knitr::kable(nof_min_stud_table, caption = "N, M, SD, Min & Max Number of Fixations per Minute (AOI Students)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# 3. Plotting the Number of Fixations per Minute on AOI Students
# Calculate descriptive statistics
summary_stats <- df_aoi_stud %>%
  group_by(Group) %>%
  summarise(
    M = round(mean(Stud_number_fixation_min), 2),
    SD = round(sd(Stud_number_fixation_min), 2)
  )

# Conduct t-test and calculate effect size
t_test_stud <- t.test(
  Stud_number_fixation_min ~ Group,
  data = df_aoi_stud,
  var.equal = TRUE
)

# Cohen's d for effect size
d_number_stud <- cohen.d(
  Stud_number_fixation_min ~ Group,
  data = df_aoi_stud
)

# Extract statistical values
mean_expert <- summary_stats %>% filter(Group == "Expert") %>% pull(M)
sd_expert <- summary_stats %>% filter(Group == "Expert") %>% pull(SD)
mean_novice <- summary_stats %>% filter(Group == "Novice") %>% pull(M)
sd_novice <- summary_stats %>% filter(Group == "Novice") %>% pull(SD)
p_value <- format.pval(t_test_stud$p.value, digits = 2, eps = .05)
cohen_d <- round(d_number_stud$estimate, 2)

# Determine the maximum y-value for ylim to ensure all data points and annotations are visible
y_max <- max(df_aoi_stud$Stud_number_fixation_min) * 1.5  # Increase the multiplier if needed

# Create the boxplot with jittered data points for better readability
plot_number_min_stud <- df_aoi_stud %>%
  ggplot(mapping = aes(x = Group, y = Stud_number_fixation_min)) +
  geom_boxplot(mapping = aes(fill = Group), outlier.shape = NA, width = 0.5) +
  geom_jitter(
    width = 0.15, height = 0, alpha = 0.6, color = "black", size = 1.2
  ) +
  labs(x = "", y = "Number of fixations per minute") +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Number of fixations per minute\n(AOI students)") +
  theme_cowplot() +
  theme(legend.position = "none") +
  ylim(0, y_max) +  # Adjust y-axis limit to include annotations
  # Annotations for mean (M) and SD using atop() to place SD below M
  annotate("text", x = 1, y = y_max * 0.85,
           label = paste0("atop(italic(M) == ", mean_novice, ", italic(SD) == ", sd_novice, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  annotate("text", x = 2, y = y_max * 0.85,
           label = paste0("atop(italic(M) == ", mean_expert, ", italic(SD) == ", sd_expert, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  # Add p-value and Cohen's d annotations above the boxplots
  annotate("text", x = 1.5, y = y_max * 0.95,
           label = paste0("p = ", p_value, "\nd = ", cohen_d),
           hjust = 0.5, size = 4, fontface = "italic")

# Display the plot
plot_number_min_stud


ggsave(filename = "plots/plot_number_min_stud.svg",
       width = 20,
       height = 12,
       units = "cm")

# 4. t-Test and Effect Size Calculation for Number of Fixations per Minute on AOI Students
t_test_stud <- t.test(
  Stud_number_fixation_min ~ Group,
  data = df_aoi_stud,
  var.equal = TRUE
)

# Calculate Cohen's d for the Effect Size
d_number_stud <- cohen.d(
  Stud_number_fixation_min ~ Group,
  data = df_aoi_stud
)

# 5. Format t-Test and Cohen's d Results for APA Table
t_test_result_stud <- data.frame(
  "Group Comparison" = "Experts vs. Novices",
  "t-value" = round(t_test_stud$statistic, 2),
  "df" = t_test_stud$parameter,
  "p-value" = format.pval(t_test_stud$p.value, digits = 2, eps = .05),
  "Mean Difference" = round(t_test_stud$estimate[1] - t_test_stud$estimate[2], 2),
  "Cohen's d" = round(d_number_stud$estimate, 2),
  "95% CI (d)" = paste0("[", round(d_number_stud$conf.int[1], 2), ", ", round(d_number_stud$conf.int[2], 2), "]")
)

# Display t-Test and Effect Size Results in APA Style
knitr::kable(t_test_result_stud, caption = "t-Test and Effect Size for Number of Fixations per Minute (AOI Students)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
  
```

#### Number of fixations per seconds (AOI disruptive person)
```{r nof_disrup, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### NUMBER OF FIXATIONS ON AOI DISRUPTIVE PERSON ########################

# Define the different types of disruptions and categories
disruptions <- c("Chatting_with_neighbour", "Clicking_pen", "Drawing", 
                 "Drumming_with_hands", "Head_on_table", "Heckling", 
                 "Looking_at_phone", "Snipping_with_fingers", "Whispering")
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")

# Step 1: Filter and prepare the data
df_aoi_disrup <- df_aoi %>%
  filter(TOI %in% disruptions) %>% # Filter rows based on the disruption list
  select(Group, Participant, TOI, Duration_of_interval, "Number_of_fixations.Disruptive_Person") %>%
  mutate(
    Group = as_factor(Group), # Convert Group column to a factor
    Disruption_Category = case_when( # Assign categories based on disruption type
      TOI %in% verbal_disruptions ~ "Verbal disruptions",
      TOI %in% physical_disruptions ~ "Physical disruptions",
      TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    ),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2) # Convert duration to seconds
  ) %>%
  filter(!is.na(Disruption_Category)) # Keep only rows with valid categories

# Step 2: Summarize data by disruption category
disruption_summary <- df_aoi_disrup %>%
  group_by(Group, Participant, Disruption_Category) %>%
  summarise(
    total_duration_sec = round(sum(Duration_of_interval_sec, na.rm = TRUE), 2), # Total time in seconds
    fixation_count = round(sum(`Number_of_fixations.Disruptive_Person`, na.rm = TRUE), 2), # Total fixations
    fixations_per_second = round(fixation_count / total_duration_sec, 2), # Fixation rate per second
    .groups = "drop"
  )

# Step 3: Summarize by participant
individual_summary <- disruption_summary %>%
  group_by(Group, Participant) %>%
  summarise(
    mean_fixations_per_second = round(mean(fixations_per_second, na.rm = TRUE), 2), # Mean fixation rate
    .groups = "drop"
  )

##################### DESCRIPTIVE STATISTICS ########################

# Descriptive statistics for overall fixation rate
overall_stats <- individual_summary %>%
  group_by(Group) %>%
  summarise(
    N = n(), # Number of participants
    Mean = round(mean(mean_fixations_per_second, na.rm = TRUE), 2), # Mean fixation rate
    SD = round(sd(mean_fixations_per_second, na.rm = TRUE), 2), # Standard deviation
    Min = round(min(mean_fixations_per_second, na.rm = TRUE), 2), # Minimum value
    Max = round(max(mean_fixations_per_second, na.rm = TRUE), 2), # Maximum value
    .groups = "drop"
  )

# Display the overall descriptive statistics table
kable(
  overall_stats,
  caption = "Descriptive Statistics (N, Mean, SD, Min, Max) for Overall Fixation Rate by Group",
  col.names = c("Group", "N", "M", "SD", "Min", "Max"),
  row.names = FALSE
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

# Descriptive statistics by disruption category
category_stats <- disruption_summary %>%
  group_by(Disruption_Category, Group) %>%
  summarise(
    N = n_distinct(Participant), # Count unique participants
    Mean = round(mean(fixations_per_second, na.rm = TRUE), 2), # Mean fixation rate
    SD = round(sd(fixations_per_second, na.rm = TRUE), 2), # Standard deviation
    Min = round(min(fixations_per_second, na.rm = TRUE), 2), # Minimum value
    Max = round(max(fixations_per_second, na.rm = TRUE), 2), # Maximum value
    .groups = "drop"
  )

# Display the descriptive statistics table by category
kable(
  category_stats,
  caption = "Descriptive Statistics (N, Mean, SD, Min, Max) for Fixation Rate by Group and Category",
  col.names = c("Group", "Category", "N", "M", "SD", "Min", "Max"),
  row.names = FALSE
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### FIRST PLOT: FIXATION RATE OVERALL ########################

# Calculate values for annotations
mean_novice <- round(mean(individual_summary$mean_fixations_per_second[individual_summary$Group == "Novice"], na.rm = TRUE), 2)
sd_novice <- round(sd(individual_summary$mean_fixations_per_second[individual_summary$Group == "Novice"], na.rm = TRUE), 2)
mean_expert <- round(mean(individual_summary$mean_fixations_per_second[individual_summary$Group == "Expert"], na.rm = TRUE), 2)
sd_expert <- round(sd(individual_summary$mean_fixations_per_second[individual_summary$Group == "Expert"], na.rm = TRUE), 2)

# t-Test and effect size
t_test <- t.test(mean_fixations_per_second ~ Group, data = individual_summary, var.equal = TRUE)
p_value <- round(t_test$p.value, 2)
cohen_d <- round(cohen.d(mean_fixations_per_second ~ Group, data = individual_summary)$estimate, 2)

# Overall fixation rate plot with annotations
y_max_overall <- max(individual_summary$mean_fixations_per_second, na.rm = TRUE) * 1.5
plot_overall_fix_disrup <- ggplot(individual_summary,
          aes(x = Group, y = mean_fixations_per_second, fill = Group)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(
    width = 0.1,
    alpha = 0.7,
    color = "black",
    size = 1.5
  ) +
  labs(x = "", y = "Mean Fixations per Second per Participant") +
  ggtitle("Overall Fixation Rate per Participant\n(AOI Disruptive Person)") +
  scale_fill_brewer(palette = "RdBu") +
  theme_cowplot() +
  ylim(0, y_max_overall) +
  theme(legend.position = "none") +
  annotate(
    "text",
    x = 1,
    y = y_max_overall * 0.85,
    label = paste0("M = ", mean_novice, "\nSD = ", sd_novice),
    hjust = 0.5,
    size = 4,
    fontface = "italic"
  ) +
  annotate(
    "text",
    x = 2,
    y = y_max_overall * 0.85,
    label = paste0("M = ", mean_expert, "\nSD = ", sd_expert),
    hjust = 0.5,
    size = 4,
    fontface = "italic"
  ) +
  annotate(
    "text",
    x = 1.5,
    y = y_max_overall * 0.95,
    label = paste0("p = ", p_value, "\nd = ", cohen_d),
    hjust = 0.5,
    size = 4,
    fontface = "italic"
  )

ggsave(filename = "plots/plot_overall_fix_disrup.svg",
       width = 20,
       height = 12,
       units = "cm")

##################### SECOND PLOT: FIXATION RATE BY CATEGORY ########################

# Create the plot
plot_category_fix_disrup <- disruption_summary %>%
  ggplot(mapping = aes(x = Group, y = fixations_per_second, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(
    size = 2,
    alpha = 0.7,
    position = position_jitter(
      seed = 1,
      width = 0.1,
      height = 0.1
    )
  ) +
  facet_wrap(~Disruption_Category, scales = "fixed", labeller = label_wrap_gen(width = 15)) + # Fixed y-axis across facets
  labs(x = "", y = "Fixations per Second") +
  ggtitle("Fixation Rate by Disruption Category\n(AOI Disruptive Person)") +
  scale_fill_brewer(palette = "RdBu") +
  theme_cowplot() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 10) # Adjust facet text size if necessary
  )

ggsave(filename = "plots/plot_category_fix_disrup.svg",
       width = 24,
       height = 12,
       units = "cm")

# Display the plots
plot_overall_fix_disrup
plot_category

##################### STATISTICAL TESTS ########################

# Table summarizing overall t-test and Cohen's d
overall_effect <- data.frame(
  Group = c("Overall"),
  `t-value` = round(t_test$statistic, 2),
  `p-value` = p_value,
  `Cohen's d` = cohen_d
)

# Display t-test and effect size table
kable(
  overall_effect,
  caption = "Overall t-Test and Effect Size for Fixation Rate",
  col.names = c("Group", "t-value", "p-value", "Cohen's d"),
  row.names = FALSE
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### REPEATED MEASURES ANOVA ########################

# Perform the repeated-measures ANOVA
anova_afex <- afex::aov_ez(
  id = "Participant", # Random effect
  dv = "fixations_per_second", # Dependent variable
  between = "Group", # Between-subject factor
  within = "Disruption_Category", # Within-subject factor
  data = disruption_summary
)

# Extract the ANOVA table
anova_results <- as.data.frame(anova_afex$anova_table)

# Recalculate generalized eta squared (η²)
eta_squared_results <- effectsize::eta_squared(anova_afex, partial = FALSE)

# Combine recalculated eta squared with the ANOVA table
anova_table_apa <- anova_results %>%
  rownames_to_column(var = "Effect") %>% # Move row names to a column
  left_join(
    as.data.frame(eta_squared_results), 
    by = c("Effect" = "Parameter") # Match the correct columns
  ) %>%
  mutate(
    `F` = round(`F`, 2), # Round F-values
    `η²` = round(Eta2, 3), # Round generalized eta squared
    `p-value` = ifelse(
      `Pr(>F)` < 0.05, "< .05", round(`Pr(>F)`, 3) # Format p-values
    )
  ) %>%
  select(Effect, `num Df`, `den Df`, `F`, `p-value`, `η²`) # Order columns, place η² last

# Display the table
kable(
  anova_table_apa,
  caption = "Repeated-Measures ANOVA Results (Including Effect Sizes)",
  col.names = c("Effect", "Df1", "Df2", "F", "p", "η²"),
  digits = 2
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### POST-HOC TESTS ########################

# Perform post-hoc pairwise comparisons for Disruption_Category (within-subject factor)
post_hoc_disruption <- emmeans(anova_afex, pairwise ~ Disruption_Category)

# Extract post-hoc pairwise contrasts for Disruption_Category
post_hoc_results_disruption <- as.data.frame(post_hoc_disruption$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison), # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))
  )

##################### COHEN'S D CALCULATION ########################

# Define the disruption categories
categories <- c("Lack of eagerness to learn", "Physical disruptions", "Verbal disruptions")

# Initialize an empty list to store the Cohen's d values
cohen_d_values <- vector("list", length = nrow(post_hoc_results_disruption))

# Loop over the post-hoc results to calculate Cohen's d for each comparison
for (i in 1:nrow(post_hoc_results_disruption)) {
  # Extract the two categories being compared
  group1 <- strsplit(post_hoc_results_disruption$Comparison[i], " - ")[[1]][1]
  group2 <- strsplit(post_hoc_results_disruption$Comparison[i], " - ")[[1]][2]
  
  # Get the data for the two groups being compared using fixations_per_second
  group1_data <- disruption_summary$fixations_per_second[disruption_summary$Disruption_Category == group1]
  group2_data <- disruption_summary$fixations_per_second[disruption_summary$Disruption_Category == group2]
  
  # Calculate the means and standard deviations for each group
  mean1 <- mean(group1_data, na.rm = TRUE)
  mean2 <- mean(group2_data, na.rm = TRUE)
  
  sd1 <- sd(group1_data, na.rm = TRUE)
  sd2 <- sd(group2_data, na.rm = TRUE)
  
  # Calculate the pooled standard deviation
  pooled_sd <- sqrt(((length(group1_data) - 1) * sd1^2 + (length(group2_data) - 1) * sd2^2) / (length(group1_data) + length(group2_data) - 2))
  
  # Calculate Cohen's d using the formula (mean difference / pooled SD)
  d_value <- (mean1 - mean2) / pooled_sd
  
  # Store the absolute value of Cohen's d
  cohen_d_values[[i]] <- abs(round(d_value, 2))  # Take the absolute value of Cohen's d
}

# Add the Cohen's d values to the post-hoc results
post_hoc_results_disruption$Cohen_d <- unlist(cohen_d_values)

##################### TABLE FOR DISRUPTION CATEGORY ########################

# Ensure the number of column names matches the number of columns in the data frame
post_hoc_results_disruption <- post_hoc_results_disruption %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)

# Displaying the table
knitr::kable(
  post_hoc_results_disruption,
  caption = "Post-Hoc Pairwise Comparisons for Disruption Categories (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# # effect size for category differences
# d_fix_disrup <- CohenD(
#   x = disruption_summary$fixations_per_second[disruption_summary$Disruption_Category == "Lack of eagerness to learn"],
#   y = disruption_summary$fixations_per_second[disruption_summary$Disruption_Category == "Verbal disruptions"],
#   na.rm = TRUE
# )
# 
# round(d_fix_disrup, 2) 

```

### Duration of disruption
```{r dur_disrup, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### DATA PREPARATION ########################

# Prepare data for analysis: filter, calculate, and categorize disruptions
df_aoi_disrup <- df_aoi %>%
  filter(TOI %in% disruptions, Duration_of_interval <= 30000) %>%
  select(Group, Participant, TOI, Duration_of_interval) %>%
  mutate(
    Group = as_factor(Group),
    Disruption_Category = case_when(
      TOI %in% verbal_disruptions ~ "Verbal disruptions",
      TOI %in% physical_disruptions ~ "Physical disruptions",
      TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    ),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2)
  ) %>%
  filter(!is.na(Disruption_Category)) %>%
  drop_na()

##################### DESCRIPTIVE STATISTICS ########################

# Descriptive Statistics by Group
summary_stats_group <- df_aoi_disrup %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    Mean = round(mean(Duration_of_interval_sec, na.rm = TRUE), 2),
    SD = round(sd(Duration_of_interval_sec, na.rm = TRUE), 2),
    Median = round(median(Duration_of_interval_sec, na.rm = TRUE), 2),
    IQR = round(IQR(Duration_of_interval_sec, na.rm = TRUE), 2),
    Min = round(min(Duration_of_interval_sec, na.rm = TRUE), 2),
    Max = round(max(Duration_of_interval_sec, na.rm = TRUE), 2),
    .groups = "drop"
  )

# Descriptive Statistics by Category and Group
summary_stats_category_group <- df_aoi_disrup %>%
  group_by(Disruption_Category, Group) %>%
  summarise(
    N = n(),
    Mean = round(mean(Duration_of_interval_sec, na.rm = TRUE), 2),
    SD = round(sd(Duration_of_interval_sec, na.rm = TRUE), 2),
    Median = round(median(Duration_of_interval_sec, na.rm = TRUE), 2),
    IQR = round(IQR(Duration_of_interval_sec, na.rm = TRUE), 2),
    Min = round(min(Duration_of_interval_sec, na.rm = TRUE), 2),
    Max = round(max(Duration_of_interval_sec, na.rm = TRUE), 2),
    .groups = "drop"
  )

# Display Descriptive Tables
kable(
  summary_stats_group,
  caption = "Descriptive Statistics for Disruption Duration by Group",
  col.names = c("Group", "N", "Mean", "SD", "Median", "IQR", "Min", "Max"),
  row.names = FALSE
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

kable(
  summary_stats_category_group,
  caption = "Descriptive Statistics for Disruption Duration by Category and Group",
  col.names = c("Category", "Group", "N", "Mean", "SD", "Median", "IQR", "Min", "Max"),
  row.names = FALSE
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### PLOTS ########################

# Plot 1: Disruption Duration by Group
plot_duration_group <- ggplot(df_aoi_disrup, aes(x = Group, y = Duration_of_interval_sec, fill = Group)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1.5) +
  labs(x = "Group", y = "Disruption Duration (seconds)") +
  theme_cowplot() +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Disruption Duration by Group") +
  theme(legend.position = "none") +
  annotate("text", x = 1, y = max(df_aoi_disrup$Duration_of_interval_sec) + 4,
           label = paste0("Median = ", summary_stats_group$Median[summary_stats_group$Group == "Novice"],
                          "\nIQR = ", summary_stats_group$IQR[summary_stats_group$Group == "Novice"]),
           hjust = 0.5, size = 4) +
  annotate("text", x = 2, y = max(df_aoi_disrup$Duration_of_interval_sec) + 4,
           label = paste0("Median = ", summary_stats_group$Median[summary_stats_group$Group == "Expert"],
                          "\nIQR = ", summary_stats_group$IQR[summary_stats_group$Group == "Expert"]),
           hjust = 0.5, size = 4)

plot_duration_group

ggsave(filename = "plots/plot_duration_group.svg",
       width = 20,
       height = 12,
       units = "cm")


# Plot 2: Disruption Duration by Group and Category
plot_duration_category <- ggplot(df_aoi_disrup, aes(x = Group, y = Duration_of_interval_sec, fill = Group)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1.5) +
  facet_wrap(~Disruption_Category, scales = "fixed", labeller = label_wrap_gen(width = 15)) +  # Use fixed scale for all facets
  labs(x = "Group", y = "Disruption Duration (seconds)") +
  theme_cowplot() +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Disruption Duration by Group and Category") +
  theme(legend.position = "none")

# Display the plot
plot_duration_category

ggsave(filename = "plots/plot_duration_category.svg",
       width = 24,
       height = 12,
       units = "cm")


##################### STATISTICAL TESTS ########################

##################### REPEATED MEASURES ANOVA ########################

# Perform the repeated-measures ANOVA with `Duration_of_interval_sec` as the dependent variable
anova_afex_duration <- afex::aov_ez(
  id = "Participant",  # Random effect
  dv = "Duration_of_interval_sec",  # Dependent variable: disruption duration in seconds
  between = "Group",  # Between-subject factor: Group (Novice vs Expert)
  within = "Disruption_Category",  # Within-subject factor: Disruption Categories
  data = df_aoi_disrup
)

# Extract the ANOVA table
anova_results_duration <- as.data.frame(anova_afex_duration$anova_table)

# Recalculate generalized eta squared (η²) for effect size
eta_squared_results_duration <- effectsize::eta_squared(anova_afex_duration, partial = FALSE)

# Combine recalculated eta squared with the ANOVA table
anova_table_apa_duration <- anova_results_duration %>%
  rownames_to_column(var = "Effect") %>%  # Move row names to a column
  left_join(
    as.data.frame(eta_squared_results_duration), 
    by = c("Effect" = "Parameter")  # Match the correct columns
  ) %>%
  mutate(
    `F` = round(`F`, 2),  # Round F-values
    `η²` = round(Eta2, 3),  # Round generalized eta squared
    `p-value` = ifelse(
      `Pr(>F)` < 0.05, "< .05", round(`Pr(>F)`, 3)  # Format p-values
    )
  ) %>%
  select(Effect, `num Df`, `den Df`, `F`, `p-value`, `η²`)  # Order columns, place η² last

# Display the ANOVA table
kable(
  anova_table_apa_duration,
  caption = "Repeated-Measures ANOVA Results for Disruption Duration (Including Effect Sizes)",
  col.names = c("Effect", "Df1", "Df2", "F", "p", "η²"),
  digits = 2
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### POST-HOC TESTS Disruption_Category (main effect) ########################

# Perform post-hoc pairwise comparisons for Disruption_Category (main effect)
post_hoc_disruption <- emmeans(anova_afex, pairwise ~ Disruption_Category)

# Extract post-hoc pairwise contrasts for Disruption_Category (main effect)
post_hoc_results_disruption <- as.data.frame(post_hoc_disruption$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison), # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))
  )

##################### COHEN'S D CALCULATION ########################

# Initialize empty lists to store Cohen's d values for both post-hoc tests
cohen_d_values_disruption <- vector("list", length = nrow(post_hoc_results_disruption))

# Loop over the post-hoc results for Disruption_Category to calculate Cohen's d for each comparison (main effect)
for (i in 1:nrow(post_hoc_results_disruption)) {
  # Extract the two categories being compared
  group1 <- strsplit(post_hoc_results_disruption$Comparison[i], " - ")[[1]][1]
  group2 <- strsplit(post_hoc_results_disruption$Comparison[i], " - ")[[1]][2]
  
  # Get the data for the two groups being compared using Duration_of_interval_sec
  group1_data <- df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Disruption_Category == group1]
  group2_data <- df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Disruption_Category == group2]
  
  # Calculate the means and standard deviations for each group
  mean1 <- mean(group1_data, na.rm = TRUE)
  mean2 <- mean(group2_data, na.rm = TRUE)
  
  sd1 <- sd(group1_data, na.rm = TRUE)
  sd2 <- sd(group2_data, na.rm = TRUE)
  
  # Calculate the pooled standard deviation
  pooled_sd <- sqrt(((length(group1_data) - 1) * sd1^2 + (length(group2_data) - 1) * sd2^2) / (length(group1_data) + length(group2_data) - 2))
  
  # Calculate Cohen's d using the formula (mean difference / pooled SD)
  d_value <- (mean1 - mean2) / pooled_sd
  
  # Store the absolute value of Cohen's d
  cohen_d_values_disruption[[i]] <- abs(round(d_value, 2))  # Take the absolute value of Cohen's d
}


# Add the Cohen's d values to the post-hoc results
post_hoc_results_disruption$Cohen_d <- unlist(cohen_d_values_disruption)


##################### TABLE FOR DISRUPTION CATEGORY ########################

# Ensure the number of column names matches the number of columns in the data frame
post_hoc_results_disruption <- post_hoc_results_disruption %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)

# Displaying the post-hoc results for Disruption Category (main effect)
knitr::kable(
  post_hoc_results_disruption,
  caption = "Post-Hoc Pairwise Comparisons for Disruption Categories (Main Effect)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


#################### POST-HOC TESTS interaction effect (Group:Disruption_Category) ########################

# Calculate post-hoc pairwise comparisons for the interaction effect (Group:Disruption_Category)
post_hoc_interaction <- emmeans(anova_afex, pairwise ~ Group * Disruption_Category)

# Extract the post-hoc contrasts for the interaction
post_hoc_results_interaction <- as.data.frame(post_hoc_interaction$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison), # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))  # Round p-values to 2 decimals
  )

##################### COHEN'S D CALCULATION ########################

# 1. Novice Lack of eagerness to learn vs Expert Lack of eagerness to learn
d_LackOfEagerness_Novice_vs_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  na.rm = TRUE
)

# 2. Novice Lack of eagerness to learn vs Novice Physical disruptions
d_LackOfEagerness_vs_Physical_Novice <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

# 3. Novice Lack of eagerness to learn vs Expert Physical disruptions
d_LackOfEagerness_vs_Physical_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

# 4. Novice Lack of eagerness to learn vs Novice Verbal disruptions
d_LackOfEagerness_vs_Verbal_Novice <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 5. Novice Lack of eagerness to learn vs Expert Verbal disruptions
d_LackOfEagerness_vs_Verbal_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 6. Expert Lack of eagerness to learn vs Novice Physical disruptions
d_Expert_LackOfEagerness_vs_Physical_Novice <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

# 7. Expert Lack of eagerness to learn vs Expert Physical disruptions
d_Expert_LackOfEagerness_vs_Physical_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

# 8. Expert Lack of eagerness to learn vs Novice Verbal disruptions
d_Expert_LackOfEagerness_vs_Verbal_Novice <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 9. Expert Lack of eagerness to learn vs Expert Verbal disruptions
d_Expert_LackOfEagerness_vs_Verbal_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 10. Novice Physical disruptions vs Expert Physical disruptions
d_Physical_Novice_vs_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

# 11. Novice Physical disruptions vs Novice Verbal disruptions
d_Physical_Novice_vs_Verbal_Novice <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 12. Novice Physical disruptions vs Expert Verbal disruptions
d_Physical_Novice_vs_Verbal_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 13. Expert Physical disruptions vs Novice Verbal disruptions
d_Physical_Expert_vs_Verbal_Novice <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 14. Expert Physical disruptions vs Expert Verbal disruptions
d_Physical_Expert_vs_Verbal_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Physical disruptions"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# 15. Novice Verbal disruptions vs Expert Verbal disruptions
d_Verbal_Novice_vs_Expert <- CohenD(
  x = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Novice" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  y = df_aoi_disrup$Duration_of_interval_sec[df_aoi_disrup$Group == "Expert" & df_aoi_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

##################### CREATE A NAMED VECTOR FOR COHEN'S D ########################

# Create a named vector with the correct Cohen's d values
cohen_d_values_interaction <- c(
  "Novice Lack of eagerness to learn - Expert Lack of eagerness to learn" = round(d_LackOfEagerness_Novice_vs_Expert, 2),
  "Novice Lack of eagerness to learn - Novice Physical disruptions" = round(d_LackOfEagerness_vs_Physical_Novice, 2),
  "Novice Lack of eagerness to learn - Expert Physical disruptions" = round(d_LackOfEagerness_vs_Physical_Expert, 2),
  "Novice Lack of eagerness to learn - Novice Verbal disruptions" = round(d_LackOfEagerness_vs_Verbal_Novice, 2),
  "Novice Lack of eagerness to learn - Expert Verbal disruptions" = round(d_LackOfEagerness_vs_Verbal_Expert, 2),
  "Expert Lack of eagerness to learn - Novice Physical disruptions" = round(d_Expert_LackOfEagerness_vs_Physical_Novice, 2),
  "Expert Lack of eagerness to learn - Expert Physical disruptions" = round(d_Expert_LackOfEagerness_vs_Physical_Expert, 2),
  "Expert Lack of eagerness to learn - Novice Verbal disruptions" = round(d_Expert_LackOfEagerness_vs_Verbal_Novice, 2),
  "Expert Lack of eagerness to learn - Expert Verbal disruptions" = round(d_Expert_LackOfEagerness_vs_Verbal_Expert, 2),
  "Novice Physical disruptions - Expert Physical disruptions" = round(d_Physical_Novice_vs_Expert, 2),
  "Novice Physical disruptions - Novice Verbal disruptions" = round(d_Physical_Novice_vs_Verbal_Novice, 2),
  "Novice Physical disruptions - Expert Verbal disruptions" = round(d_Physical_Novice_vs_Verbal_Expert, 2),
  "Expert Physical disruptions - Novice Verbal disruptions" = round(d_Physical_Expert_vs_Verbal_Novice, 2),
  "Expert Physical disruptions - Expert Verbal disruptions" = round(d_Physical_Expert_vs_Verbal_Expert, 2),
  "Novice Verbal disruptions - Expert Verbal disruptions" = round(d_Verbal_Novice_vs_Expert, 2)
)

##################### ADD COHEN'S D VALUES TO THE POST-HOC RESULTS ########################

# Add Cohen's d values to the post-hoc results for each comparison
post_hoc_results_interaction$Cohen_d <- cohen_d_values_interaction[post_hoc_results_interaction$Comparison]

##################### TABLE FOR INTERACTION EFFECT ########################

# Ensure the number of column names matches the number of columns in the data frame
post_hoc_results_interaction <- post_hoc_results_interaction %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)

# Display the post-hoc results for Group x Disruption_Category interaction with Cohen's d
knitr::kable(
  post_hoc_results_interaction,
  caption = "Post-Hoc Pairwise Comparisons for Group x Disruption Category Interaction (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


# 
# # 1. Normality Tests (Shapiro-Wilk)
# # The Shapiro-Wilk test is used to assess whether the data for each group (Novice and Expert) follows a normal distribution.
# normality_tests <- df_aoi_disrup %>%
#   group_by(Group) %>%  # Group data by "Group" (Novice and Expert)
#   summarise(
#     Shapiro_Wilk_p = round(shapiro.test(Duration_of_interval_sec)$p.value, 3),  # Perform Shapiro-Wilk test for normality and round the p-value
#     .groups = "drop"  # Drop the grouping after summarizing
#   )
# 
# # The p-value here is extremely small (0), which indicates that both the "Novice" and "Expert" groups deviate significantly from a normal distribution. This suggests that the data in both groups are not normally distributed, and therefore, non-parametric tests like the Mann-Whitney U test are more appropriate for analyzing differences between these groups.
# 
# # Display the Shapiro-Wilk test results in a nicely formatted table
# kable(
#   normality_tests,  # Table with Shapiro-Wilk p-values for each group
#   caption = "Shapiro-Wilk Test for Normality by Group",  # Caption for the table
#   col.names = c("Group", "Shapiro-Wilk p-value"),  # Column names
#   row.names = FALSE  # Don't show row names
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)  # Style the table with a striped pattern
# 
# # 2. Mann-Whitney U-Test and Effect Size
# # The Mann-Whitney U test is used to compare the duration of disruption between the Novice and Expert groups
# # This is a non-parametric test used when the data is not normally distributed (based on the Shapiro-Wilk test results).
# mann_whitney_test <- wilcox.test(Duration_of_interval_sec ~ Group, data = df_aoi_disrup, exact = FALSE)
# 
# # Calculate Effect Size (r) for the Mann-Whitney U test
# # Formula for r: r = |W - (n1 * n2 / 2)| / sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
# n1 <- nrow(df_aoi_disrup %>% filter(Group == "Novice"))  # Number of Novice participants
# n2 <- nrow(df_aoi_disrup %>% filter(Group == "Expert"))  # Number of Expert participants
# r_effect <- abs(mann_whitney_test$statistic - (n1 * n2 / 2)) / sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
# 
# # Create a data frame with the Mann-Whitney U test results, including the test statistic, p-value, and effect size
# mann_whitney_results <- data.frame(
#   "Test" = "Mann-Whitney U",  # Test name
#   "W" = round(mann_whitney_test$statistic, 2),  # Test statistic (W)
#   "p-value" = round(mann_whitney_test$p.value, 3),  # p-value from the test
#   "Effect Size (r)" = round(r_effect, 3)  # Effect size (r) rounded to 3 decimals
# )
# 
# # Explanation: The Mann-Whitney U test is a non-parametric test used to compare differences between two independent groups (in this case, Novices and Experts). It is used because the data is not normally distributed, as indicated by the Shapiro-Wilk test. 
# # p-value: A p-value of 0.879 is much larger than the common significance threshold of 0.05. This means there is no significant difference between the Novice and Expert groups in terms of the disruption duration.
# # Effect size (r): The effect size value of 0.152 suggests a small effect. This confirms that even though the test was not significant, there was still a small effect observed, but it's not large enough to be practically meaningful.
# 
# 
# # Display the Mann-Whitney U test results in a formatted table
# kable(
#   mann_whitney_results,
#   caption = "Mann-Whitney U-Test Results for Disruption Duration",  # Table caption
#   row.names = FALSE  # Don't show row names
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)  # Apply striped styling to the table
# 
# # 3. Kruskal-Wallis Test and Pairwise Comparisons
# # The Kruskal-Wallis test is a non-parametric test to compare multiple groups (Disruption Categories) at once.
# # It tests whether the distributions of disruption duration across categories are equal.
# kruskal_test <- kruskal.test(Duration_of_interval_sec ~ Disruption_Category, data = df_aoi_disrup)
# 
# # Create a data frame with the Kruskal-Wallis test results, including Chi-squared statistic, degrees of freedom, and p-value
# kruskal_results <- data.frame(
#   "Test" = "Kruskal-Wallis",  # Test name
#   "Chi-squared" = round(kruskal_test$statistic, 2),  # Chi-squared statistic from the test
#   "df" = kruskal_test$parameter,  # Degrees of freedom (df)
#   "p-value" = round(kruskal_test$p.value, 3)  # p-value from the test
# )
# 
# # Explanation: The Kruskal-Wallis test is a non-parametric test used to compare more than two independent groups (in this case, different types of disruptions). It is used when the assumption of normality is not met (as in the Shapiro-Wilk test).
# # p-value: A p-value of 0 indicates a highly significant difference between the disruption categories (i.e., "Verbal disruptions", "Physical disruptions", and "Lack of eagerness to learn"). This suggests that there is a significant difference in disruption duration among these categories.
# # Chi-squared: The large value of 145.07 supports this conclusion, indicating a strong effect in terms of the differences between disruption categories.
# 
# # Display the Kruskal-Wallis test results in a formatted table
# kable(
#   kruskal_results,
#   caption = "Kruskal-Wallis Test Results for Differences Between Disruption Categories",  # Table caption
#   row.names = FALSE  # Don't show row names
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)  # Apply striped styling to the table
# 
# # 4. Pairwise Wilcoxon test with Bonferroni correction
# # The pairwise Wilcoxon test is a non-parametric test used for multiple comparisons between pairs of disruption categories.
# # The p-values are adjusted for multiple comparisons using the Bonferroni correction to control for type I error.
# pairwise_wilcox <- pairwise.wilcox.test(
#   x = df_aoi_disrup$Duration_of_interval_sec,  # The dependent variable (Duration of Interval)
#   g = df_aoi_disrup$Disruption_Category,  # The grouping factor (Disruption Category)
#   p.adjust.method = "bonferroni"  # Adjust p-values using the Bonferroni method
# )
# 
# # Extract the p-values from the pairwise Wilcoxon test results and round to 3 decimal places
# pairwise_results <- as.data.frame(pairwise_wilcox$p.value) %>%
#   mutate(across(everything(), ~ round(., 3)))  # Round p-values to 3 decimals
# 
# # Display the pairwise Wilcoxon test results (with Bonferroni correction) in a formatted table
# kable(
#   pairwise_results,
#   caption = "Pairwise Wilcoxon Test Results (Bonferroni Corrected)",  # Table caption
#   row.names = TRUE  # Display row names
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)  # Apply striped styling to the table

```

#### Percentage of fixation durations on each AOI, relative to the total duration of fixations during the entire "Lesson" 
```{r dur_fix_percent, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

# Step 1: Define AOI categories with correct column names for fixation duration
aoi_columns <- list(
  "AOI_Students" = c(
    "Total_duration_of_fixations.Anna",
    "Total_duration_of_fixations.Bianca",
    "Total_duration_of_fixations.Carl(a)"
  ),
  "AOI_Disruptive_Person" = c("Total_duration_of_fixations.Disruptive_Person"),
  "AOI_Teacher_Material" = c(
    "Total_duration_of_fixations.Board_Screen",
    "Total_duration_of_fixations.Material_Teacher"
  ),
  "AOI_Student_Desk" = c(
    "Total_duration_of_fixations.Nametag_Anna",
    "Total_duration_of_fixations.Nametag_Bianca",
    "Total_duration_of_fixations.Nametag_Carl(a)",
    "Total_duration_of_fixations.Material_Students"
  ),
  "AOI_Classroom_Others" = c("Total_duration_of_fixations.Classroom_Others")
)

# Step 2: Filter data for "Lesson" and select relevant columns for fixation duration
df_durations <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select(Participant, Group, starts_with("Total_duration_of_fixations"))

# Step 3: Calculate total fixation duration per participant, excluding "Disruptive Person"
relevant_columns <- unlist(aoi_columns[c("AOI_Students", "AOI_Teacher_Material", "AOI_Student_Desk", "AOI_Classroom_Others")])

df_durations <- df_durations %>%
  mutate(Total_duration_excluding_disruptive = rowSums(across(all_of(relevant_columns)), na.rm = TRUE))

# Step 4: Calculate fixation duration percentages for each AOI based on the adjusted total duration
aoi_durations_percentages <- df_durations %>%
  rowwise() %>%
  mutate(
    AOI_Students_pct = sum(c_across(any_of(aoi_columns$AOI_Students)), na.rm = TRUE) / Total_duration_excluding_disruptive * 100,
    AOI_Disruptive_Person_pct = sum(c_across(any_of(aoi_columns$AOI_Disruptive_Person)), na.rm = TRUE) / (
      Total_duration_excluding_disruptive + sum(c_across(any_of(aoi_columns$AOI_Disruptive_Person)), na.rm = TRUE)
    ) * 100,
    AOI_Teacher_Material_pct = sum(c_across(any_of(aoi_columns$AOI_Teacher_Material)), na.rm = TRUE) / Total_duration_excluding_disruptive * 100,
    AOI_Student_Desk_pct = sum(c_across(any_of(aoi_columns$AOI_Student_Desk)), na.rm = TRUE) / Total_duration_excluding_disruptive * 100,
    AOI_Classroom_Others_pct = sum(c_across(any_of(aoi_columns$AOI_Classroom_Others)), na.rm = TRUE) / Total_duration_excluding_disruptive * 100
  ) %>%
  ungroup()

# Step 5: Summarize fixation duration percentages by Group and arrange in descending order
grouped_aoi_durations_percentages <- aoi_durations_percentages %>%
  group_by(Group) %>%
  summarise(
    Mean_AOI_Students_pct = round(mean(AOI_Students_pct, na.rm = TRUE), 2),
    Mean_AOI_Disruptive_Person_pct = round(mean(AOI_Disruptive_Person_pct, na.rm = TRUE), 2),
    Mean_AOI_Teacher_Material_pct = round(mean(AOI_Teacher_Material_pct, na.rm = TRUE), 2),
    Mean_AOI_Student_Desk_pct = round(mean(AOI_Student_Desk_pct, na.rm = TRUE), 2),
    Mean_AOI_Classroom_Others_pct = round(mean(AOI_Classroom_Others_pct, na.rm = TRUE), 2)
  ) %>%
  pivot_longer(cols = starts_with("Mean_AOI"), names_to = "AOI", values_to = "Duration_Percentage") %>%
  mutate(AOI = recode(AOI,
                      "Mean_AOI_Students_pct" = "Students",
                      "Mean_AOI_Disruptive_Person_pct" = "Disruptive Person",
                      "Mean_AOI_Teacher_Material_pct" = "Teacher Material",
                      "Mean_AOI_Student_Desk_pct" = "Student Desk",
                      "Mean_AOI_Classroom_Others_pct" = "Classroom/Others")) %>%
  arrange(Group, desc(Duration_Percentage))

# Step 6: Plot the fixation duration percentages by AOI and Group
percentage_duration_fixation <- ggplot(
  grouped_aoi_durations_percentages,
  aes(
    x = reorder(AOI, -Duration_Percentage),
    y = Duration_Percentage,
    fill = Group
  )
) +
  geom_bar(stat = "identity",
           position = position_dodge(width = 0.8),
           width = 0.7) +
  geom_text(
    aes(label = paste0(Duration_Percentage, "%")),
    position = position_dodge(width = 0.8),
    vjust = -0.3,
    size = 3
  ) +
  labs(title = "Total Fixation Duration Percentage by AOI and Group (Descending Order)", x = "AOI", y = "Fixation Duration Percentage (%)") +
  scale_fill_brewer(palette = "RdBu") +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  guides(fill = guide_legend(title = "Group")) +
  ylim(0, 100)  # Set y-axis limit to 100%

ggsave(
  filename = "plots/percentage_duration_fixation.svg",
  width = 24,
  height = 12,
  units = "cm"
)

# Step 7: Perform a t-test between Experts and Novices on the duration percentages and calculate Cohen's d
aoi_list <- c("AOI_Students_pct", "AOI_Disruptive_Person_pct", "AOI_Teacher_Material_pct", "AOI_Student_Desk_pct", "AOI_Classroom_Others_pct")
results <- data.frame()

for (column_name in aoi_list) {
  if (column_name %in% names(aoi_durations_percentages)) {
    aoi_data <- aoi_durations_percentages %>%
      select(Group, !!sym(column_name)) %>%
      rename(Duration_Percentage = !!sym(column_name))
    
    expert_data <- aoi_data$Duration_Percentage[aoi_data$Group == "Expert"]
    novice_data <- aoi_data$Duration_Percentage[aoi_data$Group == "Novice"]
    
    if (length(expert_data) > 0 && length(novice_data) > 0) {
      t_test_result <- t.test(expert_data, novice_data, var.equal = TRUE)
      cohen_d_value <- cohen.d(expert_data, novice_data, pooled = TRUE)$estimate
      
      results <- rbind(
        results,
        data.frame(
          "AOI" = gsub("_pct", "", column_name),
          "Group Comparison" = "Experts vs. Novices",
          "t-value" = round(t_test_result$statistic, 2),
          "df" = t_test_result$parameter,
          "p-value" = format.pval(t_test_result$p.value, digits = 2, eps = .05),
          "Mean Difference" = round(t_test_result$estimate[1] - t_test_result$estimate[2], 2),
          "Cohen's d" = round(cohen_d_value, 2),
          "95% CI (d)" = paste0("[", round(t_test_result$conf.int[1], 2), ", ", round(t_test_result$conf.int[2], 2), "]")
        )
      )
    } else {
      results <- rbind(
        results,
        data.frame(
          "AOI" = gsub("_pct", "", column_name),
          "Group Comparison" = "Experts vs. Novices",
          "t-value" = NA,
          "df" = NA,
          "p-value" = NA,
          "Mean Difference" = NA,
          "Cohen's d" = NA,
          "95% CI (d)" = NA
        )
      )
    }
  }
}

# Map AOI names to clean versions for readability in the final results table
results$AOI <- recode(results$AOI,
                      "AOI_Students" = "Students",
                      "AOI_Disruptive_Person" = "Disruptive Person",
                      "AOI_Teacher_Material" = "Teacher Material",
                      "AOI_Student_Desk" = "Student Desk",
                      "AOI_Classroom_Others" = "Classroom/Others")

# Display the t-Test and Effect Size table in APA style
knitr::kable(results, 
             caption = "t-Test and Effect Size for Fixation Duration Percentage across AOIs (Experts vs. Novices)", 
             row.names = FALSE) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```


#### Average duration of fixations in milliseconds (micro-teaching unit)
```{r dur_all, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### AVERAGE FIXATION DURATION ANALYSIS ########################

# 1. Data Preparation: Filter and Calculate Average Fixation Duration in the Micro-Teaching Unit
df_aoi_sum <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select(
    Group,
    Participant,
    Duration_of_interval,
    starts_with("Total_duration_of_fixations"),
    starts_with("Number_of_fixations"),
    starts_with("Average_duration"),
    !"Total_duration_of_fixations.Disruptive_Person",
    !"Number_of_fixations.Disruptive_Person",
    !"Average_duration_of_fixations.Disruptive_Person"
  ) %>%
  rowwise() %>%
  transmute(
    Group = as_factor(Group),
    Participant = Participant,
    Duration_of_interval = Duration_of_interval,
    Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),
    Sum_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
    Sum_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
    Number_fixation_min_mtu = round(Sum_number_fixation / Duration_of_interval_min, 2),
    Average_duration_fixation = round(Sum_duration_fixation / Sum_number_fixation, 2)
  ) %>%
  drop_na()

# 2. Descriptive Statistics Table
fixation_duration_table <- df_aoi_sum %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(Average_duration_fixation, na.rm = TRUE), 2),
    SD = round(sd(Average_duration_fixation, na.rm = TRUE), 2),
    Min = round(min(Average_duration_fixation, na.rm = TRUE), 2),
    Max = round(max(Average_duration_fixation, na.rm = TRUE), 2)
  )

# Display the descriptive table in APA style
knitr::kable(fixation_duration_table, caption = "N, M, SD, min & max Average Fixation Duration (micro-teaching unit)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# 3. Calculate means and standard deviations for Novice and Expert groups
mean_novice_fixation <- round(mean(df_aoi_sum$Average_duration_fixation[df_aoi_sum$Group == "Novice"], na.rm = TRUE), 2)
sd_novice_fixation <- round(sd(df_aoi_sum$Average_duration_fixation[df_aoi_sum$Group == "Novice"], na.rm = TRUE), 2)
mean_expert_fixation <- round(mean(df_aoi_sum$Average_duration_fixation[df_aoi_sum$Group == "Expert"], na.rm = TRUE), 2)
sd_expert_fixation <- round(sd(df_aoi_sum$Average_duration_fixation[df_aoi_sum$Group == "Expert"], na.rm = TRUE), 2)

# 4. Perform t-test to get the p-value
t_test_fixation <- t.test(
  Average_duration_fixation ~ Group,
  data = df_aoi_sum,
  var.equal = TRUE
)
p_value_fixation <- round(t_test_fixation$p.value, 2)

# 5. Calculate Cohen's d for effect size using formula syntax
cohen_d_fixation <- round(cohen.d(Average_duration_fixation ~ Group, data = df_aoi_sum)$estimate, 2)

# 6. Plotting the Average Fixation Duration
y_max_fixation <- max(df_aoi_sum$Average_duration_fixation) * 1.5

plot_avg_fixation_group <- df_aoi_sum %>%
  ggplot(mapping = aes(x = Group, y = Average_duration_fixation)) +
  geom_boxplot(mapping = aes(fill = Group), outlier.shape = NA, width = 0.5) +
  geom_jitter(
    width = 0.15, height = 0.1, alpha = 0.5, color = "black", size = 1.5
  ) +
  ylim(0, y_max_fixation) +
  labs(x = "", y = "Average Fixation Duration (ms)") +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Average Fixation Duration\n(Micro-Teaching Unit)") +
  theme_cowplot() +
  theme(legend.position = "none") +
  # Add annotations for mean (M) and SD
  annotate("text", x = 1, y = y_max_fixation * 0.85,
           label = paste0("atop(italic(M) == ", mean_novice_fixation, ", italic(SD) == ", sd_novice_fixation, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  annotate("text", x = 2, y = y_max_fixation * 0.85,
           label = paste0("atop(italic(M) == ", mean_expert_fixation, ", italic(SD) == ", sd_expert_fixation, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  # Add p-value and Cohen's d annotations
  annotate("text", x = 1.5, y = y_max_fixation * 0.95,
           label = paste0("p = ", p_value_fixation, "\nd = ", cohen_d_fixation),
           hjust = 0.5, size = 4, fontface = "italic")

plot_avg_fixation_group

ggsave(
  filename = "plots/plot_avg_fixation_group.svg",
  width = 20,
  height = 12,
  units = "cm"
)

# 7. Format the t-Test and Cohen's d results for APA Table without the first column
t_test_result <- data.frame(
  "Group Comparison" = "Experts vs. Novices",
  "t-value" = round(t_test_fixation$statistic, 2),
  "df" = t_test_fixation$parameter,
  "p-value" = round(t_test_fixation$p.value, 2),
  "Mean Difference" = round(t_test_fixation$estimate[1] - t_test_fixation$estimate[2], 2),
  "Cohen's d" = cohen_d_fixation,
  "95% CI (d)" = paste0("[", round(t_test_fixation$conf.int[1], 2), ", ", round(t_test_fixation$conf.int[2], 2), "]")
)

# Display t-Test and Effect Size results in APA style without row names
knitr::kable(t_test_result, caption = "t-Test and Effect Size for Average Fixation Duration (Micro-Teaching Unit)", row.names = FALSE) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

#### Average duration of fixations (AOI students)
```{r dur_students, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### AVERAGE DURATION ON AOI STUDENTS ########################

# 1. Data Preparation: Filter and Calculate Average Duration of Fixations on AOI Students
df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select (
    Group,
    Duration_of_interval,
    Participant,
    "Total_duration_of_fixations.Anna",
    "Total_duration_of_fixations.Bianca",
    "Total_duration_of_fixations.Carl(a)",
    "Number_of_fixations.Anna",
    "Number_of_fixations.Bianca",
    "Number_of_fixations.Carl(a)"
  ) %>%
  rowwise() %>%
  transmute(
    Group = as_factor(Group),
    Participant = Participant,
    Duration_of_interval_min = round(Duration_of_interval/60000, digits = 2),
    Duration_of_interval_sec = round(Duration_of_interval/1000, digits = 2),
    Stud_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
    Stud_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
    Stud_number_fixation_min = round(Stud_number_fixation / Duration_of_interval_min, digits = 2),
    Stud_number_fixation_sec = round(Stud_number_fixation / Duration_of_interval_sec, digits = 2),
    Average_duration_stud = round(Stud_duration_fixation / Stud_number_fixation, digits = 0)
    ) -> df_aoi_stud

# 2. Descriptive Statistics Table
dur_stud_table <- df_aoi_stud %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    "M in ms" = round(mean(Average_duration_stud, na.rm = TRUE), 2),
    "SD in ms" = round(sd(Average_duration_stud, na.rm = TRUE), 2),
    "Min in ms" = round(min(Average_duration_stud, na.rm = TRUE), 2),
    "Max in ms" = round(max(Average_duration_stud, na.rm = TRUE), 2)
  )

# Display the descriptive table in APA style
knitr::kable(dur_stud_table,
             caption = "N, M, SD, Min & Max Average Duration of Fixations in Milliseconds (AOI Students)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# 3. Plotting Average Duration on AOI Students
# Calculate values for annotation
mean_novice_stud <- round(mean(df_aoi_stud$Average_duration_stud[df_aoi_stud$Group == "Novice"], na.rm = TRUE), 2)
sd_novice_stud <- round(sd(df_aoi_stud$Average_duration_stud[df_aoi_stud$Group == "Novice"], na.rm = TRUE), 2)
mean_expert_stud <- round(mean(df_aoi_stud$Average_duration_stud[df_aoi_stud$Group == "Expert"], na.rm = TRUE), 2)
sd_expert_stud <- round(sd(df_aoi_stud$Average_duration_stud[df_aoi_stud$Group == "Expert"], na.rm = TRUE), 2)

# Maximum y-axis value for plot
y_max_stud <- max(df_aoi_stud$Average_duration_stud) * 1.2

# Conduct t-test
t_test_stud <- t.test(
  Average_duration_stud ~ Group,
  data = df_aoi_stud,
  var.equal = TRUE
)

# Extract p-value
p_value_stud <- round(t_test_stud$p.value, 2)

# Calculate Cohen's d (full result object)
d_aver_stud_full <- cohen.d(Average_duration_stud ~ Group, data = df_aoi_stud, pooled = TRUE)

# Extract Cohen's d and confidence interval
d_aver_stud <- round(d_aver_stud_full$estimate, 2)
d_conf_int <- paste0("[", round(d_aver_stud_full$conf.int[1], 2), ", ", round(d_aver_stud_full$conf.int[2], 2), "]")

# Annotated Plot
plot_average_duration_stud <- df_aoi_stud %>%
  ggplot(mapping = aes(x = Group, y = Average_duration_stud)) +
  geom_boxplot(mapping = aes(fill = Group), outlier.shape = NA, width = 0.5) +
  geom_jitter(
    width = 0.15, height = 0.1, alpha = 0.5, color = "black", size = 1.5
  ) +
  ylim(0, y_max_stud) + 
  labs(x = "", y = "Average Fixation Duration (ms)") + 
  scale_fill_brewer(palette = "RdBu") + 
  ggtitle("Average Duration of Fixations\n(AOI Students)") +
  theme_cowplot() +
  theme(legend.position = "none") +
  # Annotate mean (M) and SD
  annotate("text", x = 1, y = y_max_stud * 0.85,
           label = paste0("atop(italic(M) == ", mean_novice_stud, ", italic(SD) == ", sd_novice_stud, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  annotate("text", x = 2, y = y_max_stud * 0.85,
           label = paste0("atop(italic(M) == ", mean_expert_stud, ", italic(SD) == ", sd_expert_stud, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  # Annotate p-value and Cohen's d
  annotate("text", x = 1.5, y = y_max_stud * 0.95,
           label = paste0("p = ", p_value_stud, "\nd = ", d_aver_stud),
           hjust = 0.5, size = 4, fontface = "italic")

plot_average_duration_stud

ggsave(
  filename = "plots/plot_average_duration_stud.svg",
  width = 20,
  height = 12,
  units = "cm"
)


# 4. t-Test and Effect Size Results Table
t_test_stud_result <- data.frame(
  "Group Comparison" = "Experts vs. Novices",
  "t-value" = round(t_test_stud$statistic, 2),
  "df" = t_test_stud$parameter,
  "p-value" = round(t_test_stud$p.value, 2),
  "Mean Difference" = round(t_test_stud$estimate[1] - t_test_stud$estimate[2], 2),
  "Cohen's d" = d_aver_stud,
  "95% CI (d)" = d_conf_int
)

# Display the t-Test and Effect Size results table in APA style
knitr::kable(t_test_stud_result,
             caption = "t-Test and Effect Size for Average Fixation Duration on AOI Students (milliseconds)",
             row.names = FALSE) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

#### Average duration of fixations (AOI disruptive person)
```{r average_dur_disrup, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### AVERAGE DURATION ON AOI DISRUPTIVE PERSON ########################
##################### DATA PREPARATION ########################

# Define the different types of disruptions and categories
disruptions <- c("Chatting_with_neighbour", "Clicking_pen", "Drawing", 
                 "Drumming_with_hands", "Head_on_table", "Heckling", 
                 "Looking_at_phone", "Snipping_with_fingers", "Whispering")
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")

# Step 1: Filter and prepare the data
df_aoi_disrup <- df_aoi %>%
  filter(TOI %in% disruptions) %>% # Filter rows based on the disruption list
  select(Group, Participant, TOI, 
         "Total_duration_of_fixations.Disruptive_Person", 
         "Number_of_fixations.Disruptive_Person") %>%
  mutate(
    Group = as_factor(Group), # Convert Group column to a factor
    Disruption_Category = case_when( # Assign categories based on disruption type
      TOI %in% verbal_disruptions ~ "Verbal disruptions",
      TOI %in% physical_disruptions ~ "Physical disruptions",
      TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    ),
    Average_duration_disrup = round(Total_duration_of_fixations.Disruptive_Person / 
                                    Number_of_fixations.Disruptive_Person, 2) # Average duration in milliseconds
  ) %>%
  filter(!is.na(Disruption_Category) & !is.na(Average_duration_disrup)) # Remove NAs

##################### DESCRIPTIVE STATISTICS ########################

# Step 2: Summarize data by disruption category
disruption_summary <- df_aoi_disrup %>%
  group_by(Group, Participant, Disruption_Category) %>%
  summarise(
    mean_duration_ms = round(mean(Average_duration_disrup, na.rm = TRUE), 2),
    .groups = "drop"
  )

# Step 3: Summarize by participant
individual_summary <- disruption_summary %>%
  group_by(Group, Participant) %>%
  summarise(
    mean_duration = round(mean(mean_duration_ms, na.rm = TRUE), 2), # Mean duration per participant
    .groups = "drop"
  )

# Overall descriptive statistics
overall_stats <- individual_summary %>%
  group_by(Group) %>%
  summarise(
    N = n(), # Number of participants
    Mean = round(mean(mean_duration, na.rm = TRUE), 2), # Mean duration
    SD = round(sd(mean_duration, na.rm = TRUE), 2), # Standard deviation
    Min = round(min(mean_duration, na.rm = TRUE), 2), # Minimum value
    Max = round(max(mean_duration, na.rm = TRUE), 2), # Maximum value
    .groups = "drop"
  )

# Display the overall descriptive statistics table
knitr::kable(
  overall_stats,
  caption = "Descriptive Statistics (N, Mean, SD, Min, Max) for Average Duration by Group",
  col.names = c("Group", "N", "M", "SD", "Min", "Max"),
  row.names = FALSE
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# Descriptive statistics by category
category_stats <- disruption_summary %>%
  group_by(Disruption_Category, Group) %>%
  summarise(
    N = n(), # Number of data points
    Mean = round(mean(mean_duration_ms, na.rm = TRUE), 2), # Mean duration
    SD = round(sd(mean_duration_ms, na.rm = TRUE), 2), # Standard deviation
    Min = round(min(mean_duration_ms, na.rm = TRUE), 2), # Minimum value
    Max = round(max(mean_duration_ms, na.rm = TRUE), 2), # Maximum value
    .groups = "drop"
  )

# Display the descriptive statistics table by category
knitr::kable(
  category_stats,
  caption = "Descriptive Statistics (N, Mean, SD, Min, Max) for Average Duration by Group and Category",
  col.names = c("Category", "Group", "N", "M", "SD", "Min", "Max"),
  row.names = FALSE
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### PLOTTING ########################

# Overall plot
mean_novice <- round(mean(individual_summary$mean_duration[individual_summary$Group == "Novice"], na.rm = TRUE), 2)
sd_novice <- round(sd(individual_summary$mean_duration[individual_summary$Group == "Novice"], na.rm = TRUE), 2)
mean_expert <- round(mean(individual_summary$mean_duration[individual_summary$Group == "Expert"], na.rm = TRUE), 2)
sd_expert <- round(sd(individual_summary$mean_duration[individual_summary$Group == "Expert"], na.rm = TRUE), 2)

# t-Test and effect size
t_test <- t.test(mean_duration ~ Group, data = individual_summary, var.equal = TRUE)
p_value <- round(t_test$p.value, 2)
cohen_d <- round(effsize::cohen.d(mean_duration ~ Group, data = individual_summary)$estimate, 2)

# Overall plot
y_max_overall <- max(individual_summary$mean_duration, na.rm = TRUE) * 1.5
plot_overall_dur_disrup <- ggplot(individual_summary, aes(x = Group, y = mean_duration, fill = Group)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(width = 0.1, alpha = 0.7, color = "black", size = 1.5) +
  labs(x = "", y = "Mean Duration (ms) per Participant") +
  ggtitle("Average Duration per Participant\n(AOI Disruptive Person)") +
  scale_fill_brewer(palette = "RdBu") +
  theme_cowplot() +
  ylim(0, y_max_overall) +
  theme(legend.position = "none") +
  annotate("text", x = 1, y = y_max_overall * 0.85,
           label = paste0("M = ", mean_novice, "\nSD = ", sd_novice),
           hjust = 0.5, size = 4, fontface = "italic") +
  annotate("text", x = 2, y = y_max_overall * 0.85,
           label = paste0("M = ", mean_expert, "\nSD = ", sd_expert),
           hjust = 0.5, size = 4, fontface = "italic") +
  annotate("text", x = 1.5, y = y_max_overall * 0.95,
           label = paste0("p = ", p_value, "\nd = ", cohen_d),
           hjust = 0.5, size = 4, fontface = "italic")

ggsave(
  filename = "plots/plot_overall_dur_disrup.svg",
  width = 20,
  height = 12,
  units = "cm"
)


# Plot by category
plot_category_dur_disrup <- disruption_summary %>%
  ggplot(aes(x = Group, y = mean_duration_ms, fill = Group)) +  # Ensure using correct column name here
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(width = 0.1, alpha = 0.7, size = 1.5, color = "black") +
  facet_wrap(~Disruption_Category, scales = "fixed", labeller = label_wrap_gen(width = 20)) +
  ylim(0, 2000) +
  labs(x = "", y = "Mean Duration (ms)") +
  ggtitle("Average Duration of Fixations by Disruption Category and Group") +
  scale_fill_brewer(palette = "RdBu") +
  theme_cowplot() +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 10)
  )

ggsave(
  filename = "plots/plot_category_dur_disrup.svg",
  width = 24,
  height = 12,
  units = "cm"
)

# Display plots
plot_overall
plot_category


##################### REPEATED MEASURES ANOVA ########################

# Perform the repeated-measures ANOVA with `mean_duration_ms` as the dependent variable
anova_afex <- afex::aov_ez(
  id = "Participant",  # Random effect
  dv = "mean_duration_ms",  # Dependent variable
  between = "Group",  # Between-subject factor
  within = "Disruption_Category",  # Within-subject factor
  data = disruption_summary
)

# Extract the ANOVA table
anova_results <- as.data.frame(anova_afex$anova_table)

# Recalculate generalized eta squared (η²)
eta_squared_results <- effectsize::eta_squared(anova_afex, partial = FALSE)

# Combine recalculated eta squared with the ANOVA table
anova_table_apa <- anova_results %>%
  rownames_to_column(var = "Effect") %>%  # Move row names to a column
  left_join(
    as.data.frame(eta_squared_results), 
    by = c("Effect" = "Parameter")  # Match the correct columns
  ) %>%
  mutate(
    `F` = round(`F`, 2),  # Round F-values
    `η²` = round(Eta2, 3),  # Round generalized eta squared
    `p-value` = ifelse(
      `Pr(>F)` < 0.05, "< .05", round(`Pr(>F)`, 3)  # Format p-values
    )
  ) %>%
  select(Effect, `num Df`, `den Df`, `F`, `p-value`, `η²`)  # Order columns, place η² last

# Display the ANOVA table
kable(
  anova_table_apa,
  caption = "Repeated-Measures ANOVA Results for Average Duration (Including Effect Sizes)",
  col.names = c("Effect", "Df1", "Df2", "F", "p", "η²"),
  digits = 2
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### POST-HOC TESTS Group (between-subject factor) ########################

# Perform post-hoc pairwise comparisons for Group (between-subject factor)
post_hoc_group <- emmeans(anova_afex, pairwise ~ Group)

# Calculate Cohen's d manually
# Extract group means, standard deviations, and sample sizes from the data
group_stats <- individual_summary %>%
  group_by(Group) %>%
  summarise(
    Mean = mean(mean_duration, na.rm = TRUE),
    SD = sd(mean_duration, na.rm = TRUE),
    N = n(),
    .groups = "drop"
  )

# Calculate pooled standard deviation for Cohen's d
pooled_sd <- sqrt(
  ((group_stats$N[1] - 1) * group_stats$SD[1]^2 + (group_stats$N[2] - 1) * group_stats$SD[2]^2) /
    (sum(group_stats$N) - 2)
)

# Calculate Cohen's d
cohen_d <- round((group_stats$Mean[1] - group_stats$Mean[2]) / pooled_sd, 2)

# Add Cohen's d to the post-hoc results table
post_hoc_results_group <- as.data.frame(post_hoc_group$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    df = round(df, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2)),
    `Cohen's d` = cohen_d
  ) %>%
  select(Comparison, Estimate, SE, df, t, p.value, `Cohen's d`)

##################### TABLE FOR GROUP ########################

# Display the post-hoc test results for Group
knitr::kable(
  post_hoc_results_group,
  caption = "Post-Hoc Pairwise Comparisons for Group (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


##################### POST-HOC TESTS Disruption_Category (within-subject factor) ########################

# Perform post-hoc pairwise comparisons for Disruption_Category (within-subject factor)
post_hoc_disruption <- emmeans(anova_afex, pairwise ~ Disruption_Category)

# Extract post-hoc pairwise contrasts for Disruption_Category
post_hoc_results_disruption <- as.data.frame(post_hoc_disruption$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison), # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))
  )

##################### COHEN'S D CALCULATION ########################

# Define the disruption categories
categories <- c("Lack of eagerness to learn", "Physical disruptions", "Verbal disruptions")

# Initialize an empty list to store the Cohen's d values
cohen_d_values <- vector("list", length = nrow(post_hoc_results_disruption))

# Loop over the post-hoc results to calculate Cohen's d for each comparison
for (i in 1:nrow(post_hoc_results_disruption)) {
  # Extract the two categories being compared
  group1 <- strsplit(post_hoc_results_disruption$Comparison[i], " - ")[[1]][1]
  group2 <- strsplit(post_hoc_results_disruption$Comparison[i], " - ")[[1]][2]
  
  # Calculate Cohen's d for the pair of categories
  d_value <- CohenD(
    x = disruption_summary$mean_duration_ms[disruption_summary$Disruption_Category == group1],
    y = disruption_summary$mean_duration_ms[disruption_summary$Disruption_Category == group2],
    na.rm = TRUE
  )
  
  # Store the absolute value of Cohen's d
  cohen_d_values[[i]] <- abs(round(d_value, 2))  # Take the absolute value of Cohen's d
}

# Add the Cohen's d values to the post-hoc results
post_hoc_results_disruption$Cohen_d <- unlist(cohen_d_values)

##################### TABLE FOR DISRUPTION CATEGORY ########################

# Ensure the number of column names matches the number of columns in the dataframe
post_hoc_results_disruption <- post_hoc_results_disruption %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)

# Displaying the table
knitr::kable(
  post_hoc_results_disruption,
  caption = "Post-Hoc Pairwise Comparisons for Disruption Categories (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```


#### Gaze Relational Index (GRI; micro-teaching unit)
```{r gri_all, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### GRI in MICRO-TEACHING UNIT ########################

# Step 1: Calculate GRI (Gaze Ratio Index) for each participant
df_gri <- df_aoi_sum %>%
  mutate(GRI = round(Average_duration_fixation / Number_fixation_min_mtu, 2))

# Step 2: Summarize GRI statistics (N, Mean, SD, Min, Max) by Group
gri_table <- df_gri %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    "M" = round(mean(GRI, na.rm = TRUE), 2),
    "SD" = round(sd(GRI, na.rm = TRUE), 2),
    "Min" = round(min(GRI, na.rm = TRUE), 2),
    "Max" = round(max(GRI, na.rm = TRUE), 2)
  )

# Display the GRI summary table in APA format
knitr::kable(gri_table,
             caption = "N, M, SD, Min, and Max GRI (Micro-Teaching Unit)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# Step 3: Plot GRI by Group with boxplot and jittered points
# Calculate annotation values
mean_novice_gri <- round(mean(df_gri$GRI[df_gri$Group == "Novice"], na.rm = TRUE), 2)
sd_novice_gri <- round(sd(df_gri$GRI[df_gri$Group == "Novice"], na.rm = TRUE), 2)
mean_expert_gri <- round(mean(df_gri$GRI[df_gri$Group == "Expert"], na.rm = TRUE), 2)
sd_expert_gri <- round(sd(df_gri$GRI[df_gri$Group == "Expert"], na.rm = TRUE), 2)

# Maximum y-axis value for plot
y_max_gri <- max(df_gri$GRI, na.rm = TRUE) * 1.2

# Conduct t-test
t_test_gri <- t.test(
  GRI ~ Group,
  data = df_gri,
  var.equal = TRUE
)

# Extract p-value
p_value_gri <- round(t_test_gri$p.value, 2)

# Calculate Cohen's d (full result object)
d_gri_full <- cohen.d(GRI ~ Group, data = df_gri, pooled = TRUE)

# Extract Cohen's d and confidence interval
d_gri <- round(d_gri_full$estimate, 2)
d_conf_int_gri <- paste0("[", round(d_gri_full$conf.int[1], 2), ", ", round(d_gri_full$conf.int[2], 2), "]")

# Annotated Plot
plot_gri_group <- df_gri %>%
  ggplot(aes(x = Group, y = GRI, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 2, alpha = 0.7, width = 0.1, height = 0.1, seed = 1) +
  ylim(0, y_max_gri) +
  labs(x = "", y = "Average Duration of Fixations /\nNumber of Fixations per Minute") +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("GRI\n(Micro-Teaching Unit)") +
  theme_cowplot() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, face = "bold")
  ) +
  # Annotate mean (M) and SD
  annotate("text", x = 1, y = y_max_gri * 0.85,
           label = paste0("atop(italic(M) == ", mean_novice_gri, ", italic(SD) == ", sd_novice_gri, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  annotate("text", x = 2, y = y_max_gri * 0.85,
           label = paste0("atop(italic(M) == ", mean_expert_gri, ", italic(SD) == ", sd_expert_gri, ")"),
           hjust = 0.5, size = 3.5, vjust = -0.5, parse = TRUE) +
  # Annotate p-value and Cohen's d
  annotate("text", x = 1.5, y = y_max_gri * 0.95,
           label = paste0("p = ", p_value_gri, "\nd = ", d_gri),
           hjust = 0.5, size = 4, fontface = "italic") 

plot_gri_group

##################### t-Test & Effect Size for GRI ########################

# Step 6: Create a table for the t-test and Cohen's d results
gri_t_test_table <- data.frame(
  "Group Comparison" = "Experts vs. Novices",
  "t-value" = round(t_test_gri$statistic, 2),
  "df" = t_test_gri$parameter,
  "p-value" = round(t_test_gri$p.value, 2),
  "Mean Difference" = round(t_test_gri$estimate[1] - t_test_gri$estimate[2], 2),
  "Cohen's d" = d_gri,
  "95% CI (d)" = d_conf_int_gri
)

# Display the t-Test and Effect Size table for GRI in APA format
knitr::kable(gri_t_test_table, 
             caption = "t-Test and Effect Size for GRI (Micro-Teaching Unit)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

#### Time to first fixation in seconds (AOI disruptive person)
```{r ttff_disrup, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

##################### TIME TO FIRST FIXATION ########################

# Define disruptions and categories
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")

# Step 1: Data Preparation
df_ttff_disrup <- df_aoi %>%
  filter(TOI %in% c(verbal_disruptions, physical_disruptions, lack_of_eagerness)) %>%
  dplyr::select(
    Participant,
    TOI,
    Time_to_first_fixation.Disruptive_Person
  ) %>%
  mutate(
    Group = ifelse(Participant < 200, "Novice", "Expert"),  # Assigning Group based on Participant
    Disruption_Category = case_when(
      TOI %in% verbal_disruptions ~ "Verbal disruptions",
      TOI %in% physical_disruptions ~ "Physical disruptions",
      TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(Disruption_Category)) %>% # Keep only rows with valid categories
  drop_na() %>%
  filter(
    Time_to_first_fixation.Disruptive_Person > 0, # Exclude zero fixation times
    Time_to_first_fixation.Disruptive_Person <= 30000 # Cut-off at 30 seconds
  ) %>%
  mutate(
    Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person / 1000, 2)
  )

# Summarize the Disrup_time_fixation_sec by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
  group_by(Participant, Group) %>%
  summarise(
    Disrup_time_fixation_sec = round(mean(Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average time to first fixation per participant
    .groups = "drop"
  )

##################### DESCRIPTIVE STATISTICS ########################

# Step 2: Descriptive Statistics by Group
ttff_disrup_table <- df_ttff_disrup_participant_summary %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    "M in sec" = round(mean(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    "SD in sec" = round(sd(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    "Min in sec" = round(min(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    "Max in sec" = round(max(Disrup_time_fixation_sec, na.rm = TRUE), 2)
  )

knitr::kable(ttff_disrup_table,
             caption = "N, M, SD, Min & Max Time to First Fixation in Seconds (AOI Disruptive Person)") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### STATISTICS BY DISRUPTION CATEGORY ########################

# Step 3: Descriptive Statistics by Category and Group
summary_stats_category_group <- df_ttff_disrup %>%
  group_by(Disruption_Category, Group) %>%
  summarise(
    N = n_distinct(Participant),  # Count unique participants
    Mean = round(mean(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    SD = round(sd(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    Median = round(median(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    IQR = round(IQR(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    Min = round(min(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    Max = round(max(Disrup_time_fixation_sec, na.rm = TRUE), 2),
    .groups = "drop"
  )

# Display the table
knitr::kable(
  summary_stats_category_group,
  caption = "Descriptive Statistics for Time to First Fixation by Category and Group",
  col.names = c("Category", "Group", "N (Participants)", "Mean", "SD", "Median", "IQR", "Min", "Max"), # Ensure the column names match
  row.names = FALSE
) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### PLOTS ########################

# Plot 1: Time to First Fixation by Group
plot_ttff_group <- ggplot(df_ttff_disrup, aes(x = Group, y = Disrup_time_fixation_sec, fill = Group)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1.5) +
  labs(x = "Group", y = "Time to First Fixation (seconds)") +
  theme_cowplot() +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Time to First Fixation by Group") +
  theme(legend.position = "none") +
  annotate("text", x = 1, y = max(df_ttff_disrup$Disrup_time_fixation_sec, na.rm = TRUE) * 1.1,
           label = paste0("Median = ", round(median(df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Group == "Novice"], na.rm = TRUE), 2),
                          "\nIQR = ", round(IQR(df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Group == "Novice"], na.rm = TRUE), 2)),
           hjust = 0.5, size = 4) +
  annotate("text", x = 2, y = max(df_ttff_disrup$Disrup_time_fixation_sec, na.rm = TRUE) * 1.1,
           label = paste0("Median = ", round(median(df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Group == "Expert"], na.rm = TRUE), 2),
                          "\nIQR = ", round(IQR(df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Group == "Expert"], na.rm = TRUE), 2)),
           hjust = 0.5, size = 4)

# Display the first plot
plot_ttff_group

# Plot 2: Time to First Fixation by Group and Disruption Category
plot_ttff_category <- ggplot(df_ttff_disrup, aes(x = Group, y = Disrup_time_fixation_sec, fill = Group)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1.5) +
  facet_wrap(~Disruption_Category, scales = "fixed", labeller = label_wrap_gen(width = 15)) +  # Use fixed scale for all facets  
  ylim(0, 30) + 
  labs(x = "Group", y = "Time to First Fixation (seconds)") +
  theme_cowplot() +
  scale_fill_brewer(palette = "RdBu") +
  ggtitle("Time to First Fixation by Group and Disruption Category") +
  theme(legend.position = "none")

# Display the second plot
plot_ttff_category

##################### STATISTICAL TESTS ########################

##################### REPEATED MEASURES ANOVA ########################

# Perform the repeated-measures ANOVA with `Disrup_time_fixation_sec` as the dependent variable
anova_afex_ttff <- afex::aov_ez(
  id = "Participant",  # Random effect (each participant is measured multiple times)
  dv = "Disrup_time_fixation_sec",  # Dependent variable: Time to First Fixation (seconds)
  between = "Group",  # Between-subject factor: Group (Novice vs Expert)
  within = "Disruption_Category",  # Within-subject factor: Disruption Categories (Verbal, Physical, Lack of eagerness)
  data = df_ttff_disrup  # The data frame that contains the TTFF data
)

# Extract the ANOVA table
anova_results_ttff <- as.data.frame(anova_afex_ttff$anova_table)

# Recalculate generalized eta squared (η²) for effect size
eta_squared_results_ttff <- effectsize::eta_squared(anova_afex_ttff, partial = FALSE)

# Combine recalculated eta squared with the ANOVA table
anova_table_apa_ttff <- anova_results_ttff %>%
  rownames_to_column(var = "Effect") %>%  # Move row names to a column
  left_join(
    as.data.frame(eta_squared_results_ttff), 
    by = c("Effect" = "Parameter")  # Match the correct columns
  ) %>%
  mutate(
    `F` = round(`F`, 2),  # Round F-values
    `η²` = round(Eta2, 3),  # Round generalized eta squared
    `p-value` = ifelse(
      `Pr(>F)` < 0.05, "< .05", round(`Pr(>F)`, 2)  # Format p-values
    )
  ) %>%
  select(Effect, `num Df`, `den Df`, `F`, `p-value`, `η²`)  # Order columns, place η² last

# Display the ANOVA table for Time to First Fixation
knitr::kable(
  anova_table_apa_ttff,
  caption = "Repeated-Measures ANOVA Results for Time to First Fixation (Including Effect Sizes)",
  col.names = c("Effect", "Df1", "Df2", "F", "p", "η²"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


##################### POST-HOC TESTS Disruption_Category (within-subject factor) ########################
  
# Perform post-hoc pairwise comparisons for Disruption_Category (within-subject factor)
post_hoc_disruption <- emmeans(anova_afex_ttff, pairwise ~ Disruption_Category)
  
# Extract post-hoc pairwise contrasts for Disruption_Category
post_hoc_results_disruption <- as.data.frame(post_hoc_disruption$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),
    # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison),
    # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))  # Round p-values to 2 decimals
  )

##################### COHEN'S D CALCULATION ########################
  
# Calculate Cohen's d for each pairwise comparison
d_LackOfEagerness_vs_Physical <- CohenD(
  x = df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

d_LackOfEagerness_vs_Verbal <- CohenD(
  x = df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

d_Physical_vs_Verbal <- CohenD(
  x = df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Disruption_Category == "Physical disruptions"],
  y = df_ttff_disrup$Disrup_time_fixation_sec[df_ttff_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

##################### ADD COHEN'S D VALUES TO THE POST-HOC RESULTS ########################

# Create a named vector with the correct Cohen's d values
cohen_d_values <- c(
  "Physical disruptions - Lack of eagerness to learn" = round(d_LackOfEagerness_vs_Physical, 2),
  "Physical disruptions - Verbal disruptions" = round(d_Physical_vs_Verbal, 2),
  "Lack of eagerness to learn - Verbal disruptions" = round(d_LackOfEagerness_vs_Verbal, 2)
)

# Add Cohen's d values to the post-hoc results
post_hoc_results_disruption$Cohen_d <- cohen_d_values[post_hoc_results_disruption$Comparison]

##################### TABLE FOR DISRUPTION CATEGORY ########################

# Ensure the number of column names matches the number of columns in the dataframe
post_hoc_results_disruption <- post_hoc_results_disruption %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)

# Displaying the post-hoc results for Disruption Category (main effect) with Cohen's d
knitr::kable(
  post_hoc_results_disruption,
  caption = "Post-Hoc Pairwise Comparisons for Disruption Categories (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


# # Normality Tests (Shapiro-Wilk)
# normality_tests <- df_ttff_disrup %>%
#   group_by(Group) %>%
#   summarise(
#     Shapiro_Wilk_p = round(shapiro.test(Disrup_time_fixation_sec)$p.value, 2),
#     .groups = "drop"
#   )
# 
# kable(
#   normality_tests,
#   caption = "Shapiro-Wilk Test for Normality by Group",
#   col.names = c("Group", "Shapiro-Wilk p-value"),
#   row.names = FALSE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
# 
# # Mann-Whitney U-Test and Effect Size
# mann_whitney_test <- wilcox.test(Disrup_time_fixation_sec ~ Group, data = df_ttff_disrup, exact = FALSE)
# 
# # Effect Size Calculation for Mann-Whitney (r)
# n1 <- nrow(df_ttff_disrup %>% filter(Group == "Novice"))
# n2 <- nrow(df_ttff_disrup %>% filter(Group == "Expert"))
# r_effect <- abs(mann_whitney_test$statistic - (n1 * n2 / 2)) / sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)
# 
# mann_whitney_results <- data.frame(
#   "Test" = "Mann-Whitney U",
#   "W" = round(mann_whitney_test$statistic, 2),
#   "p-value" = round(mann_whitney_test$p.value, 2),
#   "Effect Size (r)" = round(r_effect, 3)
# )
# 
# kable(
#   mann_whitney_results,
#   caption = "Mann-Whitney U-Test Results for Time to First Fixation",
#   row.names = FALSE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
# 
# # Kruskal-Wallis Test and Pairwise Comparisons
# kruskal_test <- kruskal.test(Disrup_time_fixation_sec ~ Disruption_Category, data = df_ttff_disrup)
# 
# kruskal_results <- data.frame(
#   "Test" = "Kruskal-Wallis",
#   "Chi-squared" = round(kruskal_test$statistic, 2),
#   "df" = kruskal_test$parameter,
#   "p-value" = round(kruskal_test$p.value, 2)
# )
# 
# kable(
#   kruskal_results,
#   caption = "Kruskal-Wallis Test Results for Differences Between Disruption Categories",
#   row.names = FALSE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
# 
# # Pairwise Wilcoxon test with Bonferroni correction
# pairwise_wilcox <- pairwise.wilcox.test(
#   x = df_ttff_disrup$Disrup_time_fixation_sec,
#   g = df_ttff_disrup$Disruption_Category,
#   p.adjust.method = "bonferroni"
# )
# 
# # Extract and round the p-values to 3 decimal places
# pairwise_results <- as.data.frame(pairwise_wilcox$p.value) %>%
#   mutate(across(everything(), ~ round(., 2)))
# 
# # Display the results with rounded p-values
# kable(
#   pairwise_results,
#   caption = "Pairwise Wilcoxon Test Results (Bonferroni Corrected)",
#   row.names = TRUE
# ) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

### Rating Scales (Disruption Appraisal, Confidence Appraisal, Prevalence Rating)
```{r rating_scales, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

# Data Import and Preprocessing ------------------------------------------
sri <- excel_sheets("data/Coding_SRI.xlsx") %>%
  map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
  filter(
    !ID %in% c(201, 223),  # Removing invalid IDs
    !disruption_appraisal %in% c(-100, -99, -88),  # Removing invalid disruption appraisals
    !confidence_appraisal %in% c(-100, -99, -88),  # Removing invalid confidence appraisals
    !prevalence_rating %in% c(-100, -99, -88)  # Removing invalid prevalence ratings
  ) %>%
  mutate(
    Group = ifelse(ID < 200, "Novice", "Expert"),  # Create a Group column based on ID
    ID = as.factor(ID)  # Ensure that ID is treated as a factor (if needed)
  )

# Ensure no NAs and that all relevant columns exist
sri <- sri %>%
  drop_na(disruption_appraisal, confidence_appraisal, prevalence_rating, event, ID)

# Define disruptions and categories based on the exact event names
verbal_disruptions <- c("chatting", "heckling", "whispering")
physical_disruptions <- c("clicking pen", "drumming", "snipping")
lack_of_eagerness <- c("looking at phone", "head on table", "drawing")

# Step 1: Data Preparation for Disruption Categories
df_sri_disrup <- sri %>%
  mutate(
    Disruption_Category = case_when(
      event %in% verbal_disruptions ~ "Verbal disruptions",
      event %in% physical_disruptions ~ "Physical disruptions",
      event %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(Disruption_Category)) %>%
  drop_na()

# Descriptive Statistics -------------------------------------------------
## Disruption Appraisal by Group
sri_disrup_table <- sri %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(disruption_appraisal, na.rm = TRUE), 2),
    SD = round(sd(disruption_appraisal, na.rm = TRUE), 2),
    Min = round(min(disruption_appraisal, na.rm = TRUE), 2),
    Max = round(max(disruption_appraisal, na.rm = TRUE), 2)
  )

## Disruption Appraisal by Disruption Category (Split by Novice and Expert)
sri_disrup_category_table <- df_sri_disrup %>%
  group_by(Group, Disruption_Category) %>%
  summarise(
    N = n(),
    M = round(mean(disruption_appraisal, na.rm = TRUE), 2),
    SD = round(sd(disruption_appraisal, na.rm = TRUE), 2),
    Min = round(min(disruption_appraisal, na.rm = TRUE), 2),
    Max = round(max(disruption_appraisal, na.rm = TRUE), 2)
  )

## Disruption Appraisal for each disruption event
sri_disrup_single_table <- df_sri_disrup %>%
  group_by(Group, event) %>%
  summarise(
    N = n(),
    M = round(mean(disruption_appraisal, na.rm = TRUE), 2),
    SD = round(sd(disruption_appraisal, na.rm = TRUE), 2),
    Min = round(min(disruption_appraisal, na.rm = TRUE), 2),
    Max = round(max(disruption_appraisal, na.rm = TRUE), 2)
  )

## Confidence Appraisal by Group
sri_confi_table <- sri %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(confidence_appraisal, na.rm = TRUE), 2),
    SD = round(sd(confidence_appraisal, na.rm = TRUE), 2),
    Min = round(min(confidence_appraisal, na.rm = TRUE), 2),
    Max = round(max(confidence_appraisal, na.rm = TRUE), 2)
  )

## Confidence Appraisal by Disruption Category (Split by Novice and Expert)
sri_confi_category_table <- df_sri_disrup %>%
  group_by(Group, Disruption_Category) %>%
  summarise(
    N = n(),
    M = round(mean(confidence_appraisal, na.rm = TRUE), 2),
    SD = round(sd(confidence_appraisal, na.rm = TRUE), 2),
    Min = round(min(confidence_appraisal, na.rm = TRUE), 2),
    Max = round(max(confidence_appraisal, na.rm = TRUE), 2)
  )

## Confidence Appraisal for each disruption event
sri_confi_single_table <- df_sri_disrup %>%
  group_by(Group, event) %>%
  summarise(
    N = n(),
    M = round(mean(confidence_appraisal, na.rm = TRUE), 2),
    SD = round(sd(confidence_appraisal, na.rm = TRUE), 2),
    Min = round(min(confidence_appraisal, na.rm = TRUE), 2),
    Max = round(max(confidence_appraisal, na.rm = TRUE), 2)
  )

## Prevalence Rating by Group
sri_preva_table <- sri %>%
  group_by(Group) %>%
  summarise(
    N = n(),
    M = round(mean(prevalence_rating, na.rm = TRUE), 2),
    SD = round(sd(prevalence_rating, na.rm = TRUE), 2),
    Min = round(min(prevalence_rating, na.rm = TRUE), 2),
    Max = round(max(prevalence_rating, na.rm = TRUE), 2)
  )

## Prevalence Rating by Disruption Category (Split by Novice and Expert)
sri_preva_category_table <- df_sri_disrup %>%
  group_by(Group, Disruption_Category) %>%
  summarise(
    N = n(),
    M = round(mean(prevalence_rating, na.rm = TRUE), 2),
    SD = round(sd(prevalence_rating, na.rm = TRUE), 2),
    Min = round(min(prevalence_rating, na.rm = TRUE), 2),
    Max = round(max(prevalence_rating, na.rm = TRUE), 2)
  )

## Prevalence Rating for each disruption event
sri_preva_single_table <- sri %>%
  group_by(Group, event) %>%
  summarise(
    N = n(),
    M = round(mean(prevalence_rating, na.rm = TRUE), 2),
    SD = round(sd(prevalence_rating, na.rm = TRUE), 2),
    Min = round(min(prevalence_rating, na.rm = TRUE), 2),
    Max = round(max(prevalence_rating, na.rm = TRUE), 2)
  )

# Step 4: Arrange Values in Descending Order by Mean for Each Event ----------------------------------------

## Disruption Appraisal for each disruption event, sorted by Mean
sri_disrup_single_table_sorted <- sri_disrup_single_table %>%
  arrange(Group, desc(M))  # Sorting by mean (M) in descending order within each ID group

## Confidence Appraisal for each disruption event, sorted by Mean
sri_confi_single_table_sorted <- sri_confi_single_table %>%
  arrange(Group, desc(M))  # Sorting by mean (M) in descending order within each ID group

## Prevalence Rating for each disruption event, sorted by Mean
sri_preva_single_table_sorted <- sri_preva_single_table %>%
  arrange(Group, desc(M))  # Sorting by mean (M) in descending order within each ID group

# APA-Conform Tables with Sorted Values --------------------------------------------

## Disruption Appraisal by Group
kable(sri_disrup_table, caption = "Descriptive Statistics for Disruption Appraisal", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Disruption Appraisal by Disruption Category (Split by Novice and Expert)
kable(sri_disrup_category_table, caption = "Descriptive Statistics for Disruption Appraisal by Disruption Category", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Disruption Appraisal for each disruption event (Sorted by Mean)
kable(sri_disrup_single_table_sorted, caption = "Descriptive Statistics for Disruption Appraisal by Disruption Event (Sorted by Mean)", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Confidence Appraisal by Group
kable(sri_confi_table, caption = "Descriptive Statistics for Confidence Appraisal", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Confidence Appraisal by Disruption Category (Split by Novice and Expert)
kable(sri_confi_category_table, caption = "Descriptive Statistics for Confidence Appraisal by Disruption Category", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Confidence Appraisal for each disruption event (Sorted by Mean)
kable(sri_confi_single_table_sorted, caption = "Descriptive Statistics for Confidence Appraisal by Disruption Event (Sorted by Mean)", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Prevalence Rating by Group
kable(sri_preva_table, caption = "Descriptive Statistics for Prevalence Rating", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Prevalence Rating by Disruption Category (Split by Novice and Expert)
kable(sri_preva_category_table, caption = "Descriptive Statistics for Prevalence Rating by Disruption Category", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

## Prevalence Rating for each disruption event (Sorted by Mean)
kable(sri_preva_single_table_sorted, caption = "Descriptive Statistics for Prevalence Rating by Disruption Event (Sorted by Mean)", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Plotting ---------------------------------------------------------------

## Disruption Appraisal
disrup_plot <- sri %>%
  ggplot(aes(x = Group, y = disruption_appraisal, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 1.5, alpha = 0.6, width = 0.2, height = 0.1) +
  labs(x = "", y = "Disruption Appraisal") +
  scale_fill_brewer(palette = "RdBu") +  # Using the RdBu color palette for Novice and Expert
  ggtitle("Disruption Appraisal by Group") +
  theme_cowplot() +
  theme(legend.position = "none")  # No legend for the main plot

print(disrup_plot)

## Disruption Appraisal by Disruption Category, Split by ID (Novice vs Expert)
disrup_cat_plot <- df_sri_disrup %>%
  ggplot(aes(x = Disruption_Category, y = disruption_appraisal, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 1.5, alpha = 0.6, width = 0.2, height = 0.1) +
  labs(x = "", y = "Disruption Appraisal") +
  scale_fill_brewer(palette = "RdBu") +  # Use the same RdBu color palette as in disrup_plot
  ggtitle("Disruption Appraisal by Disruption Category") +
  theme_cowplot() +
  theme(legend.position = "top") +  # Place the legend at the top
  scale_fill_discrete(name = "Group")  # Add a title to the legend

print(disrup_cat_plot)

## Confidence Appraisal
confi_plot <- sri %>%
  ggplot(aes(x = Group, y = confidence_appraisal, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 1.5, alpha = 0.6, width = 0.2, height = 0.1) +
  labs(x = "", y = "Confidence Appraisal") +
  scale_fill_brewer(palette = "RdBu") +  # Using the RdBu color palette for Novice and Expert
  ggtitle("Confidence Appraisal by Group") +
  theme_cowplot() +
  theme(legend.position = "none")  # No legend for the main plot

print(confi_plot)

## Confidence Appraisal by Disruption Category, Split by ID (Novice vs Expert)
confi_cat_plot <- df_sri_disrup %>%
  ggplot(aes(x = Disruption_Category, y = confidence_appraisal, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 1.5, alpha = 0.6, width = 0.2, height = 0.1) +
  labs(x = "", y = "Confidence Appraisal") +
  scale_fill_brewer(palette = "RdBu") +  # Use the same RdBu color palette as in confi_plot
  ggtitle("Confidence Appraisal by Disruption Category") +
  theme_cowplot() +
  theme(legend.position = "top") +  # Place the legend at the top
  scale_fill_discrete(name = "Group")  # Add a title to the legend

print(confi_cat_plot)

## Prevalence Rating
preva_plot <- sri %>%
  ggplot(aes(x = Group, y = prevalence_rating, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 1.5, alpha = 0.6, width = 0.2, height = 0.1) +
  labs(x = "", y = "Prevalence Rating") +
  scale_fill_brewer(palette = "RdBu") +  # Using the RdBu color palette for Novice and Expert
  ggtitle("Prevalence Rating by Group") +
  theme_cowplot() +
  theme(legend.position = "none")  # No legend for the main plot

print(preva_plot)

## Prevalence Rating by Disruption Category, Split by ID (Novice vs Expert)
preva_cat_plot <- df_sri_disrup %>%
  ggplot(aes(x = Disruption_Category, y = prevalence_rating, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(size = 1.5, alpha = 0.6, width = 0.2, height = 0.1) +
  labs(x = "", y = "Prevalence Rating") +
  scale_fill_brewer(palette = "RdBu") +  # Use the same RdBu color palette as in preva_plot
  ggtitle("Prevalence Rating by Disruption Category") +
  theme_cowplot() +
  theme(legend.position = "top") +  # Place the legend at the top
  scale_fill_discrete(name = "Group")  # Add a title to the legend

print(preva_cat_plot)

# REPEATED MEASURES ANOVA ---------------------------------------------------------------

# Perform the repeated-measures ANOVA for Disruption Appraisal with the main effects of ID and Disruption_Category
# and the interaction between them
anova_disrup_appraisal <- afex::aov_ez(
  id = "ID",  # Random effect (each participant is measured multiple times)
  dv = "disruption_appraisal",  # Dependent variable: Disruption Appraisal
  within = "Disruption_Category",  # Within-subject factor: Disruption Categories (Verbal, Physical, Lack of eagerness)
  between = "Group",  # Between-subject factor: Group (Novice vs Expert)
  data = df_sri_disrup,  # The data frame that contains the disruption appraisal data
  factorize = TRUE,  # Ensure factors are treated as factors
  detailed = TRUE  # Include detailed output to check interaction effects
)

# Perform the repeated-measures ANOVA for Confidence Appraisal with the main effects of ID and Disruption_Category
# and the interaction between them
anova_confi_appraisal <- afex::aov_ez(
  id = "ID",  # Random effect (each participant is measured multiple times)
  dv = "confidence_appraisal",  # Dependent variable: Confidence Appraisal
  within = "Disruption_Category",  # Within-subject factor: Disruption Categories (Verbal, Physical, Lack of eagerness)
  between = "Group",  # Between-subject factor: Group (Novice vs Expert)
  data = df_sri_disrup,  # The data frame that contains the confidence appraisal data
  factorize = TRUE,  # Ensure factors are treated as factors
  detailed = TRUE  # Include detailed output to check interaction effects
)

# Extract the ANOVA tables for both dependent variables
anova_results_disrup_appraisal <- as.data.frame(anova_disrup_appraisal$anova_table)
anova_results_confi_appraisal <- as.data.frame(anova_confi_appraisal$anova_table)

# Recalculate generalized eta squared (η²) for effect size for both ANOVAs
eta_squared_disrup_appraisal <- effectsize::eta_squared(anova_disrup_appraisal, partial = FALSE)
eta_squared_confi_appraisal <- effectsize::eta_squared(anova_confi_appraisal, partial = FALSE)

# Combine recalculated eta squared with the ANOVA tables
anova_table_apa_disrup_appraisal <- anova_results_disrup_appraisal %>%
  rownames_to_column(var = "Effect") %>%
  left_join(
    as.data.frame(eta_squared_disrup_appraisal),
    by = c("Effect" = "Parameter")  # Match the correct columns
  ) %>%
  mutate(
    `F` = round(`F`, 2),  # Round F-values
    `η²` = round(Eta2, 3),  # Round generalized eta squared
    `p-value` = ifelse(
      `Pr(>F)` < 0.05, "< .05", round(`Pr(>F)`, 2)  # Format p-values
    )
  ) %>%
  select(Effect, `num Df`, `den Df`, `F`, `p-value`, `η²`)  # Order columns, place η² last

anova_table_apa_confi_appraisal <- anova_results_confi_appraisal %>%
  rownames_to_column(var = "Effect") %>%
  left_join(
    as.data.frame(eta_squared_confi_appraisal),
    by = c("Effect" = "Parameter")  # Match the correct columns
  ) %>%
  mutate(
    `F` = round(`F`, 2),  # Round F-values
    `η²` = round(Eta2, 3),  # Round generalized eta squared
    `p-value` = ifelse(
      `Pr(>F)` < 0.05, "< .05", round(`Pr(>F)`, 2)  # Format p-values
    )
  ) %>%
  select(Effect, `num Df`, `den Df`, `F`, `p-value`, `η²`)  # Order columns, place η² last

# Display the ANOVA tables for Disruption Appraisal and Confidence Appraisal
knitr::kable(
  anova_table_apa_disrup_appraisal,
  caption = "Repeated-Measures ANOVA Results for Disruption Appraisal (Including Effect Sizes)",
  col.names = c("Effect", "Df1", "Df2", "F", "p", "η²"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

knitr::kable(
  anova_table_apa_confi_appraisal,
  caption = "Repeated-Measures ANOVA Results for Confidence Appraisal (Including Effect Sizes)",
  col.names = c("Effect", "Df1", "Df2", "F", "p", "η²"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

##################### POST-HOC TESTS for Disruption Appraisal (Group and Disruption_Category) ########################

# Perform post-hoc pairwise comparisons for Group (between-subject factor) for disruption_appraisal
post_hoc_group_disrup <- emmeans(anova_disrup_appraisal, pairwise ~ Group)

# Extract post-hoc pairwise contrasts for Group (Disruption Appraisal)
post_hoc_results_group_disrup <- as.data.frame(post_hoc_group_disrup$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2)),
    
    # Calculate Cohen's d for Group comparison using pooled SD formula
    group1 = "Novice",  # Define group1 for Cohen's d
    group2 = "Expert",  # Define group2 for Cohen's d
    
    # Get the means for both groups
    mean1 = sri %>% 
      filter(Group == group1) %>%
      summarise(mean1 = mean(disruption_appraisal, na.rm = TRUE)) %>% 
      pull(mean1),
    
    mean2 = sri %>% 
      filter(Group == group2) %>%
      summarise(mean2 = mean(disruption_appraisal, na.rm = TRUE)) %>% 
      pull(mean2),
    
    # Get the standard deviations for both groups
    sd1 = sri %>% 
      filter(Group == group1) %>%
      summarise(sd1 = sd(disruption_appraisal, na.rm = TRUE)) %>% 
      pull(sd1),
    
    sd2 = sri %>% 
      filter(Group == group2) %>%
      summarise(sd2 = sd(disruption_appraisal, na.rm = TRUE)) %>% 
      pull(sd2),
    
    # Get the sample sizes for both groups
    n1 = nrow(sri %>% filter(Group == group1)),
    n2 = nrow(sri %>% filter(Group == group2)),
    
    # Calculate pooled standard deviation
    pooled_sd = sqrt(((n1 - 1) * sd1^2 + (n2 - 1) * sd2^2) / (n1 + n2 - 2)),
    
    # Calculate Cohen's d using the correct formula (mean difference / pooled SD)
    Cohen_d = ifelse(pooled_sd > 0, round(abs(mean1 - mean2) / pooled_sd, 2), NA)  # Avoid division by zero
  ) %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)  # Keep relevant columns


##################### POST-HOC TESTS for Confidence Appraisal (Group and Disruption_Category) ########################

# Perform post-hoc pairwise comparisons for Group (between-subject factor) for confidence_appraisal
post_hoc_group_confi <- emmeans(anova_confi_appraisal, pairwise ~ Group)

# Extract post-hoc pairwise contrasts for Group (Confidence Appraisal)
post_hoc_results_group_confi <- as.data.frame(post_hoc_group_confi$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2)),
    
    # Calculate Cohen's d for Group comparison using pooled SD formula
    group1 = "Novice",  # Define group1 for Cohen's d
    group2 = "Expert",  # Define group2 for Cohen's d
    
    # Get the means for both groups
    mean1 = sri %>% 
      filter(Group == group1) %>%
      summarise(mean1 = mean(confidence_appraisal, na.rm = TRUE)) %>% 
      pull(mean1),
    
    mean2 = sri %>% 
      filter(Group == group2) %>%
      summarise(mean2 = mean(confidence_appraisal, na.rm = TRUE)) %>% 
      pull(mean2),
    
    # Get the standard deviations for both groups
    sd1 = sri %>% 
      filter(Group == group1) %>%
      summarise(sd1 = sd(confidence_appraisal, na.rm = TRUE)) %>% 
      pull(sd1),
    
    sd2 = sri %>% 
      filter(Group == group2) %>%
      summarise(sd2 = sd(confidence_appraisal, na.rm = TRUE)) %>% 
      pull(sd2),
    
    # Get the sample sizes for both groups
    n1 = nrow(sri %>% filter(Group == group1)),
    n2 = nrow(sri %>% filter(Group == group2)),
    
    # Calculate pooled standard deviation
    pooled_sd = sqrt(((n1 - 1) * sd1^2 + (n2 - 1) * sd2^2) / (n1 + n2 - 2)),
    
    # Calculate Cohen's d using the correct formula (mean difference / pooled SD)
    Cohen_d = ifelse(pooled_sd > 0, round(abs(mean1 - mean2) / pooled_sd, 2), NA)  # Avoid division by zero
  ) %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)  # Keep relevant columns


##################### POST-HOC TESTS for Disruption_Category (within-subject factor) ########################

# Perform post-hoc pairwise comparisons for Disruption_Category (within-subject factor) for disruption_appraisal
post_hoc_disruption_disrup <- emmeans(anova_disrup_appraisal, pairwise ~ Disruption_Category)

# Extract post-hoc pairwise contrasts for Disruption_Category (Disruption Appraisal)
post_hoc_results_disruption_disrup <- as.data.frame(post_hoc_disruption_disrup$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison), # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))  # Round p-values to 2 decimals
  )

# Perform post-hoc pairwise comparisons for Disruption_Category (within-subject factor) for confidence_appraisal
post_hoc_disruption_confi <- emmeans(anova_confi_appraisal, pairwise ~ Disruption_Category)

# Extract post-hoc pairwise contrasts for Disruption_Category (Confidence Appraisal)
post_hoc_results_disruption_confi <- as.data.frame(post_hoc_disruption_confi$contrasts) %>%
  mutate(
    Comparison = gsub("_", " ", contrast),  # Replace underscores with spaces
    Comparison = gsub("\\.", " ", Comparison), # Replace periods with spaces
    Estimate = round(estimate, 2),
    SE = round(SE, 2),
    t = round(t.ratio, 2),
    p.value = ifelse(p.value < 0.05, "< .05", round(p.value, 2))  # Round p-values to 2 decimals
  )

##################### COHEN'S D CALCULATION ########################

# Calculate Cohen's d for each pairwise comparison for disruption_appraisal
d_LackOfEagerness_vs_Physical_disrup <- CohenD(
  x = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

d_LackOfEagerness_vs_Verbal_disrup <- CohenD(
  x = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

d_Physical_vs_Verbal_disrup <- CohenD(
  x = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  y = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

# Calculate Cohen's d for each pairwise comparison for confidence_appraisal
d_LackOfEagerness_vs_Physical_confi <- CohenD(
  x = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

d_LackOfEagerness_vs_Verbal_confi <- CohenD(
  x = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

d_Physical_vs_Verbal_confi <- CohenD(
  x = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  y = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

##################### COHEN'S D CALCULATION DISRUPTION APPRAISAL ########################

# Calculate Cohen's d for each pairwise comparison for disruption_appraisal
d_LackOfEagerness_vs_Verbal_disrup <- CohenD(
  x = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

d_LackOfEagerness_vs_Physical_disrup <- CohenD(
  x = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

d_Physical_vs_Verbal_disrup <- CohenD(
  x = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  y = df_sri_disrup$disruption_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

###################### ADD MISSING COHEN'S D VALUES ########################

# Add the missing Cohen's d values to the cohen_d_values_disrup vector
cohen_d_values_disrup <- c(
  "Verbal disruptions - Lack of eagerness to learn" = round(d_LackOfEagerness_vs_Verbal_disrup, 2),
  "Physical disruptions - Lack of eagerness to learn" = round(d_LackOfEagerness_vs_Physical_disrup, 2),
  "Physical disruptions - Verbal disruptions" = round(d_Physical_vs_Verbal_disrup, 2),
  "Verbal disruptions - Physical disruptions" = round(d_Physical_vs_Verbal_disrup, 2),  # Add missing comparison
  "Lack of eagerness to learn - Physical disruptions" = round(d_LackOfEagerness_vs_Physical_disrup, 2)  # Add missing comparison
)

# Add Cohen's d values to the post-hoc results for disruption_appraisal
post_hoc_results_disruption_disrup$Cohen_d <- cohen_d_values_disrup[post_hoc_results_disruption_disrup$Comparison]

# Ensure the number of column names matches the number of columns in the data frame
post_hoc_results_disruption_disrup <- post_hoc_results_disruption_disrup %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)


##################### COHEN'S D CALCULATION FOR CONFIDENCE APPRAISAL ########################

# Calculate Cohen's d for each pairwise comparison for confidence_appraisal
d_LackOfEagerness_vs_Physical_confi <- CohenD(
  x = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  na.rm = TRUE
)

d_LackOfEagerness_vs_Verbal_confi <- CohenD(
  x = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Lack of eagerness to learn"],
  y = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

d_Physical_vs_Verbal_confi <- CohenD(
  x = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Physical disruptions"],
  y = df_sri_disrup$confidence_appraisal[df_sri_disrup$Disruption_Category == "Verbal disruptions"],
  na.rm = TRUE
)

##################### ADD MISSING COHEN'S D VALUES FOR CONFIDENCE APPRAISAL ########################

# Create a named vector with the correct Cohen's d values for confidence_appraisal
cohen_d_values_confi <- c(
  "Verbal disruptions - Lack of eagerness to learn" = round(d_LackOfEagerness_vs_Verbal_confi, 2),
  "Physical disruptions - Lack of eagerness to learn" = round(d_LackOfEagerness_vs_Physical_confi, 2),
  "Physical disruptions - Verbal disruptions" = round(d_Physical_vs_Verbal_confi, 2),
  "Verbal disruptions - Physical disruptions" = round(d_Physical_vs_Verbal_confi, 2),  # Add missing comparison
  "Lack of eagerness to learn - Physical disruptions" = round(d_LackOfEagerness_vs_Physical_confi, 2)  # Add missing comparison
)

# Add Cohen's d values to the post-hoc results for confidence_appraisal
post_hoc_results_disruption_confi$Cohen_d <- cohen_d_values_confi[post_hoc_results_disruption_confi$Comparison]

# Ensure the number of column names matches the number of columns in the data frame
post_hoc_results_disruption_confi <- post_hoc_results_disruption_confi %>%
  select(Comparison, Estimate, SE, df, t, p.value, Cohen_d)

##################### TABLE FOR GROUP AND DISRUPTION CATEGORY ########################

# Display the post-hoc test results for Group (Disruption Appraisal)
knitr::kable(
  post_hoc_results_group_disrup,
  caption = "Post-Hoc Pairwise Comparisons for Disruption Appraisal by Group (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
)%>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)

# Display the post-hoc test results for Disruption Category (Disruption Appraisal) with Cohen's d
knitr::kable(
  post_hoc_results_disruption_disrup,
  caption = "Post-Hoc Pairwise Comparisons for Disruption Appraisal by Disruption Category (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


# Display the post-hoc test results for Group (Confidence Appraisal)
knitr::kable(
  post_hoc_results_group_confi,
  caption = "Post-Hoc Pairwise Comparisons for Confidence Appraisal by Group (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)


# Displaying the post-hoc results for Disruption Category (Confidence Appraisal) with Cohen's d
knitr::kable(
  post_hoc_results_disruption_confi,
  caption = "Post-Hoc Pairwise Comparisons for Confidence Appraisal by Disruption Category (Including Effect Sizes)",
  col.names = c("Comparison", "Estimate", "SE", "df", "t", "p", "Cohen's d"),
  digits = 2
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)



# # t-Tests and Effect Sizes -----------------------------------------------
# ## Disruption Appraisal
# disrup_ttest <- t.test(
#   disruption_appraisal ~ ID, data = sri, var.equal = TRUE
# )
# disrup_d <- cohen.d(disruption_appraisal ~ ID, data = sri)
# 
# ## Confidence Appraisal
# confi_ttest <- t.test(
#   confidence_appraisal ~ ID, data = sri, var.equal = TRUE
# )
# confi_d <- cohen.d(confidence_appraisal ~ ID, data = sri)
# 
# ## Prevalence Rating
# preva_ttest <- t.test(
#   prevalence_rating ~ ID, data = sri, var.equal = TRUE
# )
# preva_d <- cohen.d(prevalence_rating ~ ID, data = sri)
# 
# # APA-Conform Tables for t-Tests and Effect Sizes ------------------------
# disrup_stats <- tibble(
#   Statistic = c("t-value", "df", "p-value", "Cohen's d"),
#   Value = c(
#     round(disrup_ttest$statistic, 2),
#     round(disrup_ttest$parameter, 2),
#     round(disrup_ttest$p.value, 2),
#     round(disrup_d$estimate, 2)
#   )
# )
# 
# confi_stats <- tibble(
#   Statistic = c("t-value", "df", "p-value", "Cohen's d"),
#   Value = c(
#     round(confi_ttest$statistic, 2),
#     round(confi_ttest$parameter, 2),
#     round(confi_ttest$p.value, 2),
#     round(confi_d$estimate, 2)
#   )
# )
# 
# preva_stats <- tibble(
#   Statistic = c("t-value", "df", "p-value", "Cohen's d"),
#   Value = c(
#     round(preva_ttest$statistic, 2),
#     round(preva_ttest$parameter, 2),
#     round(preva_ttest$p.value, 2),
#     round(preva_d$estimate, 2)
#   )
# )
# 
# kable(disrup_stats, caption = "t-Test and Effect Size for Disruption Appraisal", digits = 2) %>%
#   kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
# 
# kable(confi_stats, caption = "t-Test and Effect Size for Confidence Appraisal", digits = 2) %>%
#   kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
# 
# kable(preva_stats, caption = "t-Test and Effect Size for Prevalence Rating", digits = 2) %>%
#   kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)


# Omega Calculations -----------------------------------------------------
# Data Import
sri <- excel_sheets("data/Coding_SRI.xlsx") %>%
  map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
  filter(
    !ID %in% c(201, 223), # Exclude specific IDs
    !disruption_appraisal %in% c(-100, -99, -88),
    !confidence_appraisal %in% c(-100, -99, -88),
    !prevalence_rating %in% c(-100, -99, -88)
  )

# Change Long Format to Wide Format
sri_wide <- sri %>%
  pivot_wider(
    names_from = event,
    values_from = c(disruption_appraisal, confidence_appraisal, prevalence_rating)
  )

# Helper Function for Omega Calculation
calculate_omega_total <- function(data, scale_name) {
  if (nrow(data) == 0 || ncol(data) == 0) {
    warning(paste("No valid data for", scale_name))
    return(NA)
  }
  
  # Try Omega Calculation
  result <- tryCatch(
    omega(data),
    error = function(e) {
      warning(paste("Omega calculation failed for", scale_name, ":", e$message))
      return(NULL)
    }
  )
  
  # Check if Result is Valid and Extract omega.tot
  if (is.null(result) || !"omega.tot" %in% names(result)) {
    warning(paste("Omega total not available for", scale_name))
    return(NA)
  }
  
  return(round(result$omega.tot, 2))
}

# Disruption Appraisal ---------------------------------------------------
sri_wide_disrup <- sri_wide %>%
  dplyr::select(starts_with("disruption_appraisal")) %>%
  mutate(across(everything(), ~ as.numeric(.))) %>%
  drop_na()

omega_total_disrup <- calculate_omega_total(sri_wide_disrup, "Disruption Appraisal")

# Confidence Appraisal ---------------------------------------------------
sri_wide_confi <- sri_wide %>%
  dplyr::select(starts_with("confidence_appraisal")) %>%
  mutate(across(everything(), ~ as.numeric(.))) %>%
  drop_na()

omega_total_confi <- calculate_omega_total(sri_wide_confi, "Confidence Appraisal")

# Prevalence Rating ------------------------------------------------------
sri_wide_preva <- sri_wide %>%
  dplyr::select(starts_with("prevalence_rating")) %>%
  mutate(across(everything(), ~ as.numeric(.))) %>%
  drop_na()

omega_total_preva <- calculate_omega_total(sri_wide_preva, "Prevalence Rating")

# APA-Conform Table ------------------------------------------------------
omega_table <- tibble(
  Measure = c("Disruption Appraisal", "Confidence Appraisal", "Prevalence Rating"),
  Omega_Total = c(omega_total_disrup, omega_total_confi, omega_total_preva)
)

# Display APA-Conform Table ----------------------------------------------
kable(omega_table, caption = "Internal Consistency (Omega Total) for Appraisal Measures", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

``` 


### Situational Jugdement Test
```{r sjt, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

# Data Import and Preprocessing ------------------------------------------
df_sjt <- read_excel("./data/SJT.xlsx") %>%
  dplyr::select(
    UI06_05,  # ID
    SJT_AL_gek, # Monitoring
    SJT_ST_gek, # Managing momentum
    SJT_R_gek,  # Rules and routines
    SJT_KF_gek  # All
  ) %>%
  filter(!UI06_05 == 201,
         !UI06_05 == 223) %>% # Exclude specific IDs
  na.omit() %>% # Remove NAs
  rename(
    Group = UI06_05,
    Monitoring = SJT_AL_gek,
    `Managing momentum` = SJT_ST_gek,
    `Rules and routines` = SJT_R_gek,
    All = SJT_KF_gek
  ) %>%
  mutate(Group = ifelse(Group < 200, "Novice", "Expert")) # Define groups

# Reshape Data to Long Format --------------------------------------------
df_sjt_long <- df_sjt %>%
  pivot_longer(
    !Group,
    names_to = "Facets Classroom Management",
    values_to = "Mean"
  )

# Descriptive Statistics Tables ------------------------------------------
## Function to Calculate Descriptive Stats
descriptive_stats <- function(data, facet) {
  data %>%
    filter(`Facets Classroom Management` == facet) %>%
    group_by(Group) %>%
    summarise(
      N = n(),
      M = round(mean(Mean), 2),
      SD = round(sd(Mean), 2),
      Min = round(min(Mean), 2),
      Max = round(max(Mean), 2),
      .groups = "drop"
    )
}

## Generate Tables
sjt_all <- descriptive_stats(df_sjt_long, "All")
sjt_mm <- descriptive_stats(df_sjt_long, "Managing momentum")
sjt_m <- descriptive_stats(df_sjt_long, "Monitoring")
sjt_r <- descriptive_stats(df_sjt_long, "Rules and routines")

## Display APA-Conform Tables
kable(sjt_all, caption = "Descriptive Statistics for Overall SJT Score") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

kable(sjt_mm, caption = "Descriptive Statistics for Managing Momentum") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

kable(sjt_m, caption = "Descriptive Statistics for Monitoring") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

kable(sjt_r, caption = "Descriptive Statistics for Rules and Routines") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Plotting SJT Facets ----------------------------------------------------
mean_plot <- df_sjt_long %>%
  mutate(Group = factor(Group, levels = c("Novice", "Expert"))) %>%
  ggplot(aes(x = Group, y = Mean)) +
  geom_boxplot(aes(fill = Group), outlier.shape = NA) +
  geom_point(
    size = 1,
    alpha = 0.4,
    position = position_jitter(seed = 1, width = 0.1, height = 0.1)
  ) +
  labs(x = "", y = "Mean SJT Score") +
  scale_fill_brewer(palette = "RdBu") +
  facet_wrap(~`Facets Classroom Management`, nrow = 1, strip.position = "bottom") +
  theme_cowplot() +
  ggtitle("SJT Scores by Group") +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_blank(), # Remove x-axis text
    axis.ticks.x = element_blank(), # Remove x-axis ticks
    strip.text = element_text(size = 10) # Increase facet label font size
  )

print(mean_plot)

# Statistical Tests ------------------------------------------------------
## Function to Perform t-Test and Effect Size
t_test_stats <- function(data, group_col, value_col, facet_name) {
  group_col <- ensym(group_col)  # Ensure proper quoting of group column
  value_col <- ensym(value_col)  # Ensure proper quoting of value column
  
  # Perform t-Test
  t_test <- t.test(
    formula = as.formula(paste0("`", quo_name(value_col), "` ~ ", quo_name(group_col))),
    data = data,
    var.equal = TRUE
  )
  
  # Calculate Cohen's d
  cohen_d <- CohenD(
    x = data %>% filter(!!group_col == "Expert") %>% pull(!!value_col),
    y = data %>% filter(!!group_col == "Novice") %>% pull(!!value_col)
  )
  
  tibble(
    `Facet` = facet_name,
    `t-value` = round(t_test$statistic, 2),
    `p-value` = round(t_test$p.value, 2),
    `Cohen's d` = round(cohen_d, 2)
  )
}

## Generate t-Test Tables
t_test_all <- t_test_stats(df_sjt, "Group", "All", "Overall")
t_test_mm <- t_test_stats(df_sjt, "Group", "Managing momentum", "Managing Momentum")
t_test_m <- t_test_stats(df_sjt, "Group", "Monitoring", "Monitoring")
t_test_r <- t_test_stats(df_sjt, "Group", "Rules and routines", "Rules and Routines")

## Combine Results into a Table
t_test_results <- bind_rows(t_test_all, t_test_mm, t_test_m, t_test_r)

## Display APA-Conform Table
kable(t_test_results, caption = "t-Test and Effect Sizes for SJT Facets") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)


# Internal Consistency (Omega) -------------------------------------------
# Read in Data
df_sjt <- read_excel("./data/SJT.xlsx")  # Replace with the correct path

# Helper Function for Omega Calculation
calculate_omega_total <- function(data, scale_name) {
  if (nrow(data) == 0 || ncol(data) == 0) {
    warning(paste("No valid data for", scale_name))
    return(NA)
  }
  
  # Try Omega Calculation
  result <- tryCatch(
    omega(data),
    error = function(e) {
      warning(paste("Omega calculation failed for", scale_name, ":", e$message))
      return(NULL)
    }
  )
  
  # Check if Result is Valid and Extract omega.tot
  if (is.null(result) || !"omega.tot" %in% names(result)) {
    warning(paste("Omega total not available for", scale_name))
    return(NA)
  }
  
  return(round(result$omega.tot, 2))
}

### MANAGING MOMENTUM ----------------------------------------------------
# Select relevant columns and remove NAs
df_sjt_mm <- df_sjt %>%
  dplyr::select(WT_S1_F1F2_AL:WT_S4_F4F6_AL) %>%
  na.omit()

# Calculate omega
omega_mm <- calculate_omega_total(df_sjt_mm, "Managing Momentum")

### MONITORING -----------------------------------------------------------
# Select relevant columns and remove NAs
df_sjt_m <- df_sjt %>%
  dplyr::select(WT_S5_F1F2_ST:WT_S9_F4F5_ST) %>%
  na.omit()

# Calculate omega
omega_m <- calculate_omega_total(df_sjt_m, "Monitoring")

### RULES & ROUTINES -----------------------------------------------------
# Select relevant columns and remove NAs
df_sjt_r <- df_sjt %>%
  dplyr::select(WT_S11_F1F5_R:WT_S14_F4F6_R) %>%
  na.omit()

# Calculate omega
omega_r <- calculate_omega_total(df_sjt_r, "Rules and Routines")

### OVERALL TEST -----------------------------------------------------
# Select relevant columns and remove NAs
df_overall <- df_sjt %>%
  select(matches("WT_S")) %>%
  mutate(across(everything(), as.numeric)) %>%  # Ensure numeric data
  drop_na()

# Calculate omega
omega_overall <- calculate_omega_total(df_overall, "Overall Test")

### COMBINE RESULTS INTO AN APA-CONFORM TABLE ----------------------------
# APA-Conform Table ------------------------------------------------------
omega_results <- tibble(
  Facet = c("Overall Test", "Managing Momentum", "Monitoring", "Rules and Routines"),
  `Omega Total` = c(omega_overall, omega_mm, omega_m, omega_r)
)

# Display APA-Conform Table ----------------------------------------------
kable(omega_results, caption = "Internal Consistency (Omega) for SJT Facets") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

``` 


<!-- ### Self-evaluation (5 classroom management items, 3 disruption handling items, 8 presence items) -->
<!-- ```{r self-eval_5-3-8, echo=FALSE, results='asis'} -->

<!-- # Data Import and Preparation -------------------------------------------- -->
<!-- df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% -->
<!--   filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs -->
<!--   mutate( -->
<!--     Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Group Definition -->
<!--     Participant = LI06_05  # Add new column "Participant" -->
<!--   ) %>% -->
<!--   arrange(Participant) %>%  -->
<!--   select( -->
<!--     Participant,  -->
<!--     Group,  -->
<!--     LM01_01:LM01_05,  # Classroom Management -->
<!--     LM01_06:LM01_08,  # Disruption Handling -->
<!--     LP01_01:LP01_08   # Presence -->
<!--   ) %>% -->
<!--   rename( -->
<!--     CM_01 = LM01_01, CM_02 = LM01_02, CM_03 = LM01_03, CM_04 = LM01_04, CM_05 = LM01_05, -->
<!--     DH_01 = LM01_06, DH_02 = LM01_07, DH_03 = LM01_08, -->
<!--     P_01 = LP01_01, P_02 = LP01_02, P_03 = LP01_03, P_04 = LP01_04, P_05 = LP01_05, -->
<!--     P_06 = LP01_06, P_07 = LP01_07, P_08 = LP01_08 -->
<!--   ) %>% -->
<!--   na.omit()  # Remove NAs -->

<!-- # Create Dataset for Plotting with Overall Measure -------------------------------------------- -->
<!-- df_quest_long <- df_quest %>% -->
<!--   rowwise() %>% -->
<!--   transmute( -->
<!--     Group = Group, -->
<!--     `Classroom Management` = round(mean(c_across(starts_with("CM")), na.rm = TRUE), 2), -->
<!--     `Disruption Handling` = round(mean(c_across(starts_with("DH")), na.rm = TRUE), 2), -->
<!--     `Presence` = round(mean(c_across(starts_with("P") & !starts_with("Participant")), na.rm = TRUE), 2),  # Excluding Participant column -->
<!--     `Overall` = round(mean(c(CM_01, CM_02, CM_03, CM_04, CM_05, DH_01, DH_02, DH_03, P_01, P_02, P_03, P_04, P_05, P_06, P_07, P_08), na.rm = TRUE), 2)  # Correct Overall value -->
<!--   ) %>% -->
<!--   ungroup() %>% -->
<!--   pivot_longer(cols = c(`Classroom Management`, `Disruption Handling`, `Presence`, `Overall`), -->
<!--                names_to = "Scales Self-evaluation", values_to = "Mean") -->

<!-- # Plot Mean Scores by Group ---------------------------------------------- -->
<!-- quest_plot <- df_quest_long %>% -->
<!--   mutate( -->
<!--     Group = factor(Group, levels = c("Novice", "Expert")), -->
<!--     `Scales Self-evaluation` = factor(`Scales Self-evaluation`, levels = c("Classroom Management", "Disruption Handling", "Presence", "Overall"))  # Reorder scales -->
<!--   ) %>% -->
<!--   ggplot(aes(x = Group, y = Mean)) + -->
<!--   geom_boxplot(aes(fill = Group), outlier.shape = NA) + -->
<!--   geom_point( -->
<!--     size = 1, -->
<!--     alpha = 0.4, -->
<!--     position = position_jitter(seed = 1, width = 0.1, height = 0.1) -->
<!--   ) + -->
<!--   labs(x = "", y = "Mean Scores") + -->
<!--   ylim(0, 4) +  -->
<!--   scale_fill_brewer(palette = "RdBu") + -->
<!--   facet_wrap(~`Scales Self-evaluation`, nrow = 1, strip.position = "bottom") + -->
<!--   theme_cowplot() + -->
<!--   ggtitle("Self-Evaluation Scores") + -->
<!--   theme( -->
<!--     plot.title = element_text(size = 25, face = "bold"), -->
<!--     legend.title = element_text(size = 20), -->
<!--     legend.text = element_text(size = 15), -->
<!--     axis.text.x = element_blank(), -->
<!--     axis.ticks.x = element_blank(), -->
<!--     strip.text.x = element_text(size = 8), -->
<!--     axis.title.y = element_text(size = 20) -->
<!--   ) -->

<!-- print(quest_plot) -->

<!-- # t-Test and Effect Sizes ------------------------------------------------ -->

<!-- # t-Test Function for Long Format ---------------------------------------- -->
<!-- t_test_stats_long <- function(data, group_col, scale_filter, scale_name) { -->
<!--   # Subset Data for the Specific Scale -->
<!--   filtered_data <- data %>% -->
<!--     filter(`Scales Self-evaluation` == scale_filter) -->

<!--   # Check if there are exactly two levels in the group -->
<!--   if (length(unique(filtered_data[[group_col]])) != 2) { -->
<!--     warning(paste("Skipping t-test for", scale_name, ": Group must have exactly two levels")) -->
<!--     return(tibble( -->
<!--       `Scale` = scale_name, -->
<!--       `t-value` = NA, -->
<!--       `p-value` = NA, -->
<!--       `Cohen's d` = NA -->
<!--     )) -->
<!--   } -->

<!--   # Perform t-Test -->
<!--   t_test <- t.test( -->
<!--     Mean ~ get(group_col), -->
<!--     data = filtered_data, -->
<!--     var.equal = TRUE -->
<!--   ) -->

<!--   # Calculate Cohen's d -->
<!--   cohen_d <- CohenD( -->
<!--     x = filtered_data %>% filter(!!rlang::sym(group_col) == "Expert") %>% pull(Mean), -->
<!--     y = filtered_data %>% filter(!!rlang::sym(group_col) == "Novice") %>% pull(Mean) -->
<!--   ) -->

<!--   # Return Results -->
<!--   tibble( -->
<!--     `Scale` = scale_name, -->
<!--     `t-value` = round(t_test$statistic, 2), -->
<!--     `p-value` = round(t_test$p.value, 2), -->
<!--     `Cohen's d` = round(cohen_d, 2) -->
<!--   ) -->
<!-- } -->

<!-- # Perform t-Tests for Each Scale -->
<!-- t_test_all <- t_test_stats_long(df_quest_long, "Group", "Overall", "Overall Evaluation") -->
<!-- t_test_cm <- t_test_stats_long(df_quest_long, "Group", "Classroom Management", "Classroom Management") -->
<!-- t_test_npvc <- t_test_stats_long(df_quest_long, "Group", "Disruption Handling", "Disruption Handling") -->
<!-- t_test_presence <- t_test_stats_long(df_quest_long, "Group", "Presence", "Presence") -->

<!-- # Combine Results into a Single Table -->
<!-- t_test_results <- bind_rows(t_test_all, t_test_cm, t_test_npvc, t_test_presence) -->

<!-- # Display Results in APA-Conform Table -->
<!-- kable(t_test_results, caption = "t-Test and Effect Sizes for Self-Evaluation Scales") %>% -->
<!--   kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) -->

<!-- # Internal Consistency (Omega) ------------------------------------------- -->
<!-- # Helper Function for Omega Calculation -->
<!-- calculate_omega_total <- function(data, scale_name) { -->
<!--   if (nrow(data) == 0 || ncol(data) == 0) { -->
<!--     warning(paste("No valid data for", scale_name)) -->
<!--     return(NA) -->
<!--   } -->

<!--   # Try Omega Calculation -->
<!--   result <- tryCatch( -->
<!--     omega(data), -->
<!--     error = function(e) { -->
<!--       warning(paste("Omega calculation failed for", scale_name, ":", e$message)) -->
<!--       return(NULL) -->
<!--     } -->
<!--   ) -->

<!--   # Check if Result is Valid and Extract omega.tot -->
<!--   if (is.null(result) || !"omega.tot" %in% names(result)) { -->
<!--     warning(paste("Omega total not available for", scale_name)) -->
<!--     return(NA) -->
<!--   } -->

<!--   return(round(result$omega.tot, 2)) -->
<!-- } -->

<!-- ### CLASSROOM MANAGEMENT ------------------------------------------------- -->
<!-- # Select relevant columns and remove NAs -->
<!-- df_cm <- df_quest %>% select(starts_with("CM")) -->

<!-- # Calculate omega for Classroom Management -->
<!-- omega_cm <- calculate_omega_total(df_cm, "Classroom Management") -->

<!-- ### DISRUPTION HANDLING -------------------------------------------------- -->
<!-- # Select relevant columns and remove NAs -->
<!-- df_dh <- df_quest %>% select(starts_with("DH")) -->

<!-- # Calculate omega for Disruption Handling -->
<!-- omega_dh <- calculate_omega_total(df_dh, "Disruption Handling") -->

<!-- ### PRESENCE ------------------------------------------------------------ -->
<!-- # Select relevant columns and remove NAs -->
<!-- df_presence <- df_quest %>% select(starts_with("P") & !starts_with("Participant")) -->

<!-- # Calculate omega for Presence -->
<!-- omega_presence <- calculate_omega_total(df_presence, "Presence") -->

<!-- ### OVERALL TEST ----------------------------------------------------- -->
<!-- # Select relevant columns and remove NAs (for overall evaluation) -->
<!-- df_self_all <- df_quest %>% -->
<!--   select(starts_with("CM"), starts_with("DH"), starts_with("P") & !starts_with("Participant")) %>% -->
<!--   mutate(across(everything(), as.numeric)) %>%  # Ensure numeric data -->
<!--   drop_na() -->

<!-- # Calculate omega for Overall Evaluation -->
<!-- omega_self_all <- calculate_omega_total(df_self_all, "Overall Evaluation") -->

<!-- ### COMBINE RESULTS INTO AN APA-CONFORM TABLE ---------------------------- -->
<!-- # APA-Conform Table ------------------------------------------------------ -->
<!-- omega_results <- tibble( -->
<!--   Facet = c("Overall Evaluation", "Classroom Management", "Disruption Handling", "Presence"), -->
<!--   `Omega Total` = c(omega_self_all, omega_cm, omega_dh, omega_presence) -->
<!-- ) -->

<!-- # Display APA-Conform Table ---------------------------------------------- -->
<!-- kable(omega_results, caption = "Internal Consistency (Omega) for Self-evaluation") %>% -->
<!--   kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) -->

<!-- ``` -->


### Self-evaluation (8 classroom management items, 8 presence items)
```{r self-eval_8-8, echo=FALSE, results='asis'}

# Data Import and Preparation --------------------------------------------
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
  filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs
  mutate(
    Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Group Definition
    Participant = LI06_05  # Add new column "Participant"
  ) %>%
  arrange(Participant) %>% 
  select(
    Participant, 
    Group, 
    LM01_01:LM01_08,  # Classroom Management and Disruption Handling combined
    LP01_01:LP01_08   # Presence
  ) %>%
  rename(
    CM_01 = LM01_01, CM_02 = LM01_02, CM_03 = LM01_03, CM_04 = LM01_04, CM_05 = LM01_05,
    CM_06 = LM01_06, CM_07 = LM01_07, CM_08 = LM01_08,  # Renaming combined columns
    P_01 = LP01_01, P_02 = LP01_02, P_03 = LP01_03, P_04 = LP01_04, P_05 = LP01_05,
    P_06 = LP01_06, P_07 = LP01_07, P_08 = LP01_08
  ) %>%
  na.omit()  # Remove NAs

# Create Dataset for Plotting with Combined Scales -------------------------
df_quest_long <- df_quest %>%
  rowwise() %>%
  transmute(
    Group = Group,
    `Classroom Management` = round(mean(c_across(starts_with("CM")), na.rm = TRUE), 2),  # Combine Classroom Management and Disruption Handling
    `Presence` = round(mean(c_across(starts_with("P") & !starts_with("Participant")), na.rm = TRUE), 2),  # Excluding Participant column
    `Overall` = round(mean(c(CM_01, CM_02, CM_03, CM_04, CM_05, CM_06, CM_07, CM_08, P_01, P_02, P_03, P_04, P_05, P_06, P_07, P_08), na.rm = TRUE), 2)  # Correct Overall value
  ) %>%
  ungroup() %>%
  pivot_longer(cols = c(`Classroom Management`, `Presence`, `Overall`),
               names_to = "Scales Self-evaluation", values_to = "Mean")

# Plot Mean Scores by Group ----------------------------------------------
quest_plot <- df_quest_long %>%
  mutate(
    Group = factor(Group, levels = c("Novice", "Expert")),
    `Scales Self-evaluation` = factor(`Scales Self-evaluation`, levels = c("Classroom Management", "Presence", "Overall"))  # Reorder scales
  ) %>%
  ggplot(aes(x = Group, y = Mean)) +
  geom_boxplot(aes(fill = Group), outlier.shape = NA) +
  geom_point(
    size = 1,
    alpha = 0.4,
    position = position_jitter(seed = 1, width = 0.1, height = 0.1)
  ) +
  labs(x = "", y = "Mean Scores") +
  ylim(0, 4) + 
  scale_fill_brewer(palette = "RdBu") +
  facet_wrap(~`Scales Self-evaluation`, nrow = 1, strip.position = "bottom") +
  theme_cowplot() +
  ggtitle("Self-Evaluation Scores") +
  theme(
    plot.title = element_text(size = 25, face = "bold"),
    legend.title = element_text(size = 20),
    legend.text = element_text(size = 15),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    strip.text.x = element_text(size = 8),
    axis.title.y = element_text(size = 20)
  )

print(quest_plot)

# t-Test and Effect Sizes ------------------------------------------------
# t-Test Function for Long Format ----------------------------------------
t_test_stats_long <- function(data, group_col, scale_filter, scale_name) {
  # Subset Data for the Specific Scale
  filtered_data <- data %>%
    filter(`Scales Self-evaluation` == scale_filter)
  
  # Check if there are exactly two levels in the group
  if (length(unique(filtered_data[[group_col]])) != 2) {
    warning(paste("Skipping t-test for", scale_name, ": Group must have exactly two levels"))
    return(tibble(
      `Scale` = scale_name,
      `t-value` = NA,
      `p-value` = NA,
      `Cohen's d` = NA
    ))
  }
  
  # Perform t-Test
  t_test <- t.test(
    Mean ~ get(group_col),
    data = filtered_data,
    var.equal = TRUE
  )
  
  # Calculate Cohen's d
  cohen_d <- CohenD(
    x = filtered_data %>% filter(!!rlang::sym(group_col) == "Expert") %>% pull(Mean),
    y = filtered_data %>% filter(!!rlang::sym(group_col) == "Novice") %>% pull(Mean)
  )
  
  # Return Results
  tibble(
    `Scale` = scale_name,
    `t-value` = round(t_test$statistic, 2),
    `p-value` = round(t_test$p.value, 2),
    `Cohen's d` = round(cohen_d, 2)
  )
}

# Perform t-Tests for Each Scale
t_test_all <- t_test_stats_long(df_quest_long, "Group", "Overall", "Overall Evaluation")
t_test_cm <- t_test_stats_long(df_quest_long, "Group", "Classroom Management", "Classroom Management")
t_test_presence <- t_test_stats_long(df_quest_long, "Group", "Presence", "Presence")

# Combine Results into a Single Table
t_test_results <- bind_rows(t_test_all, t_test_cm, t_test_presence)

# Display Results in APA-Conform Table
kable(t_test_results, caption = "t-Test and Effect Sizes for Self-Evaluation Scales") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Internal Consistency (Omega) -------------------------------------------
# Helper Function for Omega Calculation
calculate_omega_total <- function(data, scale_name) {
  if (nrow(data) == 0 || ncol(data) == 0) {
    warning(paste("No valid data for", scale_name))
    return(NA)
  }
  
  # Try Omega Calculation
  result <- tryCatch(
    omega(data),
    error = function(e) {
      warning(paste("Omega calculation failed for", scale_name, ":", e$message))
      return(NULL)
    }
  )
  
  # Check if Result is Valid and Extract omega.tot
  if (is.null(result) || !"omega.tot" %in% names(result)) {
    warning(paste("Omega total not available for", scale_name))
    return(NA)
  }
  
  return(round(result$omega.tot, 2))
}

### CLASSROOM MANAGEMENT -------------------------------------------------
# Select relevant columns and remove NAs
df_cm <- df_quest %>% select(starts_with("CM"))

# Calculate omega for Classroom Management
omega_cm <- calculate_omega_total(df_cm, "Classroom Management")

### PRESENCE ------------------------------------------------------------
# Select relevant columns and remove NAs
df_presence <- df_quest %>% select(starts_with("P") & !starts_with("Participant"))

# Calculate omega for Presence
omega_presence <- calculate_omega_total(df_presence, "Presence")

### OVERALL TEST -----------------------------------------------------
# Select relevant columns and remove NAs (for overall evaluation)
df_self_all <- df_quest %>%
  select(starts_with("CM"), starts_with("P") & !starts_with("Participant")) %>%
  mutate(across(everything(), as.numeric)) %>%  # Ensure numeric data
  drop_na()

# Calculate omega for Overall Evaluation
omega_self_all <- calculate_omega_total(df_self_all, "Overall Evaluation")

### COMBINE RESULTS INTO AN APA-CONFORM TABLE ----------------------------
# APA-Conform Table ------------------------------------------------------
omega_results <- tibble(
  Facet = c("Overall Evaluation", "Classroom Management", "Presence"),
  `Omega Total` = c(omega_self_all, omega_cm, omega_presence)
)

# Display APA-Conform Table ----------------------------------------------
kable(omega_results, caption = "Internal Consistency (Omega) for Self-evaluation") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

``` 

## Correlations 

```{r correlation, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

# 1. Load and Prepare Data -----------------------------------------------

# Demo Data --------------------------------------------
df_demo <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
  filter(!LI06_05 %in% c(201, 223)) %>%  # Exclude participants without eye-tracking data
  transmute(
    Participant = LI06_05,
    `Teaching Experience` = LI04_01
  ) %>%
  arrange(Participant)

# ET-Measures (Micro-Teaching Unit) - Exclude Disruptive Person --------------------------------------------
df_aoi_numb_dur <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select(
    Participant,
    starts_with("Total_duration_of_fixations"),
    starts_with("Number_of_fixations"),
    starts_with("Average_duration"),
    Duration_of_interval  # Ensure this variable is included
  ) %>%
  dplyr::select(
    -contains("Disruptive_Person")  # Exclude Disruptive Person
  ) %>%
  rowwise() %>%
  transmute(
    Participant,
    Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
    Number_fixation_min_mtu = round(sum(c_across(starts_with("Number_of")), na.rm = TRUE) /
                                      Duration_of_interval_min, 0),
    Average_duration_mtu = round(sum(c_across(starts_with("Total_duration")), na.rm = TRUE) /
                                    sum(c_across(starts_with("Number_of")), na.rm = TRUE), 0),
    GRI_mtu = round(Average_duration_mtu / Number_fixation_min_mtu, 2)
  ) %>%
  select(Participant,
        Number_fixation_min_mtu,
        Average_duration_mtu,
        GRI_mtu) %>% 
  arrange(Participant)


# ET-Measures (AOI Students) - Exclude Disruptive Person --------------------------------------------
df_aoi_stud <- df_aoi %>%
  filter(TOI == "Lesson") %>%
  dplyr::select (
    Group,
    Duration_of_interval,
    Participant,
    "Total_duration_of_fixations.Anna",
    "Total_duration_of_fixations.Bianca",
    "Total_duration_of_fixations.Carl(a)",
    "Number_of_fixations.Anna",
    "Number_of_fixations.Bianca",
    "Number_of_fixations.Carl(a)"
  ) %>%
  rowwise() %>%
  transmute(
    Group = as_factor(Group),
    Duration_of_interval_min = round(Duration_of_interval / 60000, 2),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),
    Participant = Participant,
    Stud_duration_fixation = sum(c_across(starts_with("Total_duration")), na.rm = TRUE),
    Stud_number_fixation = sum(c_across(starts_with("Number_of")), na.rm = TRUE),
    Stud_number_fixation_min = round(Stud_number_fixation / Duration_of_interval_min, 2),
    Average_duration_stud = round(Stud_duration_fixation / Stud_number_fixation, 0)
  ) %>%
  select(Participant,
         Stud_number_fixation_min,
         Average_duration_stud
         ) %>% 
  arrange(Participant) %>% 
  drop_na()


# ET-Measures (AOI Disruptive Person) --------------------------------------------

# Number of fixations per second and Average duration of fixations --------------------------------------------
# Define the different types of disruptions and categories
disruptions <- c("Chatting_with_neighbour", "Clicking_pen", "Drawing", 
                 "Drumming_with_hands", "Head_on_table", "Heckling", 
                 "Looking_at_phone", "Snipping_with_fingers", "Whispering")
verbal_disruptions <- c("Chatting_with_neighbour", "Heckling", "Whispering")
physical_disruptions <- c("Clicking_pen", "Drumming_with_hands", "Snipping_with_fingers")
lack_of_eagerness <- c("Looking_at_phone", "Head_on_table", "Drawing")

# Step 1: Filter and prepare the data for both fixation counts and average durations
df_aoi_disrup <- df_aoi %>%
  filter(TOI %in% disruptions) %>%  # Filter rows based on the disruption list
  select(Group, Participant, TOI, 
         Duration_of_interval, 
         "Number_of_fixations.Disruptive_Person", 
         "Total_duration_of_fixations.Disruptive_Person") %>%
  mutate(
    Group = as_factor(Group),  # Convert Group column to a factor
    Disruption_Category = case_when(  # Assign categories based on disruption type
      TOI %in% verbal_disruptions ~ "Verbal disruptions",
      TOI %in% physical_disruptions ~ "Physical disruptions",
      TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    ),
    Duration_of_interval_sec = round(Duration_of_interval / 1000, 2),  # Convert duration to seconds
    Disrup_average_fixations = round(Total_duration_of_fixations.Disruptive_Person / 
                                     `Number_of_fixations.Disruptive_Person`, 2)  # Average duration in seconds
  ) %>%
  filter(!is.na(Disruption_Category))  # Remove rows with NA in disruption category

# Step 2: Summarize data by disruption category
disruption_summary <- df_aoi_disrup %>%
  group_by(Group, Participant, Disruption_Category) %>%
  summarise(
    total_duration_sec = round(sum(Duration_of_interval_sec, na.rm = TRUE), 2),  # Total time in seconds
    fixation_count = round(sum(`Number_of_fixations.Disruptive_Person`, na.rm = TRUE), 2),  # Total fixations
    Disrup_fixations_per_second = round(fixation_count / total_duration_sec, 2),  # Fixation rate per second
    Disrup_average_fixations = round(mean(Disrup_average_fixations, na.rm = TRUE), 2),  # Average disruption fixations duration
    .groups = "drop"
  )

# Step 3: Summarize by participant
df_aoi_disrup <- disruption_summary %>%
  group_by(Group, Participant) %>%
  summarise(
    Disrup_fixations_per_second = round(mean(Disrup_fixations_per_second, na.rm = TRUE), 2),  # Mean fixation rate per participant
    Disrup_average_fixations = round(mean(Disrup_average_fixations, na.rm = TRUE), 2),  # Mean disruption fixation duration per participant
    .groups = "drop"
  ) %>% 
  select(Participant, Disrup_fixations_per_second, Disrup_average_fixations) %>%  # Select only relevant columns
  arrange(Participant)

# Time to first fixation on AOI Disruptive Person --------------------------------------------
# Step 1: Data Preparation
df_ttff_disrup <- df_aoi %>%
  filter(TOI %in% c(verbal_disruptions, physical_disruptions, lack_of_eagerness)) %>%
  dplyr::select(
    Participant,
    TOI,
    Time_to_first_fixation.Disruptive_Person
  ) %>%
  mutate(
    Group = ifelse(Participant < 200, "Novice", "Expert"),  # Assigning Group based on Participant
    Disruption_Category = case_when(
      TOI %in% verbal_disruptions ~ "Verbal disruptions",
      TOI %in% physical_disruptions ~ "Physical disruptions",
      TOI %in% lack_of_eagerness ~ "Lack of eagerness to learn",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(Disruption_Category)) %>% # Keep only rows with valid categories
  drop_na() %>%
  filter(
    Time_to_first_fixation.Disruptive_Person > 0, # Exclude zero fixation times
    Time_to_first_fixation.Disruptive_Person <= 30000 # Cut-off at 30 seconds
  ) %>%
  mutate(
    Disrup_time_fixation_sec = round(Time_to_first_fixation.Disruptive_Person / 1000, 2)
  )

# Summarize the Disrup_time_fixation_sec by Participant
df_ttff_disrup_participant_summary <- df_ttff_disrup %>%
  group_by(Participant) %>%
  summarise(
    Disrup_time_fixation_sec = round(mean(Disrup_time_fixation_sec, na.rm = TRUE), 2), # Average time to first fixation per participant
    .groups = "drop"
  ) %>% 
  arrange(Participant)

# SRI Rating Data --------------------------------------------
# Data Import and Preprocessing ------------------------------------------
df_sri <- excel_sheets("data/Coding_SRI.xlsx") %>%
  map_df(~ read_xlsx("data/Coding_SRI.xlsx", .)) %>%
  filter(
    !ID %in% c(201, 223),  # Removing invalid IDs
    !disruption_appraisal %in% c(-100, -99, -88),  # Removing invalid disruption appraisals
    !confidence_appraisal %in% c(-100, -99, -88),  # Removing invalid confidence appraisals
    !prevalence_rating %in% c(-100, -99, -88)  # Removing invalid prevalence ratings
  ) %>%
  mutate(
    Group = ifelse(ID < 200, "Novice", "Expert"),  # Create a Group column based on ID
    Participant = ID,  # Keep ID as is for Participant column
    Disruption_Appraisal = as.numeric(disruption_appraisal),
    Confidence_Appraisal = as.numeric(confidence_appraisal),
    Prevalence_Rating = as.numeric(prevalence_rating)
  ) %>%
  select(-ID) %>% # Remove the original ID column after renaming
  arrange(Participant)

# Summarize the SRI Data for Disruptions and Overall Columns

# Step 1: Filter for specific disruptions
verbal_disruptions <- c("whispering", "chatting")
lack_of_eagerness <- c("drawing", "looking at phone")

# Step 2: Summarize appraisals for each disruption
df_sri_disrup_summary <- df_sri %>%
  filter(event %in% c(verbal_disruptions, lack_of_eagerness)) %>%
  group_by(Participant, event) %>%
  summarise(
    Disruption_Appraisal_Mean = mean(disruption_appraisal, na.rm = TRUE),
    Confidence_Appraisal_Mean = mean(confidence_appraisal, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_wider(
    names_from = event,
    values_from = c(Disruption_Appraisal_Mean, Confidence_Appraisal_Mean),
    names_sep = "_"
  ) %>%
  mutate(across(everything(), ~ replace_na(., 0))) %>%   # Replace missing values with 0
  arrange(Participant)

# Step 3: Summarize overall appraisals by Participant
df_sri_clean <- df_sri %>%
  group_by(Participant) %>%
  summarise(
    Disruption_Appraisal = round(mean(Disruption_Appraisal, na.rm = TRUE), 2),
    Confidence_Appraisal = round(mean(Confidence_Appraisal, na.rm = TRUE), 2),
    Prevalence_Rating = round(mean(Prevalence_Rating, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(Participant)

# Combine both summaries (disruption-specific and overall)
df_sri_combined <- full_join(df_sri_clean, df_sri_disrup_summary, by = "Participant")


# Situational Judgment Test (SJT) --------------------------------------------
df_sjt <- read_excel("./data/SJT.xlsx") %>%
  filter(!UI06_05 %in% c(201, 223)) %>%
  transmute(
    Participant = UI06_05,
    SJT_All = round(SJT_KF_gek, 2),
    SJT_Monitoring = round(SJT_AL_gek, 2)
  ) %>%
  arrange(Participant)


# Self-Evaluation Data --------------------------------------------
# Data Import and Preparation
df_quest <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
  filter(LI06_05 != 201, LI06_05 != 223) %>%  # Exclude specific IDs
  mutate(
    Group = ifelse(LI06_05 < 200, "Novice", "Expert"),  # Group Definition
    Participant = LI06_05  # Add new column "Participant"
  ) %>%
  arrange(Participant) %>% 
  select(
    Participant, 
    Group, 
    LM01_01:LM01_08,  # Classroom Management and Disruption Handling combined
    LP01_01:LP01_08   # Presence
  ) %>%
  rename(
    CM_01 = LM01_01, CM_02 = LM01_02, CM_03 = LM01_03, CM_04 = LM01_04, CM_05 = LM01_05,
    CM_06 = LM01_06, CM_07 = LM01_07, CM_08 = LM01_08,  # Renaming combined columns
    P_01 = LP01_01, P_02 = LP01_02, P_03 = LP01_03, P_04 = LP01_04, P_05 = LP01_05,
    P_06 = LP01_06, P_07 = LP01_07, P_08 = LP01_08
  ) %>%
  na.omit()  # Remove NAs

# Summarize the scales to a mean per participant, rounded to 2 decimals
df_quest_summary <- df_quest %>%
  mutate(
    # Calculate mean for Classroom Management (CM)
    Self_Eval_CM = round(rowMeans(select(., starts_with("CM")), na.rm = TRUE), 2),
    # Calculate mean for Presence (P), excluding the Participant column
    Self_Eval_Presence = round(rowMeans(select(., starts_with("P"))[, -1], na.rm = TRUE), 2) # Exclude Participant column
  ) %>%
  select(Participant, Self_Eval_CM, Self_Eval_Presence) %>% # Keep Participant and means for each scale
  arrange(Participant)


# 2. Combine All Data ---------------------------------------------------

# Ensure Participant is consistent across all dataframes
df_demo <- df_demo %>% mutate(Participant = as.numeric(Participant))
df_aoi_numb_dur <- df_aoi_numb_dur %>% mutate(Participant = as.numeric(Participant))
df_aoi_stud <- df_aoi_stud %>% mutate(Participant = as.numeric(Participant))
df_aoi_disrup <- df_aoi_disrup %>% mutate(Participant = as.numeric(Participant))
df_ttff_disrup_participant_summary <- df_ttff_disrup_participant_summary %>% mutate(Participant = as.numeric(Participant))
df_sri_combined <- df_sri_combined %>% mutate(Participant = as.numeric(Participant))
df_sjt <- df_sjt %>% mutate(Participant = as.numeric(Participant))
df_quest_summary <- df_quest_summary %>% mutate(Participant = as.numeric(Participant))

# Merge the dataframes
df_list <- list(
  df_demo,
  df_aoi_numb_dur,
  df_aoi_stud,
  df_aoi_disrup,
  df_ttff_disrup_participant_summary,
  df_sri_combined,
  df_sjt,
  df_quest_summary
)

# Combine all dataframes by Participant
df_merge <- reduce(df_list, full_join, by = "Participant")

# Load required libraries
library(tidyverse)
library(Hmisc)
library(knitr)
library(kableExtra)

# 3. Correlation Analysis: Overall ---------------------------------------------

# Select relevant variables for correlation analysis

df_correlation <- df_merge %>%
  select(
    Participant,
    `Teaching Experience`, 
    Number_fixation_min_mtu, 
    Average_duration_mtu, 
    GRI_mtu, 
    Stud_number_fixation_min, 
    Average_duration_stud, 
    Disrup_fixations_per_second, 
    Disrup_average_fixations, 
    Disrup_time_fixation_sec, 
    Disruption_Appraisal, 
    Confidence_Appraisal, 
    Prevalence_Rating,
    Disruption_Appraisal_Mean_chatting,
    Disruption_Appraisal_Mean_drawing,
    Disruption_Appraisal_Mean_whispering,
    Confidence_Appraisal_Mean_chatting,
    Confidence_Appraisal_Mean_drawing,
    Confidence_Appraisal_Mean_whispering,
    SJT_All, 
    SJT_Monitoring, 
    Self_Eval_CM, 
    Self_Eval_Presence
  )

# Compute correlation coefficients and p-values for the full dataset
cor_results <- rcorr(as.matrix(df_correlation))
cor_matrix <- as.data.frame(cor_results$r)  # Extract correlation coefficients
p_matrix <- as.data.frame(cor_results$P)   # Extract p-values

# Reshape correlation coefficients and p-values into a tidy format
correlation_pvalues <- cor_matrix %>%
  rownames_to_column(var = "Variable1") %>%
  pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
  left_join(
    p_matrix %>%
      rownames_to_column(var = "Variable1") %>%
      pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
    by = c("Variable1", "Variable2")
  ) %>%
  mutate(
    Correlation = round(Correlation, 2),  # Round correlation coefficients
    P_value = round(P_value, 2),          # Round p-values
    APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))  # Format APA style
  )

# Create an APA-style table
correlation_table <- correlation_pvalues %>%
  select(Variable1, Variable2, APA_Format) %>%
  pivot_wider(
    names_from = Variable2,
    values_from = APA_Format
  )

# Display the table
kable(correlation_table, format = "html", caption = "Correlation Table: Overall") %>%
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))


# 4. Correlation Analysis: Experts ---------------------------------------------

# Filter data for Experts (Participants with ID > 200)
df_experts <- df_merge %>%
  filter(Participant > 200) %>% 
  select(-Participant)

# Compute correlation coefficients and p-values for Experts
cor_results_experts <- rcorr(as.matrix(df_experts))
cor_matrix_experts <- as.data.frame(cor_results_experts$r)  # Extract correlation coefficients
p_matrix_experts <- as.data.frame(cor_results_experts$P)   # Extract p-values

# Reshape data into tidy format for Experts
correlation_pvalues_experts <- cor_matrix_experts %>%
  rownames_to_column(var = "Variable1") %>%
  pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
  left_join(
    p_matrix_experts %>%
      rownames_to_column(var = "Variable1") %>%
      pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
    by = c("Variable1", "Variable2")
  ) %>%
  mutate(
    Correlation = round(Correlation, 2),
    P_value = round(P_value, 2),
    APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
  )

# Create an APA-style table for Experts
correlation_table_experts <- correlation_pvalues_experts %>%
  select(Variable1, Variable2, APA_Format) %>%
  pivot_wider(
    names_from = Variable2,
    values_from = APA_Format
  )

# Display the Experts table
kable(correlation_table_experts, format = "html", caption = "Correlation Table: Experts") %>%
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))


# 5. Correlation Analysis: Novices ---------------------------------------------

# Filter data for Novices (Participants with ID < 200)
df_novices <- df_merge %>%
  filter(Participant < 200) %>% 
  select(-`Teaching Experience`,
         -Participant)

# Compute correlation coefficients and p-values for Novices
cor_results_novices <- rcorr(as.matrix(df_novices))
cor_matrix_novices <- as.data.frame(cor_results_novices$r)  # Extract correlation coefficients
p_matrix_novices <- as.data.frame(cor_results_novices$P)   # Extract p-values

# Reshape data into tidy format for Novices
correlation_pvalues_novices <- cor_matrix_novices %>%
  rownames_to_column(var = "Variable1") %>%
  pivot_longer(-Variable1, names_to = "Variable2", values_to = "Correlation") %>%
  left_join(
    p_matrix_novices %>%
      rownames_to_column(var = "Variable1") %>%
      pivot_longer(-Variable1, names_to = "Variable2", values_to = "P_value"),
    by = c("Variable1", "Variable2")
  ) %>%
  mutate(
    Correlation = round(Correlation, 2),
    P_value = round(P_value, 2),
    APA_Format = paste0(Correlation, ifelse(P_value < 0.05, "*", ""))
  )

# Create an APA-style table for Novices
correlation_table_novices <- correlation_pvalues_novices %>%
  select(Variable1, Variable2, APA_Format) %>%
  pivot_wider(
    names_from = Variable2,
    values_from = APA_Format
  )

# Display the Novices table
kable(correlation_table_novices, format = "html", caption = "Correlation Table: Novices") %>%
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover", "condensed"))

```



