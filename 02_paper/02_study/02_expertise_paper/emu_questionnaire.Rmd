---
title: "EMU Questionnaire - Item & Scale Analysis"
output:
  pdf_document: default
  html_notebook: default
---

# Load packages
```{r include=FALSE}
# install.packages("needs")

# suppress "summarize" info. 
# if this line is ommitted, each table using the summarize function will be accompanied with a warning from the console
options(dplyr.summarise.inform = FALSE)

library(needs)
needs(tidyverse,
      lubridate,
      viridis,
      grid,
      gridExtra,
      cowplot,
      readxl,
      ARTofR,
      moments,
      ltm,
      sjPlot,
      kableExtra,
      xtable,
      DescTools,
      formattable,
      psych,
      psy,
      nFactors)

```


# Presence Questionnaire

After each micro-teaching-unit, participants answered items on teaching quality using a validated questionnaire [@helmke2014unterrichtsdiagnostik] and self developed scales on the teacher's presence behavior derived from the research literature. The questionnaire was a 4-point Likert scale (1 = Strongly Disagree; 4 = Strongly Agree).

# Scale analysis --> Classroom Management with 16 Items 
```{r presence_questionnaire, echo=FALSE, results=TRUE}

# load data files with modified scales
quest.data1 <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
  dplyr::select(LM01_01:LM01_08,
                LP01_01:LP01_08) %>% 
  rename(LM09 = LP01_01,
         LM10 = LP01_02,
         LM11 = LP01_03,
         LM12 = LP01_04,
         LM13 = LP01_05,
         LM14 = LP01_06,
         LM15 = LP01_07,
         LM16 = LP01_08)

# creating a matrix
quest.table1 <- matrix(data = NA, nrow = 1, ncol = 8)
rownames(quest.table1) <- c("LM")
colnames(quest.table1) <- c("N Items","M","SD","Min","Max","Skewness","Kurtosis","Alpha")

# creating a loop
i <- "LM"

for (i in c("LM")) {

loop.data <- quest.data1 %>%
  dplyr::select(starts_with(match = i))

quest.table1[i, "N Items"] <- length(loop.data)

# calculating mean
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  mean() %>%
  round(., digits = 2) ->
quest.table1[i, "M"]

# calculating SD
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  sd() %>%
  round(., digits = 2) ->
quest.table1[i, "SD"]

# calculating Min
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  min() %>%
  round(., digits = 2) ->
quest.table1[i, "Min"]

# calculating Max
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  max() %>%
  round(., digits = 2) ->
quest.table1[i, "Max"]

# calculating Skewness
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  skewness() %>%
  round(., digits = 2) ->
quest.table1[i, "Skewness"]

# calculating Kurtosis
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  kurtosis() %>%
  round(., digits = 2) ->
quest.table1[i, "Kurtosis"]

# calculating Alpha
alpha <- loop.data %>%
  cronbach.alpha()

quest.table1[i, "Alpha"] <- round(alpha$alpha,2)

# # calculating Alpha
# omega <- loop.data %>% 
#   omega()

}

# rename columns
rownames(quest.table1) <- c("Classroom Management")

# format and insert table in manuscript
knitr::kable(
quest.table1,
  caption = "Scale analysis for teachers' self-assessment",
  # note = "Write Note here",
  escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
  placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
  font_size = "tiny" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)

quest.data1 %>%
  dplyr::select(contains("LM")) %>%
  as.data.frame() %>%
  tab_itemscale(CSS = list(
    css.firsttablerow.col7 = "'cronbachs alpha';"
  ))
```

# Scale analysis --> Classroom Management (8 Items) and Presence (8 Items) 
```{r presence_questionnaire, echo=FALSE, results=TRUE}

# load data files with modified scales
quest.data2 <- read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>%
  dplyr::select(LM01_01:LM01_08,
                LP01_01:LP01_08)

# creating a matrix
quest.table2 <- matrix(data = NA, nrow = 2, ncol = 8)
rownames(quest.table2) <- c("LM", "LP")
colnames(quest.table2) <- c("N Items","M","SD","Min","Max","Skewness","Kurtosis","Alpha")

# creating a loop
i <- "LM"

for (i in c("LM")) {

loop.data <- quest.data2 %>%
  dplyr::select(starts_with(match = i))

quest.table2[i, "N Items"] <- length(loop.data)

# calculating mean
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  mean() %>%
  round(., digits = 2) ->
quest.table2[i, "M"]

# calculating SD
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  sd() %>%
  round(., digits = 2) ->
quest.table2[i, "SD"]

# calculating Min
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  min() %>%
  round(., digits = 2) ->
quest.table2[i, "Min"]

# calculating Max
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  max() %>%
  round(., digits = 2) ->
quest.table2[i, "Max"]

# calculating Skewness
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  skewness() %>%
  round(., digits = 2) ->
quest.table2[i, "Skewness"]

# calculating Kurtosis
loop.data %>%
  mutate(mean = rowMeans(.)) %>%
  pull(mean) %>%
  kurtosis() %>%
  round(., digits = 2) ->
quest.table2[i, "Kurtosis"]

# calculating Alpha
alpha <- loop.data %>%
  cronbach.alpha()

quest.table2[i, "Alpha"] <- round(alpha$alpha,2)

}

# rename columns
rownames(quest.table2) <- c("Classroom Management", "Presence")

# format and insert table in manuscript
knitr::kable(
quest.table2,
  caption = "Scale analysis for teachers' self-assessment",
  # note = "Write Note here",
  escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
  placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
  font_size = "tiny" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)

quest.data2 %>%
  dplyr::select(contains("LM")) %>%
  as.data.frame() %>%
  tab_itemscale(CSS = list(
    css.firsttablerow.col7 = "'cronbachs alpha';"
  ))

quest.data2 %>%
  dplyr::select(contains("LP")) %>%
  as.data.frame() %>%
  tab_itemscale()

```


```{r item_analysis_balance, echo=FALSE, results='asis'}
quest.data %>%
  dplyr::select(contains("LB")) %>%
  as.data.frame() %>%
  tab_itemscale()
```

```{r item_analysis_presence, echo=FALSE, results='asis'}
quest.data %>%
  dplyr::select(contains("LP")) %>%
  as.data.frame() %>%
  tab_itemscale()
```

```{r item_analysis_behavior, echo=FALSE, results='asis'}
quest.data %>%
  dplyr::select(contains("LV")) %>%
  as.data.frame() %>%
  tab_itemscale()
```

```{r item_analysis_additional, echo=FALSE, results='asis'}
quest.data %>%
  dplyr::select(contains("LZ")) %>%
  as.data.frame() %>%
  tab_itemscale()
```

# Exploratory factor analysis
```{r item_analysis_additional, echo=FALSE, results='asis'}

## Bartlett-Test 
# --> prüft, ob Items miteinander korrelieren; das sollten sie tun

cortest.bartlett(quest.data)

# p < .05 --> p signifikant, d.h. Items korrelieren

## Kaiser-Meyer-Olkin-Kriterium (KMO-Werte) Measure of Adequacy (MSA) prüfen 
# gibt an, ob ein Datensatz für eine Faktorenanalyse geeignet ist
# --> KMO & MSA-Werte sollten größer als 0.5 sein

KMO(quest.data)

# overall MSA = 0.7
# einzelne MSA-Werte checken; sollten auch alle größer als 0.5 sein

# Item "LZ01_06 Ich habe vieles mit kurzen Blicken und knappen Gesten geregelt" hat einen Wert von 0.43 --> Ausschluss 

# quest.data[, !names(quest.data) %in% c("LZ01_06")] -> clean.data.quest
# KMO(clean.data.quest)

## Anzahl Faktoren mit MAP-Test (unter anderem) 
# durch verschiedene Methoden wird optimale Anzahl an Faktoren ermittelt
# MAP-Test wird häufig empfohlen 
# mit Varimax-Rotation (macht Sinn, da man die Interpretierbarkeit der Faktoren verbessert) und ML-Faktorenanalyse

nfactors(clean.data.quest, 
         rotate = "varimax", 
         fm = "mle")

# MAP-Wert = 2 Faktoren

## Anzahl Faktoren kann auch mit Parallelanalyse bestimmt werden

ev <- eigen(cor(quest.data))
ap <- parallel(subject = nrow(quest.data),
               var = ncol(quest.data),
               rep = 100,
               cent = .05)
nS <- nScree(x = ev$values,
             aparallel = ap$eigen$qevpea)
plotnScree(nS)

# Parallel Analysis n = 2 factors

###################################################

## Maximum-Likelihood-Faktorenanalyse
# passt methodisch am besten, wenn man noch eine konfirmatorische Faktorenanalyse machen will
# n Faktoren
# Varimax-Rotation

fit1 <- factanal(x = clean.data.quest,
                 factors = 4, # inhaltlich macht es keinen Sinn, nur 2 Faktoren anzunehmen
                 rotation = "varimax")

# Ergebnisse ausgeben lassen mit 2 Dezimalstellen und Faktorenladung < 0.3 unterdrückt

print(fit1, 
      digits = 2,
      cutoff = .3)

# wir sehen Faktorladungen, um die Faktoren zu interpretieren
# Faktorladungen wurden nur ausgegeben, wenn sie größer als 0.3 und -0.3 waren (um nur große Faktorladungen zu sehen)
# weiter unten: erklärte Varianz (Cumulative Var = 0.29) und wie ist Zuwachs der erklärten Varianz durch einzelne Faktoren
# zurück zu Faktorladungen: ideal wäre eigentlich, wenn jedes Item nur auf einen Faktor lädt

# Mit Uniquenesses kann Kommunalität berechnet werden
# --> zeigen an, wie viel Varianz von den einzelnen Items durch die Faktoren erklärt wird (wie wichtig sind die einzelnen Items für Lösung)

1-fit1$uniquenesses

# Screeplot zur Visualisierung

scree.plot(fit1$correlation)


###################################################

## Hauptachsenfaktorenanalyse
# 4 Faktoren
# Varimax-Rotation

fit2 <- fa(r = clean.data.quest, 
           nfactors = 4, 
           rotate = "varimax",
           cutoff = .3)

# Ergebnisse ausgeben

fit2

# Faktorladungen ausgeben

fit2$loadings

# Kommunalitäten ausgeben

fit2$communality

# Sceeplot 

plot(fit2$values, 
     type = "b")

###################################################

## Hauptkomponentenanalyse
# 2 Faktoren
# Varimax-Rotation

fit3 <- principal(r = quest.data,
                  nfactors = 2, 
                  rotate = "varimax")

# Ergebnisse ausgeben

print(loadings(fit3), cutoff= .3)


# Faktorladungen ausgeben

fit3$loadings

# Kommunalitäten ausgeben

fit3$communality

# Sceeplot 

plot(fit3$values, 
     type = "b")

```
