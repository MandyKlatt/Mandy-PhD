---
title: "Fitbit & ET Glasses - Methods"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Packages
# install.packages("needs")
# Choose "No"
library(needs)
needs(tidyverse,
      janitor,
      lubridate,
      readxl,
      ggthemes,
      gridExtra,
      imputeTS,
      DescTools,
      cowplot,
      rstatix,
      ggpubr,
      psych,
      stargazer,
      lmtest,
      sandwich,
      car)

```


# Initial Preparations

Run following Code only if new data is added to the initial data.

```{r message=FALSE, warning=FALSE,include=FALSE}
# fitbit data
# source(file = "data.wrangling.R")
# 
# # demographic data
# # prepare data (selected from questionnaire data)
# demo.data <- readxl::read_xlsx("./Data/data_empschul_labor_lehrperson.xlsx") 
# 
# # select relevant columns
# demo.data <- demo.data %>% select(LI02_01_1,
#                                   LI03_01,
#                                   LI04_01,
#                                   LI06_05)
# 
# # rename columns
# demo.data <- rename(demo.data, c("ID" = "LI06_05",
#                                   "Gender" = "LI02_01_1",
#                                   "Age" = "LI03_01",
#                                   "Teaching Experience" = "LI04_01"))
# 
# # exclude cases with no fitbit data
# demo.data <- demo.data %>% filter(!ID %in% c("126",
#                                              "132",
#                                              )
#                                   )


```

# FitBit

All participants were given a FitBit Smart Watch to wear during the experiment. 

## Heart Rate

```{r}
# # aggregate data 
# 
# df_heart_all <-
#   read_rds(file = "data/heart_all.rds") |> 
#   mutate(status = factor(status,
#                          levels = c("Expert","Novice"),
#                          labels = c("Expert","Novice")
#                          )
#          )
# 
# df_heart_min <-
#   read_rds(file = "data/heart_min.rds")
# 
# df_heart_aggr <- 
#   read_rds(file = "data/heart_aggr.rds") |> 
#   mutate(status = factor(status,
#                          levels = c("Novice","Expert"),
#                          labels = c("Novice","Expert")
#                          )
#          )
# 
# 
# # Mean, SD and Cohen D for experts & novices
# # novices
# mean_nov <- 
#   df_heart_aggr %>%
#   filter(status == "Novice" ) %>% 
#   pull(mean) %>% 
#   mean() %>% 
#   round(., digits = 0)
# 
# sd_nov <- 
#   df_heart_aggr %>%
#   filter(status == "Novice") %>% 
#   pull(mean) %>% 
#   sd() %>% 
#   round(., digits = 0)
# 
# # experts
# mean_exp <-
#   df_heart_aggr %>%
#   filter(status == "Expert") %>% 
#   pull(mean) %>% 
#   mean() %>% 
#   round(., digits = 0)
# 
# sd_exp <- 
#   df_heart_aggr %>%
#   filter(status == "Expert") %>% 
#   pull(mean) %>% 
#   sd() %>% 
#   round(., digits = 0)
# 
# # effect size for expertise differences
# d_heartrate <- CohenD(x = df_heart_aggr$mean[df_heart_aggr$status == "Expert"],
#                y = df_heart_aggr$mean[df_heart_aggr$status == "Novice"],
#                na.rm = TRUE)

```


The heart rate of each participant were measured during the experiment.

```{r}
# # Plots
# 
# ############## FLOW PLOT #############
# plot_flow <-
# ggplot(data = df_heart_all,
#        mapping = aes(x = as.numeric(Time),
#                      y = `Heart Rate`,
#                      group = ID)
#        ) +
#   geom_line(mapping = aes(color = status),
#             size = 0.3,
#             alpha = 1
#             ) +
#   xlim(0, 600) +
#   scale_color_viridis_d(option = "A",
#                        end = 0.8)  +
#   scale_linetype_manual(values = c(1, 6)) +
#   labs(x = "Time (in Seconds)",
#        y = "Heart Rate\n(in Beats per Minute)") +
#   theme_minimal() +
#   theme(text = element_text(family = "serif"),
#         legend.position = "none",
#         strip.text = element_text(size = 16)) +
#   facet_grid(cols = vars(Type),
#              scales = "free_x")
# 
# ############### FLOW PLOT EXPERT NOVICE #############
# 
# plot_flow_leg <-
# ggplot(data = df_heart_all,
#        mapping = aes(x = Time,
#                      y = `Heart Rate`
#                      )
#        ) +
#   xlim(0, 600) +
#   geom_smooth(mapping = aes(color = status),
#               method = "loess") +
#   scale_color_viridis_d(option = "A",
#                         end = 0.8) +
#   scale_linetype_manual(values = c(1, 6)) +
#   labs(x = "Time (in Seconds)",
#        y = "Heart Rate\n(in Beats per Minute)") +
#   ggtitle("Experts' and novices' heart rate per phase") +
#   theme_minimal() +
#   theme(text = element_text(family = "serif"),
#         legend.text = element_text(size = 15),
#         legend.title = element_blank(),
#         axis.text.x = element_text(size = 12),
#         axis.text.y = element_text(size = 10),
#         strip.text = element_text(size = 16),
#         plot.title = element_text(size = 20, 
#                                   face = "bold")) +
#   facet_grid(cols = vars(Type),
#              scales = "free_x")
# 
# legend <- cowplot::get_legend(plot_flow_leg)
# 
# # saving plot 
# ggsave(plot = plot_flow_leg,
#        filename = "Plots/plot_flow_leg.svg",
#        height = 5,
#        width = 8,
#        units = "in")
# 
# ############### LOESS PLOT #############
# 
# plot_loess <-
# ggplot(data = filter(df_heart_all),
#        mapping = aes(x = as.numeric(Time),
#                      y = `Heart Rate`
#                      )
#        ) +
#   stat_smooth(geom = "line",
#               mapping = aes(color = status),
#               method = "loess",
#               se = FALSE) +
#   xlim(0,600) +
#   scale_color_viridis_d(option = "A",
#                         end = 0.8) +
#   scale_linetype_manual(values = c(1, 6)) +
#   labs(x = "Time (in Seconds)",
#        y = "Heart Rate\n(in Beats per Minute)") +
#   theme_minimal() +
#   facet_grid(cols = vars(Type),
#              scales = "free_x",
#              ) +
#   theme(text = element_text(family = "serif"),
#         legend.position = "none",
#         strip.background = element_blank(),
#         strip.text.x = element_blank()
#         )
# 
# 
# ############### BOX PLOT #############
# 
# ##### Box 1 Plot ##### 
# plot_box1 <- 
# ggplot(data = df_heart_aggr,
#        mapping = aes(x = Type,
#                      y = mean,
#                      color = status
#                      )
#        ) +
#   geom_boxplot(color = "darkgrey",
#                fill = "grey") +
#   geom_line(data = filter(df_heart_aggr,
#                           status == "Novice"),
#             mapping = aes(x = Type,
#                           y = mean,
#                           group = as_factor(ID)
#                           ),
#             linetype = 1,
#             alpha = 0.5
#             ) +
#   geom_line(data = filter(df_heart_aggr,
#                           status == "Expert"),
#             mapping = aes(x = Type,
#                           y = mean,
#                           group = as_factor(ID)
#                           ),
#             linetype = 6,
#             alpha = 0.5
#             ) +
#   geom_point(size = 2,
#              alpha = 0.5) +
#   labs(x = "",
#        y = "Average Heart Rate\n(in Beats per Minute)") +
#   scale_color_viridis_d(option = "A",
#                        end = 0.8) +
#   theme_minimal() +
#   theme(text = element_text(family = "serif"),
#         strip.text = element_blank(),
#         legend.position = "none",
#         axis.text.x = element_blank()
#         ) +
#   aes(fill = Type)
# 
# plot_box1
# 
# ##### Box 2 Plot ##### 
# plot_box <-
#   ggplot(data = df_heart_aggr,
#          mapping = aes(x = Type,
#                        y = mean)) + 
#   geom_boxplot(mapping = aes(fill = status),
#                outlier.shape = NA) +
#   geom_point(mapping = aes(shape = status),
#              alpha = 0.5,
#              position = position_jitter(seed = 1,
#                                         width = 0.1,
#                                         height = 0.1)) +
#   labs(x ="",
#        y = "Average Heart Rate\n(in Beats per Minute)") + 
#   ggtitle("Experts' and novices' heart rate per phase") +
#   scale_fill_brewer(palette  = "RdBu") +  
#   theme_minimal() +
#   theme(text = element_text(family = "serif"),
#         legend.text = element_text(size = 15),
#         legend.title = element_blank(),
#         axis.text.x = element_text(size = 12),
#         axis.text.y = element_text(size = 10),
#         strip.text = element_text(size = 16),
#         plot.title = element_text(size = 20, 
#                                   face = "bold"))
# 
# plot_box
# 
# # saving plot 
# ggsave(plot = plot_box,
#        filename = "Plots/plot_box.svg",
#        height = 5,
#        width = 8,
#        units = "in")

##############


# lo_mat <- rbind(c(1,1,1,1,1,1,NA),
#                 c(2,2,2,2,2,2,4),
#                 c(3,3,3,3,3,3,NA))
# 
# plot_heart <- 
# grid.arrange(grobs = list(plot_flow, plot_loess, plot_box1, legend),
#              layout_matrix = lo_mat)
# 
# plot_heart

```

# Repeated Measures ANOVA

```{r}

# read in data
# disruption & confidence rating
df_rating <- 
  excel_sheets("data/Coding_SRI.xlsx") %>% 
  map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
  dplyr::select(ID, # select relevant columns 
         disruption_factor, # -99 = subject did not notice event; -100 = experimenter did not asked for event
         confidence_factor,
         event
         ) %>% 
  mutate(disruption_factor = ifelse(disruption_factor < 0,
                                    yes = NA,
                                    no = disruption_factor
                                    ),
         confidence_factor = ifelse(confidence_factor < 0,
                                   yes = NA,
                                   no = confidence_factor),
         event = as_factor(event)
         ) %>% 
  na.omit() 
  # group_by(ID) %>% 
  # summarise("mean_disrup" = round(mean(disruption_factor), 2),
  #           "mean_confi" = round(mean(confidence_factor), 2))


# demographic data
df_demo <- 
  read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel 
  transmute(ID = LI06_05, # select and rename relevant columns 
            gender = factor(LI02_01_1,
                            levels = 1:2,
                            labels = c("male","female")
                            ),
            age = LI03_01, # 1 = male; 2 = female
            teaching_experience = LI04_01)

# merge two data frames by ID 
df_merge <- merge(df_demo,
                  df_rating,
                  by = "ID") %>% 
  filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
                    "132")
         )

# rm(list = c("df_demo","df_rating"))


data_path <- "./data/heart_rate_data"

main <-
map(.x = dir(path = data_path,
             pattern = ".csv"),
    ~ read_csv(file.path(data_path, .), 
               id = "id",
               col_types = c("t","n")
               ) %>% 
  mutate(time = .$Time - min(.$Time),
         time = as.numeric(time),
         heart_rate = `Heart Rate`,
         ID = id,
         time_span = case_when(str_detect(string = id, pattern = "_a") ~ "after",
                               str_detect(string = id, pattern = "_m") ~ "main",
                               str_detect(string = id, pattern = "_p") ~ "pre",
                               str_detect(string = id, pattern = "_s") ~ "subsequent",
                               str_detect(string = id, pattern = "_i") ~ "interview",
                               TRUE ~ "overall"
                               ),
         ID = str_extract(string = ID,
                          pattern = "[:digit:]{3}"),
         ID = as.numeric(ID)
      ) %>%
      # filter(time <= 600) %>% # filter for 10min intervals
    filter(time <= 9000) %>% # filter for 2 hours 30min (maximal duration of study)
    dplyr::select(!c("Time","Heart Rate","id"))
    ) %>%
  bind_rows()

main <-
  left_join(main, df_merge,
            by = "ID")

main %>% 
  dplyr::select("time", 
                "heart_rate", 
                "ID",
                "time_span",
                "teaching_experience",
                "disruption_factor",
                "confidence_factor") %>% 
  distinct() %>% 
  # filter(time_span == "overall") %>% 
  group_by(ID) %>% 
  summarize(mean_heart = mean(heart_rate),
            sd_heart = sd(heart_rate)) %>%
  ungroup() %>% 
  right_join(x = .,
             y = main,
             by = "ID") %>% 
  mutate(heart_rate_std = (heart_rate - mean_heart)/
           sd_heart) -> main



# data wrangling - preparing data for anova
df_anova <-
  main %>% 
  filter(time_span != "overall") %>%   
  dplyr::select("ID",
         "time_span",
         "heart_rate",
         "teaching_experience",
         "disruption_factor",
         "confidence_factor") %>% 
  mutate(time_span = fct_recode(time_span,
                                "Pre-Lehrphase" = "pre",
                                "Lehrphase" = "main",
                                "Post-Lehrphase" = "subsequent",
                                "Interviewphase" = "interview",
                                "Endphase" = "after"
                                ),
         time_span = factor(time_span,
                            levels = c("Pre-Lehrphase",
                                       "Lehrphase",
                                       "Post-Lehrphase",
                                       "Interviewphase",
                                       "Endphase"
                                       )
                            )
         ) %>%
  distinct() %>% 
  group_by(ID, time_span) %>%
  summarise(mean_hr = mean(heart_rate, na.rm = TRUE),
            mean_confi = mean(confidence_factor, na.rm = TRUE),
            mean_disrup = mean(disruption_factor, na.rm = TRUE),
            mean_te = mean(teaching_experience, na.rm = TRUE)
         )

# counting participants in individual phases
table(df_anova['time_span'])

# descriptive analysis
describeBy(df_anova$mean_hr,
           df_anova$time_span)

# # merge demo data and fitbit data
# df_anova <- merge(df_anova,
#                   df_heart_aggr,
#                   by="ID")

# clean variable names
# df_anova <- df_anova %>% clean_names()

# Visualization
bxp <- ggboxplot(df_anova, x = "time_span", y = "mean_hr", add = "point")
bxp

# check for outliers
outliers <-
  df_anova %>%
  group_by(time_span) %>%
  identify_outliers(mean_hr)

# check for normality assumption --> can be checked by computing Shapiro-Wilk test for each time point. If the data is normally distributed, the p-value should be greater than 0.05
norm_assump <-
  df_anova %>%
  group_by(time_span) %>%
  shapiro_test(mean_hr)

# QQ plot draws the correlation between a given data and the normal distribution. 
plot <- 
  ggqqplot(df_anova, "mean_hr", facet.by = "time_span")

df_anova_subset <- subset(df_anova, select = c(time_span, mean_hr))

# # anova
# res.aov <- rstatix::anova_test(data = df_anova_subset,
#                                dv = mean_hr,
#                                wid = ,
#                                within = time_span)
# get_anova_table(res.aov)

# anova
df_anova_phase <- 
  aov(df_anova_subset$mean_hr ~ df_anova_subset$time_span)
summary(df_anova_phase)

# pairwise comparisons
pwc <- 
  pairwise.t.test(df_anova_subset$mean_hr, 
                  df_anova_subset$time_span, 
                  p.adjust="holm")
pwc


# effect size of ANOVA
EtaSq(df_anova_phase)

effect_size_anova <-
  round(sqrt(0.6533274/(1-0.6533274)), 2)

# effect size of pairwise comparisons
library(dplyr)
library(rstatix)
effect_size_pwc <-
  df_anova_subset %>%
  cohens_d(mean_hr ~ time_span) %>% 
  as.data.frame()

# # pairwise comparisons
# pwc <- df_anova_subset %>%
#   pairwise_t_test(
#     mean_hr ~ time_span, paired = TRUE,
#     p.adjust.method = "bonferroni"
#     )
# pwc

# # Visualization: box plots with p-values
# pwc <- 
#   pwc %>% 
#   add_xy_position(x = "time_span")
# 
# # boxplot
# bxp_anova <- ggboxplot(data = df_anova, 
#                  x = "type", 
#                  y = "mean", 
#                  add = "point")
# 
# bxp_anova + 
#   stat_pvalue_manual(pwc) +
#   labs(
#     subtitle = get_test_label(res.aov, detailed = TRUE),
#     caption = get_pwc_label(pwc)
#     )


# # saving plot 
# ggsave(plot = bxp_anova,
#        filename = "Plots/bxp_anova.svg",
#        height = 5,
#        width = 8,
#        units = "in")

```

# Repeated Measures ANOVA (STD)

```{r}

# read in data
# disruption & confidence rating
df_rating <- 
  excel_sheets("data/Coding_SRI.xlsx") %>% 
  map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
  dplyr::select(ID, # select relevant columns 
         disruption_factor, # -99 = subject did not notice event; -100 = experimenter did not asked for event
         confidence_factor,
         event
         ) %>% 
  mutate(disruption_factor = ifelse(disruption_factor < 0,
                                    yes = NA,
                                    no = disruption_factor
                                    ),
         confidence_factor = ifelse(confidence_factor < 0,
                                   yes = NA,
                                   no = confidence_factor),
         event = as_factor(event)
         ) %>% 
  na.omit() 
  # group_by(ID) %>% 
  # summarise("mean_disrup" = round(mean(disruption_factor), 2),
  #           "mean_confi" = round(mean(confidence_factor), 2))


# demographic data
df_demo <- 
  read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel 
  transmute(ID = LI06_05, # select and rename relevant columns 
            gender = factor(LI02_01_1,
                            levels = 1:2,
                            labels = c("male","female")
                            ),
            age = LI03_01, # 1 = male; 2 = female
            teaching_experience = LI04_01)

# merge two data frames by ID 
df_merge <- merge(df_demo,
                  df_rating,
                  by = "ID") %>% 
  filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
                    "132")
         )

# rm(list = c("df_demo","df_rating"))


data_path <- "./data/heart_rate_data"

main <-
map(.x = dir(path = data_path,
             pattern = ".csv"),
    ~ read_csv(file.path(data_path, .), 
               id = "id",
               col_types = c("t","n")
               ) %>% 
  dplyr::mutate(time = .$Time - min(.$Time),
         time = as.numeric(time),
         heart_rate = `Heart Rate`,
         ID = id,
         time_span = case_when(str_detect(string = id, pattern = "_a") ~ "after",
                               str_detect(string = id, pattern = "_m") ~ "main",
                               str_detect(string = id, pattern = "_p") ~ "pre",
                               str_detect(string = id, pattern = "_s") ~ "subsequent",
                               str_detect(string = id, pattern = "_i") ~ "interview",
                               TRUE ~ "overall"
                               ),
         ID = str_extract(string = ID,
                          pattern = "[:digit:]{3}"),
         ID = as.numeric(ID)
      ) %>%
      # filter(time <= 600) %>% # filter for 10min intervals
    filter(time <= 9000) %>% # filter for 2 hours 30min (maximal duration of study)
    dplyr::select(!c("Time","Heart Rate","id"))
    ) %>%
  bind_rows()

main <-
  left_join(main, df_merge,
            by = "ID")

main %>% 
  dplyr::select("time", 
                "heart_rate", 
                "ID",
                "time_span",
                "teaching_experience",
                "disruption_factor",
                "confidence_factor") %>% 
  distinct() %>% 
  # filter(time_span == "overall") %>% 
  group_by(ID) %>% 
  summarize(mean_heart = mean(heart_rate),
            sd_heart = sd(heart_rate)) %>%
  ungroup() %>% 
  right_join(x = .,
             y = main,
             by = "ID") %>% 
  dplyr::mutate(heart_rate_std = (heart_rate - mean_heart)/
           sd_heart) -> main



# data wrangling - preparing data for anova
df_anova <-
  main %>% 
  filter(time_span != "overall") %>%   
  dplyr::select("ID",
         "time_span",
         "heart_rate_std",
         "teaching_experience",
         "disruption_factor",
         "confidence_factor") %>% 
  mutate(time_span = fct_recode(time_span,
                                "Pre-Lehrphase" = "pre",
                                "Lehrphase" = "main",
                                "Post-Lehrphase" = "subsequent",
                                "Interviewphase" = "interview",
                                "Endphase" = "after"
                                ),
         time_span = factor(time_span,
                            levels = c("Pre-Lehrphase",
                                       "Lehrphase",
                                       "Post-Lehrphase",
                                       "Interviewphase",
                                       "Endphase"
                                       )
                            )
         ) %>%
  distinct() %>% 
  group_by(ID, time_span) %>%
  summarise(mean_hr_std = mean(heart_rate_std, na.rm = TRUE),
            mean_confi = mean(confidence_factor, na.rm = TRUE),
            mean_disrup = mean(disruption_factor, na.rm = TRUE),
            mean_te = mean(teaching_experience, na.rm = TRUE)
         )

# counting participants in individual phases
table(df_anova['time_span'])

# descriptive analysis
describeBy(df_anova$mean_hr_std,
           df_anova$time_span)

# # merge demo data and fitbit data
# df_anova <- merge(df_anova,
#                   df_heart_aggr,
#                   by="ID")

# clean variable names
# df_anova <- df_anova %>% clean_names()

# Visualization
bxp <- ggboxplot(df_anova, x = "time_span", y = "mean_hr_std", add = "point")
bxp

# check for outliers
outliers <-
  df_anova %>%
  group_by(time_span) %>%
  identify_outliers(mean_hr_std)

# check for normality assumption --> can be checked by computing Shapiro-Wilk test for each time point. If the data is normally distributed, the p-value should be greater than 0.05
norm_assump <-
  df_anova %>%
  group_by(time_span) %>%
  shapiro_test(mean_hr)

# QQ plot draws the correlation between a given data and the normal distribution. 
plot <- 
  ggqqplot(df_anova, "mean_hr_std", facet.by = "time_span")

df_anova_subset <- subset(df_anova, select = c(time_span, mean_hr_std))

# # anova
# res.aov <- rstatix::anova_test(data = df_anova_subset,
#                                dv = mean_hr,
#                                wid = ,
#                                within = time_span)
# get_anova_table(res.aov)

# anova
df_anova_phase <- 
  aov(df_anova_subset$mean_hr_std ~ df_anova_subset$time_span)
summary(df_anova_phase)

# pairwise comparisons
pwc <- 
  pairwise.t.test(df_anova_subset$mean_hr_std, 
                  df_anova_subset$time_span, 
                  p.adjust="holm")
pwc


# effect size of ANOVA
EtaSq(df_anova_phase)

effect_size_anova <-
  round(sqrt(0.6829502   /(1-0.6829502   )), 2)

# effect size of pairwise comparisons
library(dplyr)
library(rstatix)
effect_size_pwc <-
  df_anova_subset %>%
  cohens_d(mean_hr_std ~ time_span) %>% 
  as.data.frame()

# # pairwise comparisons
# pwc <- df_anova_subset %>%
#   pairwise_t_test(
#     mean_hr ~ time_span, paired = TRUE,
#     p.adjust.method = "bonferroni"
#     )
# pwc

# # Visualization: box plots with p-values
# pwc <- 
#   pwc %>% 
#   add_xy_position(x = "time_span")
# 
# # boxplot
# bxp_anova <- ggboxplot(data = df_anova, 
#                  x = "type", 
#                  y = "mean", 
#                  add = "point")
# 
# bxp_anova + 
#   stat_pvalue_manual(pwc) +
#   labs(
#     subtitle = get_test_label(res.aov, detailed = TRUE),
#     caption = get_pwc_label(pwc)
#     )


# # saving plot 
# ggsave(plot = bxp_anova,
#        filename = "Plots/bxp_anova.svg",
#        height = 5,
#        width = 8,
#        units = "in")

```
### Multiple Regression

```{r}

# AV = mittlere Herzrate in teaching phase; UV1 = Störfaktor, UV2 = Sicherheitsfaktor, UV3= Lehrerfahrung

df_lm_subset <- df_anova %>% 
  filter(time_span == "Lehrphase") %>% 
  dplyr::select(mean_hr, 
               mean_disrup, 
               mean_confi,
               mean_te)

# modell rechnen
modell <-   lm(mean_hr ~ mean_confi + mean_disrup + mean_te, 
               data = df_lm_subset,
               family = binomial)
summary(modell)

# Voraussetzungen:
# metrische AV
# 0 Linearität --> nicht gegeben

# 1 Normalverteilung Residuen = Unterschied zwischen geschätztem Wert der AV und beobachtetem Wert der AV
plot(modell, 2)

# 2a Homoskedastizität = gleichmäißge Streuung der Residuen
plot(modell, 1) # Hetereoskedastizität, da Residuen nicht gleichmäßig streuen --> verzerrte Standardfehler
bptest(modell) # Breusch-Pagan test --> Homoskedastizität liegt vor, da p-Wert unter 0.05; Nullhypothese wird nicht verworfen

# 2b Autokorrelation = Residuen korrelieren miteinander
# nicht erfüllt, da Wellenlinien bei Plot

# keine Multikollinearität = starke Korrelation der UVs = UV messen das Gleiche
vif(modell) # konservativ: unter 10 --> check

# 4 keine einflussreiche Fälle (Ausreißer)
plot(modell, 4)

# robuste Standardfehler 
coeftest(modell, vcov = vcovHC(modell, type = "HC3"))

# standardisierte Koeffizienten
zmodell <- lm(scale(mean_hr) ~ scale(mean_confi) + scale (mean_disrup) + scale(mean_te), 
              data = df_lm_subset)
summary(zmodell)


# cor(df_lm_subset)

```


### Multiple Regression (STD)

```{r}

# AV = mittlere Herzrate in teaching phase; UV1 = Störfaktor, UV2 = Sicherheitsfaktor, UV3= Lehrerfahrung
df_lm_subset <- df_anova %>% 
  filter(time_span == "Lehrphase") %>% 
  dplyr::select(mean_hr_std, 
               mean_disrup, 
               mean_confi,
               mean_te)

# modell rechnen
modell <-   lm(mean_hr_std ~ mean_confi + mean_disrup + mean_te, 
               data = df_lm_subset,
               family = binomial)
summary(modell)

# Voraussetzungen:
# metrische AV
# 0 Linearität --> nicht gegeben

# 1 Normalverteilung Residuen = Unterschied zwischen geschätztem Wert der AV und beobachtetem Wert der AV
plot(modell, 2)

# 2a Homoskedastizität = gleichmäißge Streuung der Residuen
plot(modell, 1) # Hetereoskedastizität, da Residuen nicht gleichmäßig streuen --> verzerrte Standardfehler
bptest(modell) # Breusch-Pagan test --> Homoskedastizität liegt vor, da p-Wert unter 0.05; Nullhypothese wird nicht verworfen

# 2b Autokorrelation = Residuen korrelieren miteinander
# nicht erfüllt, da Wellenlinien bei Plot

# keine Multikollinearität = starke Korrelation der UVs = UV messen das Gleiche
vif(modell) # konservativ: unter 10 --> check

# 4 keine einflussreiche Fälle (Ausreißer)
plot(modell, 4)

# robuste Standardfehler 
coeftest(modell, vcov = vcovHC(modell, type = "HC3"))

# standardisierte Koeffizienten
zmodell <- lm(scale(mean_hr_std) ~ scale(mean_confi) + scale (mean_disrup) + scale(mean_te), 
              data = df_lm_subset)
summary(zmodell)


# cor(df_lm_subset)

```




