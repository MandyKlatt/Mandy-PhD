mutate(id = as_factor(ID)) %>%
group_by(id) %>%
summarise(mean_confidence = mean(confidence_factor, na.rm = T),
mean_disruption = mean(disruption_factor, na.rm = T)) %>%
right_join(x = .,
y = df_test,
by = "id") %>%
right_join(x = .,
y = transmute(df_demo,
id = as_factor(ID),
teaching_experience = teaching_experience
),
by = "id")
df_test_reg %>%
pivot_longer(cols = c("mean_confidence", "mean_disruption"),
names_to = "factor_means",
values_to = "means") %>%
ggplot(mapping = aes(x = means,
y = intercept
)
) +
geom_point() +
geom_smooth(method = "lm") +
facet_grid(cols = vars(time_span),
rows = vars(factor_means))
fit_teach_1 <-
df_test_reg %>%
filter(time_span == "main") %$%
lm(intercept ~ mean_disruption)
fit_teach_2 <-
df_test_reg %>%
filter(time_span == "main") %$%
lm(intercept ~ mean_confidence)
fit_teach_3 <-
df_test_reg %>%
filter(time_span == "main") %$%
lm(intercept ~ mean_confidence + mean_disruption)
plot(fit_teach_3)
fit_post_1 <-
df_test_reg %>%
filter(time_span == "subsequent") %$%
lm(intercept ~ mean_disruption)
fit_post_2 <-
df_test_reg %>%
filter(time_span == "subsequent") %$%
lm(intercept ~ mean_confidence)
fit_post_3 <-
df_test_reg %>%
filter(time_span == "subsequent") %$%
lm(intercept ~ mean_confidence + mean_disruption)
fit_post_4 <-
df_test_reg %>%
filter(time_span == "subsequent") %$%
lm(intercept ~ mean_confidence + mean_disruption + teaching_experience)
stargazer::stargazer(fit_post_1, fit_post_2, fit_post_3, fit_post_4,
type = "latex",
#  caption = "Teaching Phase",
dep.var.labels = "Intercept",
order = c(1, 3, 2),
covariate.labels = c("Disruption Factor",
"Confidence Factor",
"Teaching Experience"),
keep.stat = c("n","rsq","adj.rsq")
)
heart_rate_var <- "heart_rate_std"
# heart_rate_var <- "heart_rate"
cache1 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate", "time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ ranef(.)$ID %>%
as_tibble(.,
rownames = "ID"
) %>%
clean_names()
) %>%
bind_rows(.,
.id = "time_span")
cache2 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate","time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ summary(.) %>%
.$coefficients %>%
.[c(1,2)]) %>%
bind_rows(.,
.id = "time_span") %>%
pivot_longer(
cols = everything(),
names_to = "time_span",
values_to = "mean_value"
)
df_test <-
tibble(mean_intercept = cache2$mean_value[1:6],
mean_time = cache2$mean_value[7:12],
time_span = cache2$time_span[1:6]) %>%
right_join(x = .,
y = cache1,
by = "time_span") %>%
transmute(time_span,
intercept = mean_intercept + intercept,
time = mean_time + time,
id = id)
t.test(df_test$intercept[df_test$time_span == "main"],
df_test$intercept[df_test$time_span == "subsequent"],
paired = TRUE)
CohenD(x = df_test$intercept[df_test$time_span == "main"],
y = df_test$intercept[df_test$time_span == "subsequent"],
pooled = T
)
# heart_rate_var <- "heart_rate_std"
heart_rate_var <- "heart_rate"
cache1 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate", "time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ ranef(.)$ID %>%
as_tibble(.,
rownames = "ID"
) %>%
clean_names()
) %>%
bind_rows(.,
.id = "time_span")
cache1 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate", "time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ ranef(.)$ID %>%
as_tibble(.,
rownames = "ID"
) %>%
clean_names()
) %>%
bind_rows(.,
.id = "time_span")
cache2 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate","time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ summary(.) %>%
.$coefficients %>%
.[c(1,2)]) %>%
bind_rows(.,
.id = "time_span") %>%
pivot_longer(
cols = everything(),
names_to = "time_span",
values_to = "mean_value"
)
cache1 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate", "time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ ranef(.)$ID %>%
as_tibble(.,
rownames = "ID"
) %>%
clean_names()
) %>%
bind_rows(.,
.id = "time_span")
cache2 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate","time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ summary(.) %>%
.$coefficients %>%
.[c(1,2)]) %>%
bind_rows(.,
.id = "time_span") %>%
pivot_longer(
cols = everything(),
names_to = "time_span",
values_to = "mean_value"
)
df_test <-
tibble(mean_intercept = cache2$mean_value[1:6],
mean_time = cache2$mean_value[7:12],
time_span = cache2$time_span[1:6]) %>%
right_join(x = .,
y = cache1,
by = "time_span") %>%
transmute(time_span,
intercept = mean_intercept + intercept,
time = mean_time + time,
id = id)
df_test <-
tibble(mean_intercept = cache2$mean_value[1:6],
mean_time = cache2$mean_value[7:12],
time_span = cache2$time_span[1:6]) %>%
right_join(x = .,
y = cache1,
by = "time_span") %>%
transmute(time_span,
intercept = mean_intercept + intercept,
time = mean_time + time,
id = id)
t.test(df_test$intercept[df_test$time_span == "main"],
df_test$intercept[df_test$time_span == "subsequent"],
paired = TRUE)
CohenD(x = df_test$intercept[df_test$time_span == "main"],
y = df_test$intercept[df_test$time_span == "subsequent"],
pooled = T
)
heart_rate_var <- "heart_rate_std"
cache1 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate", "time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ ranef(.)$ID %>%
as_tibble(.,
rownames = "ID"
) %>%
clean_names()
) %>%
bind_rows(.,
.id = "time_span")
cache1 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate", "time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ ranef(.)$ID %>%
as_tibble(.,
rownames = "ID"
) %>%
clean_names()
) %>%
bind_rows(.,
.id = "time_span")
cache2 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate","time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ summary(.) %>%
.$coefficients %>%
.[c(1,2)]) %>%
bind_rows(.,
.id = "time_span") %>%
pivot_longer(
cols = everything(),
names_to = "time_span",
values_to = "mean_value"
)
cache2 <-
main %>%
dplyr::select("ID","time","heart_rate_std", "heart_rate","time_span") %>%
distinct() %>%
mutate(ID = as_factor(ID)) %>%
split(.$time_span) %>%
map(~ lmer(formula = eval(parse(text = heart_rate_var)) ~ 1 + time + (1 + time | ID),
data = .)) %>%
map(~ summary(.) %>%
.$coefficients %>%
.[c(1,2)]) %>%
bind_rows(.,
.id = "time_span") %>%
pivot_longer(
cols = everything(),
names_to = "time_span",
values_to = "mean_value"
)
df_test <-
tibble(mean_intercept = cache2$mean_value[1:6],
mean_time = cache2$mean_value[7:12],
time_span = cache2$time_span[1:6]) %>%
right_join(x = .,
y = cache1,
by = "time_span") %>%
transmute(time_span,
intercept = mean_intercept + intercept,
time = mean_time + time,
id = id)
t.test(df_test$intercept[df_test$time_span == "main"],
df_test$intercept[df_test$time_span == "subsequent"],
paired = TRUE)
CohenD(x = df_test$intercept[df_test$time_span == "main"],
y = df_test$intercept[df_test$time_span == "subsequent"],
pooled = T
)
df_test_reg <-
df_merge %>%
mutate(id = as_factor(ID)) %>%
group_by(id) %>%
summarise(mean_confidence = mean(confidence_factor, na.rm = T),
mean_disruption = mean(disruption_factor, na.rm = T)) %>%
right_join(x = .,
y = df_test,
by = "id") %>%
right_join(x = .,
y = transmute(df_demo,
id = as_factor(ID),
teaching_experience = teaching_experience
),
by = "id")
df_test_reg %>%
pivot_longer(cols = c("mean_confidence", "mean_disruption"),
names_to = "factor_means",
values_to = "means") %>%
ggplot(mapping = aes(x = means,
y = intercept
)
) +
geom_point() +
geom_smooth(method = "lm") +
facet_grid(cols = vars(time_span),
rows = vars(factor_means))
library("papaja")
r_refs("r-references.bib")
library(needs)
needs(ltm,
broom,
ppcor,
jtools,
lm.beta,
tidyverse,
janitor,
lubridate,
readxl,
ggthemes,
gridExtra,
imputeTS,
DescTools,
cowplot,
rstatix,
ggpubr,
lme4,
viridis)
# disruption & confidence rating
df_rating <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
dplyr::select(ID, # select relevant columns
disruption_factor, # -99 = subject did not notice event; -100 = experimenter did not asked for event
confidence_factor,
event
) %>%
mutate(disruption_factor = ifelse(disruption_factor < 0,
yes = NA,
no = disruption_factor
),
confidence_factor = ifelse(confidence_factor < 0,
yes = NA,
no = confidence_factor),
event = as_factor(event)
)
# demographic data
df_demo_all <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel
transmute(ID = LI06_05, # select and rename relevant columns
# gender = factor(LI02_01_1,
#                 levels = 1:2,
#                 labels = c("male","female")
#                 ),
gender = LI02_01_1, # 1 = male; 2 = female
age = LI03_01,
teaching_experience = LI04_01,
school_type = LI18,
term = LI11_01,
extracurricular_teaching_experience = LI14,
secondary_teaching_activities = LI17)
# merge two data frames by ID
df_merge <- merge(df_demo_all,
df_rating,
by = "ID") %>%
filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
"132")
)
# rm(list = c("df_demo","df_rating"))
data_path <- "./data/heart_rate_data"
main <-
map(.x = dir(path = data_path,
pattern = ".csv"),
~ read_csv(file.path(data_path, .),
id = "id",
col_types = c("t","n")
) %>%
mutate(time = .$Time - min(.$Time),
time = as.numeric(time),
heart_rate = `Heart Rate`,
ID = id,
time_span = case_when(str_detect(string = id, pattern = "_a") ~ "after",
str_detect(string = id, pattern = "_m") ~ "main",
str_detect(string = id, pattern = "_p") ~ "pre",
str_detect(string = id, pattern = "_s") ~ "subsequent",
str_detect(string = id, pattern = "_i") ~ "interview",
TRUE ~ "overall"
),
ID = str_extract(string = ID,
pattern = "[:digit:]{3}"),
ID = as.numeric(ID)
) %>%
filter(time <= 600) %>%
dplyr::select(!c("Time","Heart Rate","id"))
) %>%
bind_rows()
main <-
left_join(main, df_merge,
by = "ID")
# exclude cases with no fitbit data
df_demo <- df_demo_all %>%
filter(!ID %in% c("126",
"132"
)
)
# changing gender to count female gender (male = 2 --> 0)
df_demo$gender = ifelse(df_demo$gender == 2, "1","0")
# changing character Gender into numeric
df_demo$gender <- as.numeric(df_demo$gender)
# creating new column with total participants to calculate percent of gender
df_demo <- df_demo %>%
mutate(sum_participants = sum(n()))
# replacing 2 to 1 (Oberschule = Gymnasisium --> Secondary school)
df_demo$school_type[df_demo$school_type == 2] <- "1"
# creating new column to calculate percent of school type
df_demo <-
df_demo %>%
group_by(school_type) %>%
mutate(count_schooltype = sum(n())) %>%
mutate(percent_schooltype = round((count_schooltype/sum_participants) * 100,
digits = 2))
# changing character Percent_schooltype into numeric
df_demo$percent_schooltype <- as.numeric(df_demo$percent_schooltype)
#changing type of school into character
# LI18:
# 1: Grundschule
# 2: Oberschule
# 3: Gymnasium
# 4: Förderschule/Sondershausen
# 5: Berufsbildende Schule
# -1: andere Schulform
df_demo$school_type <- factor(x = df_demo$school_type,
levels = c("1","3","4","5","-1"), # Mögliche Werte # andere Möglichkeit: unique(demo.data$School_type)
labels = c("Primary School","Secondary School", "Special Education","Vocational School", "Other Schooltype")) # Bezeichnungen
# create a basic table (tibble) using tidyverse functions
df_demo_table <- df_demo %>%
group_by() %>%
summarise(N=n(),
"Gender female in percent" = round(sum(gender/sum_participants) * 100,
digits = 2),
"M Age in years" = round(mean(age),
digits = 2),
"SD Age in years" = round(sd(age),
digits = 2),
"Min Age in years" = min(age),
"Max Age in years" = max(age),
"M Teaching Experience in years" = round(mean(teaching_experience),
digits = 2),
"SD Teaching Experience in years" = round(sd(teaching_experience),
digits = 2),
"Min Teaching Experience in years" = min(teaching_experience),
"Max Teaching Experience in years" = max(teaching_experience)
)
# format and insert table in manuscript
df_demo_table %>%
papaja::apa_table(
caption = "Demographic Information",
# note = "Write Note here",
escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
font_size = "tiny" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)
View(df_demo_table)
View(df_demo_table)
View(df_demo)
View(df_demo)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, warning = FALSE)
fit_interview_1 <-
df_test_reg %>%
filter(time_span == "interview") %$%
lm(intercept ~ mean_disruption)
?stargazer
