confidence_factor = ifelse(confidence_factor < 0,
yes = NA,
no = confidence_factor),
event = as_factor(event)
) %>%
na.omit()
# demographic data
df_demo <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel
transmute(ID = LI06_05, # select and rename relevant columns
gender = factor(LI02_01_1,
levels = 1:2,
labels = c("male","female")
),
age = LI03_01, # 1 = male; 2 = female
teaching_experience = LI04_01)
# merge two data frames by ID
df_merge <- merge(df_demo,
df_rating,
by = "ID") %>%
filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
"132")
)
data_path <- "./data/heart_rate_data"
main <-
map(.x = dir(path = data_path,
pattern = ".csv"),
~ read_csv(file.path(data_path, .),
id = "id",
col_types = c("t","n")
) %>%
mutate(time = .$Time - min(.$Time),
time = as.numeric(time),
heart_rate = `Heart Rate`,
ID = id,
time_span = case_when(str_detect(string = id, pattern = "_a") ~ "after",
str_detect(string = id, pattern = "_m") ~ "main",
str_detect(string = id, pattern = "_p") ~ "pre",
str_detect(string = id, pattern = "_s") ~ "subsequent",
str_detect(string = id, pattern = "_i") ~ "interview",
TRUE ~ "overall"
),
ID = str_extract(string = ID,
pattern = "[:digit:]{3}"),
ID = as.numeric(ID)
) %>%
# filter(time <= 600) %>% # filter for 10min intervals
filter(time <= 9000) %>% # filter for 2 hours 30min (maximal duration of study)
dplyr::select(!c("Time","Heart Rate","id"))
) %>%
bind_rows()
main <-
left_join(main, df_merge,
by = "ID")
main %>%
dplyr::select("time",
"heart_rate",
"ID",
"time_span",
"teaching_experience",
"disruption_factor",
"confidence_factor") %>%
distinct() %>%
# filter(time_span == "overall") %>%
group_by(ID) %>%
summarize(mean_heart = mean(heart_rate),
sd_heart = sd(heart_rate)) %>%
ungroup() %>%
right_join(x = .,
y = main,
by = "ID") %>%
mutate(heart_rate_std = (heart_rate - mean_heart)/
sd_heart) -> main
# data wrangling - preparing data for anova
df_anova <-
main %>%
filter(time_span != "overall") %>%
dplyr::select("ID",
"time_span",
"heart_rate_std",
"teaching_experience",
"disruption_factor",
"confidence_factor") %>%
mutate(time_span = fct_recode(time_span,
"Pre-Lehrphase" = "pre",
"Lehrphase" = "main",
"Post-Lehrphase" = "subsequent",
"Interviewphase" = "interview",
"Endphase" = "after"
),
time_span = factor(time_span,
levels = c("Pre-Lehrphase",
"Lehrphase",
"Post-Lehrphase",
"Interviewphase",
"Endphase"
)
)
) %>%
distinct() %>%
group_by(ID, time_span) %>%
summarise(mean_hr_std = mean(heart_rate_std, na.rm = TRUE),
mean_confi = mean(confidence_factor, na.rm = TRUE),
mean_disrup = mean(disruption_factor, na.rm = TRUE),
mean_te = mean(teaching_experience, na.rm = TRUE)
)
df_lm_subset <- df_anova %>%
filter(time_span == "Lehrphase") %>%
dplyr::select(mean_hr_std,
mean_disrup,
mean_confi,
mean_te)
# modell rechnen
modell <-   lm(mean_hr_std ~ mean_confi + mean_disrup + mean_te,
data = df_lm_subset,
family = binomial)
summary(modell)
# modell rechnen
modell <-   lm(mean_hr_std ~ mean_confi + mean_disrup + mean_te,
data = df_lm_subset,
family = binomial)
summary(modell)
# modell rechnen
modell <-   lm(mean_hr_std ~ mean_confi + mean_disrup + mean_te,
data = df_lm_subset,
family = binomial)
summary(modell)
# robuste Standardfehler
coeftest(modell, vcov = vcovHC(modell, type = "HC3"))
# modell rechnen
modell <-   lm(mean_hr_std ~ mean_confi + mean_disrup + mean_te,
data = df_lm_subset,
family = binomial)
summary(modell)
# standardisierte Koeffizienten
zmodell <- lm(scale(mean_hr_std) ~ scale(mean_confi) + scale (mean_disrup) + scale(mean_te),
data = df_lm_subset)
summary(zmodell)
knitr::opts_chunk$set(echo = FALSE)
# Packages
# install.packages("needs")
# Choose "No"
library(needs)
needs(tidyverse,
janitor,
lubridate,
readxl,
ggthemes,
gridExtra,
imputeTS,
DescTools,
cowplot,
rstatix,
ggpubr,
psych,
stargazer,
lmtest,
sandwich,
car)
# read in data
# disruption & confidence rating
df_rating <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
dplyr::select(ID, # select relevant columns
disruption_factor, # -99 = subject did not notice event; -100 = experimenter did not asked for event
confidence_factor,
event
) %>%
mutate(disruption_factor = ifelse(disruption_factor < 0,
yes = NA,
no = disruption_factor
),
confidence_factor = ifelse(confidence_factor < 0,
yes = NA,
no = confidence_factor),
event = as_factor(event)
) %>%
na.omit()
# demographic data
df_demo <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel
transmute(ID = LI06_05, # select and rename relevant columns
gender = factor(LI02_01_1,
levels = 1:2,
labels = c("male","female")
),
age = LI03_01, # 1 = male; 2 = female
teaching_experience = LI04_01)
# merge two data frames by ID
df_merge <- merge(df_demo,
df_rating,
by = "ID") %>%
filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
"132")
)
data_path <- "./data/heart_rate_data"
main <-
map(.x = dir(path = data_path,
pattern = ".csv"),
~ read_csv(file.path(data_path, .),
id = "id",
col_types = c("t","n")
) %>%
mutate(time = .$Time - min(.$Time),
time = as.numeric(time),
heart_rate = `Heart Rate`,
ID = id,
time_span = case_when(str_detect(string = id, pattern = "_a") ~ "after",
str_detect(string = id, pattern = "_m") ~ "main",
str_detect(string = id, pattern = "_p") ~ "pre",
str_detect(string = id, pattern = "_s") ~ "subsequent",
str_detect(string = id, pattern = "_i") ~ "interview",
TRUE ~ "overall"
),
ID = str_extract(string = ID,
pattern = "[:digit:]{3}"),
ID = as.numeric(ID)
) %>%
# filter(time <= 600) %>% # filter for 10min intervals
filter(time <= 9000) %>% # filter for 2 hours 30min (maximal duration of study)
dplyr::select(!c("Time","Heart Rate","id"))
) %>%
bind_rows()
main <-
left_join(main, df_merge,
by = "ID")
main %>%
dplyr::select("time",
"heart_rate",
"ID",
"time_span",
"teaching_experience",
"disruption_factor",
"confidence_factor") %>%
distinct() %>%
# filter(time_span == "overall") %>%
group_by(ID) %>%
summarize(mean_heart = mean(heart_rate),
sd_heart = sd(heart_rate)) %>%
ungroup() %>%
right_join(x = .,
y = main,
by = "ID") %>%
mutate(heart_rate_std = (heart_rate - mean_heart)/
sd_heart) -> main
# data wrangling - preparing data for anova
df_anova <-
main %>%
filter(time_span != "overall") %>%
dplyr::select("ID",
"time_span",
"heart_rate",
"teaching_experience",
"disruption_factor",
"confidence_factor") %>%
mutate(time_span = fct_recode(time_span,
"Pre-Lehrphase" = "pre",
"Lehrphase" = "main",
"Post-Lehrphase" = "subsequent",
"Interviewphase" = "interview",
"Endphase" = "after"
),
time_span = factor(time_span,
levels = c("Pre-Lehrphase",
"Lehrphase",
"Post-Lehrphase",
"Interviewphase",
"Endphase"
)
)
) %>%
distinct() %>%
group_by(ID, time_span) %>%
summarise(mean_hr = mean(heart_rate, na.rm = TRUE),
mean_confi = mean(confidence_factor, na.rm = TRUE),
mean_disrup = mean(disruption_factor, na.rm = TRUE),
mean_te = mean(teaching_experience, na.rm = TRUE)
)
# counting participants in individual phases
table(df_anova['time_span'])
# descriptive analysis
describeBy(df_anova$mean_hr,
df_anova$time_span)
# Visualization
bxp <- ggboxplot(df_anova, x = "time_span", y = "mean_hr", add = "point")
bxp
# check for outliers
outliers <-
df_anova %>%
group_by(time_span) %>%
identify_outliers(mean_hr)
# check for normality assumption --> can be checked by computing Shapiro-Wilk test for each time point. If the data is normally distributed, the p-value should be greater than 0.05
norm_assump <-
df_anova %>%
group_by(time_span) %>%
shapiro_test(mean_hr)
# QQ plot draws the correlation between a given data and the normal distribution.
plot <-
ggqqplot(df_anova, "mean_hr", facet.by = "time_span")
df_anova_subset <- subset(df_anova, select = c(time_span, mean_hr))
# anova
df_anova_phase <-
aov(df_anova_subset$mean_hr ~ df_anova_subset$time_span)
summary(df_anova_phase)
summary(df_anova_phase)
# pairwise comparisons
pwc <-
pairwise.t.test(df_anova_subset$mean_hr,
df_anova_subset$time_span,
p.adjust="holm")
pwc
# effect size of ANOVA
EtaSq(df_anova_phase)
effect_size_anova <-
round(sqrt(0.6533274/(1-0.6533274)), 2)
# effect size of pairwise comparisons
library(dplyr)
library(rstatix)
effect_size_pwc <-
df_anova_subset %>%
cohens_d(mean_hr ~ time_span) %>%
as.data.frame()
effect_size_pwc
# read in data
# disruption & confidence rating
df_rating <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
dplyr::select(ID, # select relevant columns
disruption_factor, # -99 = subject did not notice event; -100 = experimenter did not asked for event
confidence_factor,
event
) %>%
mutate(disruption_factor = ifelse(disruption_factor < 0,
yes = NA,
no = disruption_factor
),
confidence_factor = ifelse(confidence_factor < 0,
yes = NA,
no = confidence_factor),
event = as_factor(event)
) %>%
na.omit()
# demographic data
df_demo <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel
transmute(ID = LI06_05, # select and rename relevant columns
gender = factor(LI02_01_1,
levels = 1:2,
labels = c("male","female")
),
age = LI03_01, # 1 = male; 2 = female
teaching_experience = LI04_01)
# merge two data frames by ID
df_merge <- merge(df_demo,
df_rating,
by = "ID") %>%
filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
"132")
)
data_path <- "./data/heart_rate_data"
main <-
map(.x = dir(path = data_path,
pattern = ".csv"),
~ read_csv(file.path(data_path, .),
id = "id",
col_types = c("t","n")
) %>%
mutate(time = .$Time - min(.$Time),
time = as.numeric(time),
heart_rate = `Heart Rate`,
ID = id,
time_span = case_when(str_detect(string = id, pattern = "_a") ~ "after",
str_detect(string = id, pattern = "_m") ~ "main",
str_detect(string = id, pattern = "_p") ~ "pre",
str_detect(string = id, pattern = "_s") ~ "subsequent",
str_detect(string = id, pattern = "_i") ~ "interview",
TRUE ~ "overall"
),
ID = str_extract(string = ID,
pattern = "[:digit:]{3}"),
ID = as.numeric(ID)
) %>%
# filter(time <= 600) %>% # filter for 10min intervals
filter(time <= 9000) %>% # filter for 2 hours 30min (maximal duration of study)
dplyr::select(!c("Time","Heart Rate","id"))
) %>%
bind_rows()
main <-
left_join(main, df_merge,
by = "ID")
main %>%
dplyr::select("time",
"heart_rate",
"ID",
"time_span",
"teaching_experience",
"disruption_factor",
"confidence_factor") %>%
distinct() %>%
# filter(time_span == "overall") %>%
group_by(ID) %>%
summarize(mean_heart = mean(heart_rate),
sd_heart = sd(heart_rate)) %>%
ungroup() %>%
right_join(x = .,
y = main,
by = "ID") %>%
mutate(heart_rate_std = (heart_rate - mean_heart)/
sd_heart) -> main
# data wrangling - preparing data for anova
df_anova <-
main %>%
filter(time_span != "overall") %>%
dplyr::select("ID",
"time_span",
"heart_rate_std",
"teaching_experience",
"disruption_factor",
"confidence_factor") %>%
mutate(time_span = fct_recode(time_span,
"Pre-Lehrphase" = "pre",
"Lehrphase" = "main",
"Post-Lehrphase" = "subsequent",
"Interviewphase" = "interview",
"Endphase" = "after"
),
time_span = factor(time_span,
levels = c("Pre-Lehrphase",
"Lehrphase",
"Post-Lehrphase",
"Interviewphase",
"Endphase"
)
)
) %>%
distinct() %>%
group_by(ID, time_span) %>%
summarise(mean_hr_std = mean(heart_rate_std, na.rm = TRUE),
mean_confi = mean(confidence_factor, na.rm = TRUE),
mean_disrup = mean(disruption_factor, na.rm = TRUE),
mean_te = mean(teaching_experience, na.rm = TRUE)
)
# counting participants in individual phases
table(df_anova['time_span'])
# descriptive analysis
describeBy(df_anova$mean_hr_std,
df_anova$time_span)
# Visualization
bxp <- ggboxplot(df_anova, x = "time_span", y = "mean_hr_std", add = "point")
bxp
# check for outliers
outliers <-
df_anova %>%
group_by(time_span) %>%
identify_outliers(mean_hr_std)
# check for normality assumption --> can be checked by computing Shapiro-Wilk test for each time point. If the data is normally distributed, the p-value should be greater than 0.05
norm_assump <-
df_anova %>%
group_by(time_span) %>%
shapiro_test(mean_hr)
df_anova_subset <- subset(df_anova, select = c(time_span, mean_hr_std))
# anova
df_anova_phase <-
aov(df_anova_subset$mean_hr_std ~ df_anova_subset$time_span)
df_anova_subset <- subset(df_anova, select = c(time_span, mean_hr_std))
# anova
df_anova_phase <-
aov(df_anova_subset$mean_hr_std ~ df_anova_subset$time_span)
summary(df_anova_phase)
# pairwise comparisons
pwc <-
pairwise.t.test(df_anova_subset$mean_hr_std,
df_anova_subset$time_span,
p.adjust="holm")
pwc
# pairwise comparisons
pwc <-
pairwise.t.test(df_anova_subset$mean_hr_std,
df_anova_subset$time_span,
p.adjust="holm")
pwc
# effect size of ANOVA
EtaSq(df_anova_phase)
effect_size_anova <-
round(sqrt(0.6829502   /(1-0.6829502   )), 2)
# effect size of pairwise comparisons
library(dplyr)
library(rstatix)
effect_size_pwc <-
df_anova_subset %>%
cohens_d(mean_hr_std ~ time_span) %>%
as.data.frame()
effect_size_pwc
# AV = mittlere Herzrate in teaching phase; UV1 = Störfaktor, UV2 = Sicherheitsfaktor, UV3= Lehrerfahrung
df_lm_subset <- df_anova %>%
filter(time_span == "Lehrphase") %>%
dplyr::select(mean_hr_std,
mean_disrup,
mean_confi,
mean_te)
# modell rechnen
modell <-   lm(mean_hr_std ~ mean_confi + mean_disrup + mean_te,
data = df_lm_subset,
family = binomial)
summary(modell)
# standardisierte Koeffizienten
zmodell <- lm(scale(mean_hr_std) ~ scale(mean_confi) + scale (mean_disrup) + scale(mean_te),
data = df_lm_subset)
summary(zmodell)
summary(modell)
