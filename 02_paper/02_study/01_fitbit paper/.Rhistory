bind_rows(.id = "Phase") %>%
pivot_longer(cols = everything(),
names_to = "Phase",
values_to = "p.value_intercept")
sd_mean <-
fix_models %>%
group_by(Phase) %>%
dplyr::summarise(
mean_slope = mean(slope),
sd_slope = sd(slope),
mean_intercept = mean(intercept),
sd_intercept = sd(intercept)
)
table_data <-
right_join(x = sd_mean,
y = p.values_intercept,
by = "Phase") %>%
right_join(x = .,
y = p.values_slope,
by = "Phase") %>%
transmute(Phase = factor(Phase,
levels = c("Pre Teaching Phase","Teaching Phase","Post Teaching Phase","Interview Phase","End Phase")
),
n = NA,
`Mean(Intercept)` = round(mean_intercept, digits = 3),
`SD(Intercept)` = round(sd_intercept, digits = 3),
`p-Value (Intercept)` = p.value_intercept,
`Mean(Slope)` = round(mean_slope, digits = 3),
`SD(Slope)` = round(sd_slope,digits = 3),
`p-Value (Slope)` = p.value_slope,
) %>%
arrange(Phase)
table_data$n[table_data$Phase == "Pre Teaching Phase"] <- df_regression %>% filter(Phase == "Pre Teaching Phase") %>% pull(heart_rate_std) %>% length()
table_data$n[table_data$Phase == "Teaching Phase"] <- df_regression %>% filter(Phase == "Teaching Phase") %>% pull(heart_rate_std) %>% length()
table_data$n[table_data$Phase == "Post Teaching Phase"] <- df_regression %>% filter(Phase == "Post Teaching Phase") %>% pull(heart_rate_std) %>% length()
table_data$n[table_data$Phase == "Interview Phase"] <- df_regression %>% filter(Phase == "Interview Phase") %>% pull(heart_rate_std) %>% length()
table_data$n[table_data$Phase == "End Phase"] <- df_regression %>% filter(Phase == "End Phase") %>% pull(heart_rate_std) %>% length()
table_data %>%
knitr::kable(.)
View(df_regression)
# planned constrasts
model <- aov(mean_hr_std ~ time_span, data = df_anova_subset)
summary (model)
contrast1 <- c(-1, 1, 0, 0, 0)
contrast2 <- c(0, 1, -1, 0, 0)
contrast3 <- c(0, 1, 0, -1, 0)
contrast4 <- c(0, 1, 0, 0, -1)
contrasts(df_anova_subset$time_span) <- cbind(contrast1,
contrast2,
contrast3,
contrast4)
model2 <- aov(mean_hr_std ~ time_span, data = df_anova_subset)
(model2)
contrasts(df_anova_subset$time_span) <- cbind(contrast1,
contrast2,
contrast3,
contrast4)
model2 <- aov(mean_hr_std ~ time_span, data = df_anova_subset)
(model2)
summary.lm(model2,
split = list (time_span = list ("Teaching interval vs. Pre-teaching interval" = 1,
"Teaching interval vs. Post-teaching interval" = 2,
"Teaching interval vs. Interview interval" = 3,
"Teaching interval vs. End interval" = 4
)
)
)
summary.lm(model2,
split = list (time_span = list ("Teaching interval vs. Pre-teaching interval" = 1,
"Teaching interval vs. Post-teaching interval" = 2,
"Teaching interval vs. Interview interval" = 3,
"Teaching interval vs. End interval" = 4
)
)
)
# effect size of pairwise comparisons
library(dplyr)
library(rstatix)
effect_size_pwc <-
df_anova_subset %>%
cohens_d(mean_hr_std ~ time_span) %>%
as.data.frame()
effect_size_pwc
# Data wrangling - preparing data for ANOVA
df_anova <-
main_single_hr %>%
filter(time_span != "overall") %>%
dplyr::select("ID",
"time_span",
"heart_rate_std") %>%
mutate(time_span = fct_recode(time_span,
"Pre-teaching interval" = "preparation",
"Teaching interval" = "teaching",
"Post-teaching interval" = "post",
"Interview interval" = "interview",
"End interval" = "end"
),
time_span = factor(time_span,
levels = c("Pre-teaching interval",
"Teaching interval",
"Post-teaching interval",
"Interview interval",
"End interval"
)
)
) %>%
distinct() %>%
group_by(ID, time_span) %>%
summarise(mean_hr_std = mean(heart_rate_std, na.rm = TRUE))
# Counting participants in individual phases
table(df_anova['time_span'])
# descriptive analysis
describeBy(df_anova$mean_hr_std,
df_anova$time_span)
# Visualization
bxp <- ggboxplot(df_anova, x = "time_span", y = "mean_hr_std", add = "point")
bxp
# Check for outliers
outliers <-
df_anova %>%
group_by(time_span) %>%
identify_outliers(mean_hr_std)
# check for normality assumption --> can be checked by computing Shapiro-Wilk test for each time point. If the data is normally distributed, the p-value should be greater than 0.05
norm_assump <-
df_anova %>%
group_by(time_span) %>%
shapiro_test(mean_hr_std)
# QQ plot draws the correlation between a given data and the normal distribution.
plot <-
ggqqplot(df_anova, "mean_hr_std", facet.by = "time_span")
df_anova_subset <- subset(df_anova, select = c(time_span, mean_hr_std))
# anova
df_anova_phase <-
aov(df_anova_subset$mean_hr_std ~ df_anova_subset$time_span)
summary(df_anova_phase)
# effect size for ANOVA
DescTools::EtaSq(df_anova_phase)
f = sqrt (0.7202944/ (1-0.7202944))
# planned constrasts
model <- aov(mean_hr_std ~ time_span, data = df_anova_subset)
summary (model)
contrast1 <- c(-1, 1, 0, 0, 0)
contrast2 <- c(0, 1, -1, 0, 0)
contrast3 <- c(0, 1, 0, -1, 0)
contrast4 <- c(0, 1, 0, 0, -1)
contrasts(df_anova_subset$time_span) <- cbind(contrast1,
contrast2,
contrast3,
contrast4)
model2 <- aov(mean_hr_std ~ time_span, data = df_anova_subset)
(model2)
summary.lm(model2,
split = list (time_span = list ("Teaching interval vs. Pre-teaching interval" = 1,
"Teaching interval vs. Post-teaching interval" = 2,
"Teaching interval vs. Interview interval" = 3,
"Teaching interval vs. End interval" = 4
)
)
)
# effect size of pairwise comparisons
library(dplyr)
library(rstatix)
effect_size_pwc <-
df_anova_subset %>%
cohens_d(mean_hr_std ~ time_span) %>%
as.data.frame()
effect_size_pwc
summary.lm(model2,
split = list (time_span = list ("Teaching interval vs. Pre-teaching interval" = 1,
"Teaching interval vs. Post-teaching interval" = 2,
"Teaching interval vs. Interview interval" = 3,
"Teaching interval vs. End interval" = 4
)
)
)
library(needs)
needs(ltm,
xtable,
broom,
ppcor,
jtools,
lm.beta,
janitor,
lubridate,
readxl,
ggthemes,
gridExtra,
imputeTS,
DescTools,
cowplot,
rstatix,
ggpubr,
lme4,
lmerTest,
viridis,
gridExtra,
gridtext,
magrittr,
PerformanceAnalytics,
Hmisc,
corrplot,
tidyverse,
ggplot2,
lavaan,
lm.beta,
psych,
stats)
# disruption & confidence rating
df_rating <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
dplyr::select(ID, # select relevant columns
"disruption_factor", # -99 = subject did not notice event; -100 = experimenter did not asked for event
"confidence_factor",
"event"
) %>%
mutate(disruption_factor = ifelse(disruption_factor < 0,
yes = NA,
no = disruption_factor
),
confidence_factor = ifelse(confidence_factor < 0,
yes = NA,
no = confidence_factor),
event = as_factor(event)
)
# demographic data
df_demo <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel
transmute(ID = LI06_05, # select and rename relevant columns
gender = factor(LI02_01_1,
levels = 1:2,
labels = c("male","female")
),
age = LI03_01, # 1 = male; 2 = female
teaching_experience = LI04_01)
# merge two data frames by ID
df_merge <- merge(df_demo,
df_rating,
by = "ID") %>%
filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
"132",
"236")
)
# rm(list = c("df_demo","df_rating"))
data_path <- "./data/heart_rate_data"
# single bpm values (data frame with only single measurement point)
main_single_hr <-
map(.x = dir(path = data_path,
pattern = ".csv"),
~ read_csv(file.path(data_path, .),
id = "id",
col_types = c("t","n")
) %>%
mutate(time = .$Time - min(.$Time),
time = as.numeric(time),
heart_rate = `Heart Rate`,
ID = id,
time_span = case_when(str_detect(string = id, pattern = "_a") ~ "end",
str_detect(string = id, pattern = "_m") ~ "teaching",
str_detect(string = id, pattern = "_p") ~ "preparation",
str_detect(string = id, pattern = "_s") ~ "post",
str_detect(string = id, pattern = "_i") ~ "interview",
TRUE ~ "overall"
),
ID = str_extract(string = ID,
pattern = "[:digit:]{3}"),
ID = as.numeric(ID)
) %>%
# filter(time <= 600) %>% # filter for 10min intervals
filter(time <= 7200) %>% # filter for 2 hours (maximal duration of study)
dplyr::select(!c("Time","Heart Rate","id"))
) %>%
bind_rows()
# adding z-standardized HR
main_single_hr <-
main_single_hr %>%
dplyr::select("time", "heart_rate", "ID", "time_span") %>%
distinct() %>%
group_by(ID) %>%
dplyr::summarise(mean_heart = mean(heart_rate),
sd_heart = sd(heart_rate)) %>%
ungroup() %>%
right_join(x = .,
y = main_single_hr,
by = "ID") %>%
filter(!(time_span == "teaching" & time > 600)) %>%
mutate(heart_rate_std = (heart_rate - mean_heart)/
sd_heart)
## count for individuals
main_single_hr %>%
filter(time >= 7200) %>%
distinct(ID, .keep_all = TRUE) -> filter_overall
# Mean, SD and range for disruption and confidence factor
rating_table <-
df_rating %>%
filter(!is.na(confidence_factor),
!is.na(disruption_factor)) %>%
summarise(N = n_distinct(ID),
"M disruption factor" = round(mean(disruption_factor),
digits = 2),
"SD disruption factor" = round(sd(disruption_factor),
digits = 2),
"Min disruption factor" = min(disruption_factor),
"Max disruption factor" = max(disruption_factor),
"M confidence factor" = round(mean(confidence_factor),
digits = 2),
"SD confidence factor" = round(sd(confidence_factor),
digits = 2),
"Min confidence factor" = min(confidence_factor),
"Max confidence factor" = max(confidence_factor)
)
rating_table
# Mean, SD and range for overall (unstandardized)
descrip_hr_overall <- main_single_hr %>%
filter(time_span %in% c("overall")) %>%
summarise(N = n_distinct(ID),
"M heart rate in bpm" = round(mean(heart_rate),
digits = 2),
"SD heart rate in bpm" = round(sd(heart_rate),
digits = 2),
"Min heart rate in bpm" = min(heart_rate),
"Max heart rate in bpm" = max(heart_rate)
)
descrip_hr_overall
View(df_demo)
# Mean, SD and range for disruption and confidence factor
rating_table <-
df_rating %>%
filter(!is.na(confidence_factor),
!is.na(disruption_factor),
!ID %in% c("126",
"132",
"236")
) %>%
summarise(N = n_distinct(ID),
"M disruption factor" = round(mean(disruption_factor),
digits = 2),
"SD disruption factor" = round(sd(disruption_factor),
digits = 2),
"Min disruption factor" = min(disruption_factor),
"Max disruption factor" = max(disruption_factor),
"M confidence factor" = round(mean(confidence_factor),
digits = 2),
"SD confidence factor" = round(sd(confidence_factor),
digits = 2),
"Min confidence factor" = min(confidence_factor),
"Max confidence factor" = max(confidence_factor)
)
rating_table
# Mean, SD and range for teaching experience
demo_table <-
df_demo %>%
filter(!ID %in% c("126",
"132",
"236"
)
) %>%
summarise(N = n(),
"M teaching experience" = round(mean(teaching_experience),
digits = 2),
"SD teaching experience" = round(sd(teaching_experience),
digits = 2),
"Min disruption factor" = min(teaching_experience),
"Max disruption factor" = max(teaching_experience),
)
demo_table
knitr::opts_chunk$set(
echo = TRUE,
error = FALSE,
message = FALSE,
warning = FALSE
)
library(needs)
needs(ltm,
xtable,
broom,
ppcor,
jtools,
lm.beta,
janitor,
lubridate,
readxl,
ggthemes,
gridExtra,
imputeTS,
DescTools,
cowplot,
rstatix,
ggpubr,
lme4,
lmerTest,
viridis,
gridExtra,
gridtext,
magrittr,
PerformanceAnalytics,
Hmisc,
corrplot,
tidyverse,
ggplot2,
lavaan,
lm.beta,
psych,
stats)
# disruption & confidence rating
df_rating <-
excel_sheets("data/Coding_SRI.xlsx") %>%
map_df(~read_xlsx("data/Coding_SRI.xlsx",.)) %>% # read in data with two sheets
dplyr::select(ID, # select relevant columns
"disruption_factor", # -99 = subject did not notice event; -100 = experimenter did not asked for event
"confidence_factor",
"event"
) %>%
mutate(disruption_factor = ifelse(disruption_factor < 0,
yes = NA,
no = disruption_factor
),
confidence_factor = ifelse(confidence_factor < 0,
yes = NA,
no = confidence_factor),
event = as_factor(event)
)
# demographic data
df_demo <-
read_excel("./data/data_empschul_labor_lehrperson.xlsx") %>% # read in excel
transmute(ID = LI06_05, # select and rename relevant columns
gender = factor(LI02_01_1,
levels = 1:2,
labels = c("male","female")
),
age = LI03_01, # 1 = male; 2 = female
teaching_experience = LI04_01)
# merge two data frames by ID
df_merge <- merge(df_demo,
df_rating,
by = "ID") %>%
filter(!ID %in% c("126", # exclude cases with no fitbit data (to check see data Heart Rate)
"132",
"236")
)
# rm(list = c("df_demo","df_rating"))
data_path <- "./data/heart_rate_data"
# single bpm values (data frame with only single measurement point)
main_single_hr <-
map(.x = dir(path = data_path,
pattern = ".csv"),
~ read_csv(file.path(data_path, .),
id = "id",
col_types = c("t","n")
) %>%
mutate(time = .$Time - min(.$Time),
time = as.numeric(time),
heart_rate = `Heart Rate`,
ID = id,
time_span = case_when(str_detect(string = id, pattern = "_a") ~ "end",
str_detect(string = id, pattern = "_m") ~ "teaching",
str_detect(string = id, pattern = "_p") ~ "preparation",
str_detect(string = id, pattern = "_s") ~ "post",
str_detect(string = id, pattern = "_i") ~ "interview",
TRUE ~ "overall"
),
ID = str_extract(string = ID,
pattern = "[:digit:]{3}"),
ID = as.numeric(ID)
) %>%
# filter(time <= 600) %>% # filter for 10min intervals
filter(time <= 7200) %>% # filter for 2 hours (maximal duration of study)
dplyr::select(!c("Time","Heart Rate","id"))
) %>%
bind_rows()
# adding z-standardized HR
main_single_hr <-
main_single_hr %>%
dplyr::select("time", "heart_rate", "ID", "time_span") %>%
distinct() %>%
group_by(ID) %>%
dplyr::summarise(mean_heart = mean(heart_rate),
sd_heart = sd(heart_rate)) %>%
ungroup() %>%
right_join(x = .,
y = main_single_hr,
by = "ID") %>%
filter(!(time_span == "teaching" & time > 600)) %>%
mutate(heart_rate_std = (heart_rate - mean_heart)/
sd_heart)
## count for individuals
main_single_hr %>%
filter(time >= 7200) %>%
distinct(ID, .keep_all = TRUE) -> filter_overall
View(main_single_hr)
main %>%
filter(time_span == "preparation") %>%
group_by(ID) %>%
transmute(heart_rate_m = mean(heart_rate_std),
confidence_factor_m = mean(confidence_factor,
na.rm = TRUE),
disruption_factor_m = mean(disruption_factor,
na.rm = TRUE),
teaching_experience = teaching_experience,
gender = gender
) %>%
distinct() %>%
ungroup() %>%
transmute(heart_rate_m = (heart_rate_m - mean(.$heart_rate_m))/sd(.$heart_rate_m),
confidence_factor_m = (confidence_factor_m - mean(.$confidence_factor_m))/sd(.$confidence_factor_m),
disruption_factor_m = (disruption_factor_m - mean(.$disruption_factor_m))/sd(.$disruption_factor_m),
# gender = if_else(gender == "male",
#                   true = 0,
#                   false = 1),
teaching_experience = (teaching_experience - mean(.$teaching_experience))/sd(.$teaching_experience)
) -> cor_pre
cor.test(cor_pre$heart_rate_m, cor_pre$confidence_factor_m)
