---
title             : "Through the eyes of the teacher"
shorttitle        : "Visual attention in teaching and learning processes - QUESTIONNAIRE DATA"

author: 
  - name          : "Mandy Klatt"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Egelstraße 2a 04103 Leipzig"
    email         : "mandy.klatt@uni-leipzig.de"
  - name          : "Dr. Gregor Kachel"
    affiliation   : "1, 2"
  - name          : "Dr. Christin Lotz"
    affiliation   : "1"
  - name          : "Prof. Dr. Anne Deiglmayr"
    affiliation   : "1"
  
affiliation:
  - id            : "1"
    institution   : "Leipzig University"
  - id            : "2"
    institution   : "Max-Planck University for Evolutionary Anthropology"

authornote: |
  The Ethics Advisory Board of Leipzig University has dealt with the research project and has come to the conclusion that there are no objections to the implementation of this research project. The Ethics Advisory Board points out that the scientific and ethical responsibilty for the implementation of the project remains with the project director.

abstract: |
  This document is a supplement to the paper and shows first graphs findings from the pilot study. 
  
keywords          : "Professional Vision, Expert-Novice-Paradigm, Eye-Tracking"
wordcount         : "1949"

bibliography      : ["r-references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf #bookdown::word_document2
---

```{r setup, include = FALSE}

# if a package is not installed on the current machine, it will install it
if(!"devtools" %in% rownames(installed.packages())) install.packages("devtools")
if (!require(tidyverse)) install.packages('tidyverse'); library(tidyverse)
if (!require(papaja)) install.packages("papaja"); library(papaja)
if (!require(psych)) install.packages('psych'); library(psych) # stats
if (!require(moments)) install.packages('moments'); library(moments) # skewness & kurtosis
if (!require(sjPlot)) install.packages('sjPlot'); library(sjPlot) # item analysis of a scale or index

# suppress "summarize" info. 
# if this line is ommitted, each table using the summarize function will be accompanied with a warning from the console
options(dplyr.summarise.inform = FALSE)

r_refs("r-references.bib")

```

```{r analysis-preferences, echo = FALSE}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# State of research

Teaching and classroom management are multidimensional settings in which teachers have to respond immediately to events as they develop [@barnes2004significance]. The different interests and abilities of students must be managed in a way that maximizes the active learning time of students and minimizes disruptions whilst teaching. Learning to develop such classroom management skills and to teach effectively is a complicated and complex process [@wolff2017see]. 

During teaching, teachers must be able to select from a variety of visual and acoustic impressions to focus their attention on the essential and to distinguish between relevant and irrelevant events. This ability is called professional vision and is a key component of teacher expertise and successful teaching [@barth2017professionelle]. Eye tracking technology has become a reliable means to study teachers’ visual focus of attention [@pouta2020student; @bogert2016visualperception; @wolff2017see]

Educational research has repeatedly shown that there are differences between experienced and novice teachers in terms of perception and behavioral competencies [@barth2017professionelle; @bogert2016visualperception; @wolff2017see]. For example, experts direct their attention more often and more evenly to all students, whereas novices only direct their attention to some students. The frequency and duration of fixations as eye movement are decisive [@stuermer2017eye]. Mobile eye-tracking technology has also shown that experienced teachers distribute their focus more efficiently to solve tasks [@jarodzka2010eyes]. Furthermore, in contrast to novices, experts are able to focus their attention on the entire class and guide the class while giving feedback to individual students and answering questions [@cortina2015low].



## Research questions

The aim of the pilot study was to investigate whether there are differences in how expert and novice teachers manage scripted classroom disruptions. The disruptions were experimentally varied using a previously written script. Thus, our aim was to find out whether differences in the allocation of attention between expertise groups can be detected in this controlled context.

In order to answer this question, the hypothesis was formulated that teachers with more professional experience not only notice more disruptions but also notice them faster. In the hypothesis, therefore, it is necessary to check what has already been shown in the research literature: In complex teaching situations, experts have a more structured and elaborate professional knowledge than novices in order to perceive and interpret relevant events and to act appropriately [@berliner2001learning; @lachner2016makes].


# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->


## Participants

For the sample recruitment of the subjects (N = 8, experts n = 2, novices n = 6), schools in the city of Leipzig in Saxony were contacted. The institutions as well as the subjects were informed in detail about the aim and intention of the study in advance. Participation in the study was voluntary and only took place after written consent has been given.

```{r demographicspilottable, echo = FALSE}

# prepare data (selected from questionnaire data)
quest.raw.data<-read.table("./data/short_questionnaire_data_2701211.txt", dec=",", sep="\t", header=T) 

# knock out NAs
quest.raw.data <- quest.raw.data  %>% filter(
  personID != "NA")

# create a basic table (tibble) using tidyverse functions
demo.quest.table <- quest.raw.data %>%
  filter(what == "head") %>%
  group_by(group) %>%
  summarise(N=n(),
            "Male" = sum(gender),
            "M age" = round(mean(age), 2),
            "Min age" = min(age),
            "Max age" = max(age),
            "SD age" = round(sd(age), 2),
            "M exp." = round(mean(experience), 2),
            "Min exp." = min(experience),
            "Max exp." = max(experience),
            "SD exp." = round(sd(experience), 2),
           )

# format and insert table in manuscript
apa_table(
  demo.quest.table,
  caption = "Demographic Information and Teaching Experience",
  # note = "Write Note here", 
  escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
  placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
  font_size = "small" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
  )

```

The selection of the subjects was based on extreme groups, whereby professional experience is the crucial criterion for the selection of experts or novices. Novices were recruited as teachers who have been working in the teaching profession for no more than 3 years, whereas experts were considered to have professional experience of 10 years or more [@messner2000berufliche].

## Procedure/ Data collection

### Set up

For this study, scripted mini-lessons with n = 2 experts and n = 6 novices were recorded in the mobile Lab of the Empirical School and Classroom Research at the University of Leipzig. The subjects were divided into groups of four, so the study was conducted on two different sessions. All participants were asked to hold a 10-minute lesson. The duration of each appointment was approximately 2h: per group 10min briefing, 4 x 10min mini-lessons, 10min technical preparation and follow-up and 4x 10min transition points between the lessons and answering questionnaires.

One person from the group of 4 acted as a teacher, the other three subjects acted as the class. The subjects, who represented the class, were given behavioral instructions in a pre-written script to simulate typical events and disruptions in the classroom (e.g. putting their heads on the table, chatting, looking at their mobile phones, etc.).

The lesson disruptions were displayed as instructions during the lesson for all "students" but not the teacher. In order to avoid learning effects, the disruptions in each lesson were distributed pseudo-randomly over the short teaching phase. In addition, the order of the data collection was taken into account in the analyses and variance caused by order was controlled.

(ref:datacollection-caption) Example for set up during a mini-lesson

```{r datacollection, fig.cap = "(ref:datacollection-caption)", fig.align = "center", echo = FALSE}

knitr::include_graphics("./pictures/datacollection.png", dpi = 108)

# # How to insert images in papaja
# - pictures must be png
# - I created a pictures folder in the main folder, just dumb pictures there
# - you just need to hand the name and path of the picture to the knitr::: function (see above)
# - the dpi argument is for adjusting the size on the page in pixels

# in order to write the caption, you have to use the line just above the code chunk (ref:YOURTEXT-caption) and then just write behind it
# the code chunk then opens and after "r" it needs to provide a name for the code chunk, must be unique in the document
# the fig.cap = then calls the text from the line just above
# fig.align allows to position the pic on page, center ist probablby best
# echo = false ensures that the code chunk does not occur in the pdf
# Now, go and try putting your own images in the paper 
#
# TIP = check line 46 in this manuscript. THis section ets global properties for how graphs are put in the paper. 
#         if floatsintext      : yes  --> pics, graphs, tables will be put where the code chunk is
#         if floatsintext      : no   --> pics, graphs, tables will be put at the end as is required by some journals
# TIP: check the folder "papaja_example&tutorial" that I put in this folder for paper1
# Tip: make a bookmark of this and skim through it: http://frederikaust.com/papaja_man/

```

### Questionnaire data

After each mini-lesson, the students answered items on the teaching quality using a validated questionnaire [@helmke2014unterrichtsdiagnostik] and scales on the teacher's presence behavior (students n = 24). In addition, the teacher was asked to give a self-assessment on his/her classroom management by completing the questionnaire after each mini-lesson (teachers n = 8).

## Coding/ Data preparation/ Reliability 

### Questionnaire Data

The evaluation after each mini-lesson was conducted using paper questionnaires. Time needed to complete the questionnaire was about 5 minutes. 
The scales on the quality of teaching are a validated questionnaire [@helmke2014unterrichtsdiagnostik]. Whereas the scales on the teacher's presence behavior were derived from the research literature [@brophy1986classroom; @kiel2013trainingsbuch; @kounin2006techniken; @marzano2007art; @nolting2012storungen] and were used in the pilot for the first time. The questionnaire is 4-point Likert scale (1 = Strongly Disagree; 2 = Disagree; 3 = Agree; 4 = Strongly Agree). Data was obtained from N = 32 subjects (students n = 24, teachers n = 8). 

The following scales were assessed:

(1) Classroom management
(2) Positive climate and motivation
(3) Clarity and structuredness
(4) Activation and support
(5) Presence: posture/gaze
(6) Presence: voice
(7) Presence: verbal and non-verbal intervention
(8) Natural behaviour

Table \@ref(tab:table-all-scales-self-assessment) provides an overview over the mean, the standard deviation, the range, Cronbach's Alpha and the Skewness & Kurtosis of all scales for the teachers' self-assessment.

```{r table-all-scales-self-assessment, echo=FALSE, message=FALSE, warning=FALSE}

# prepare data (selected from questionnaire data) - only equal items and without observer
quest.raw.data<-read.table("./data/short_questionnaire_data_150221.txt", dec=",", sep="\t", header=T) 

# knock out NAs and duration of speaking time
quest.raw.data <- quest.raw.data  %>% filter(
  personID != "NA",
  itemID != "8",
  perspective == "self-assessment")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
quest.raw.data <- quest.raw.data %>%  mutate(value = as.numeric(value))

##############################################

# calculate Cronbach's Alpha for each scale
# activation & support
self.as.wide <- quest.raw.data %>%
                          filter (scale == "Activation and support") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)
self.alpha.as <- alpha(self.as.wide[,-1])

#clarity & structuredness
self.cs.wide <- quest.raw.data %>%
                          filter (scale == "Clarity and structuredness") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.cs <- alpha(self.cs.wide[,-1])

#classroom management
self.cm.wide <- quest.raw.data %>%
                          filter (scale == "Classroom management") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.cm <- alpha(self.cm.wide[,-1])

#natural behaviour
self.nb.wide <- quest.raw.data %>%
                          filter (scale == "Natural behaviour") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.nb <- alpha(self.nb.wide[,-1])

#positive climate and motivation
self.pcm.wide <- quest.raw.data %>%
                          filter (scale == "Positive climate and motivation") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.pcm <- alpha(self.pcm.wide[,-1])

#presence: posture & gaze
self.ppg.wide <- quest.raw.data %>%
                          filter (scale == "Presence: posture/gaze") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.ppg <- alpha(self.ppg.wide[,-1])

#presence: voice
self.pv.wide <- quest.raw.data %>%
                          filter (scale == "Presence: voice") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.pv <- alpha(self.pv.wide[,-1])

#presence: verbal/non-verbal intervention
self.pvni.wide <- quest.raw.data %>%
                          filter (scale == "Presence: verbal and non-verbal intervention") %>%  
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.pvni <- alpha(self.pvni.wide[,-1])
	
#Presence without subscales
self.p.wide <- quest.raw.data %>%
                          filter(str_detect(scale,
                                        paste(c(
                                        "Presence: voice", 
                                        "Presence: verbal and non-verbal intervention", 
                                        "Presence: posture/gaze"),
                                         collapse = '|'))) %>% 
                          dplyr::select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

self.alpha.p <- alpha(self.p.wide[,-1])

##############################################

# item analysis of a scale or index using the tab_itemscale() function of the sjPlot package

# activation & support
tab_itemscale(self.as.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

# classroom management
tab_itemscale(self.cm.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

# clarity & structuredness
tab_itemscale(self.cs.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

# natural behaviour
tab_itemscale(self.nb.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

# postive clima and motivation
tab_itemscale(self.pcm.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

# presence without subscales
tab_itemscale(self.p.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

# presence: posture & gaze
tab_itemscale(self.ppg.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# presence: voice
tab_itemscale(self.pv.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# presence: verbal/non-verbal intervention
tab_itemscale(self.pvni.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)

##############################################

# add alphas to excel table 
# read in new data 
quest.raw.data.alpha <- read.table("./data/short_questionnaire_data_260221_alpha.txt", dec=",", sep="\t", header=T) 

# value sometimes contained text before filtering, we have to convert the numbers to numeric
quest.raw.data.alpha <- quest.raw.data.alpha %>%  mutate(alpha = as.numeric(alpha))

##############################################

# #####correlation between all presences' items
# SELF-ASSESSMENT
# install.packages("Hmisc")
# library("Hmisc")

# function cr() to format the correlation matrix
res1.self<-cor(self.p.wide[,-1])


# Visualization correlation matrix
# Use corrplot() function: Draw a correlogram

# # install.packages("corrplot")
# library("corrplot")
# 
# # Insignificant correlation are crossed
# corrplot(res1.self$r, type="upper", order="hclust",
#          p.mat = res1.self$P, sig.level = 0.01, insig = "blank")
# # Insignificant correlations are leaved blank
# corrplot(res1.self$r, type="upper", order="hclust",
#          p.mat = res1.self$P, sig.level = 0.01, insig = "blank")

###############################################

# create a basic table (tibble) using tidyverse functions for teachers' self assessment 
# Change Number of Digits in Global R Options to reduce the number of digits after the decimal point to two
options(digits = 2)              

teacher.scale.quest.table <- quest.raw.data.alpha %>% # select data
  filter(perspective == "self-assessment")%>%
  group_by(scale) %>%
  summarise("N items" = n_distinct(shortID),
            "M" = round(mean(value), 2),
            "SD" = round(sd(value), 2),
            "Min" = min(value),
            "Max" = max(value),
            "Skewness" = skewness(value),
            "Kurtosis" = kurtosis(value),
            "Cronbach's α" = mean(alpha))

# format and insert table in manuscript
apa_table(
  teacher.scale.quest.table,
  caption = "Scale analysis for teachers' self-assessment",
  # note = "Write Note here", 
  escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
  placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
  font_size = "tiny" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)

```

Table \@ref(tab:table-all-scales-students) provides an overview over the mean, the standard deviation, the range, Cronbach's Alpha and the Skewness & Kurtosis of all scales for the students' perception of the teacher's behaviour in class.

```{r table-all-scales-students, echo=FALSE, message=FALSE, warning=FALSE}

# prepare data (selected from questionnaire data) - only equal items and without observer
quest.raw.data<-read.table("./data/short_questionnaire_data_150221.txt", dec=",", sep="\t", header=T) 

# knock out NAs and duration of speaking time
quest.raw.data <- quest.raw.data  %>% filter(
  personID != "NA",
  itemID != "8",
  perspective == "student")
view(quest.raw.data)

# value sometimes contained text before filtering, we have to convert the numbers to numeric
quest.raw.data <- quest.raw.data %>%  mutate(value = as.numeric(value))

###############################################

# calculate Cronbach's Alpha for each scale of students' peception

# activation & support
stud.as.wide <- quest.raw.data %>%
                          filter (scale == "Activation and support") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)
stud.alpha.as <- alpha(stud.as.wide[,-1])

#clarity & structuredness
stud.cs.wide <- quest.raw.data %>%
                          filter (scale == "Clarity and structuredness") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.cs <- alpha(stud.cs.wide[,-1])

#classroom management
stud.cm.wide <- quest.raw.data %>%
                          filter (scale == "Classroom management") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.cm <- alpha(stud.cm.wide[,-1])

#natural behaviour
stud.nb.wide <- quest.raw.data %>%
                          filter (scale == "Natural behaviour") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.nb <- alpha(stud.nb.wide[,-1])

#positive climate and motivation
stud.pcm.wide <- quest.raw.data %>%
                          filter (scale == "Positive climate and motivation") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.pcm <- alpha(stud.pcm.wide[,-1])

#presence: posture & gaze
stud.ppg.wide <- quest.raw.data %>%
                          filter (scale == "Presence: posture/gaze") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.ppg <- alpha(stud.ppg.wide[,-1])

#presence: verbal and non-verbal intervention
stud.pvni.wide <- quest.raw.data %>%
                          filter (scale == "Presence: verbal and non-verbal intervention") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.pvni <- alpha(stud.pvni.wide[,-1])
	
#presence: voice
stud.pv.wide <- quest.raw.data %>%
                          filter (scale == "Presence: voice") %>%  
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.pv <- alpha(stud.pv.wide[,-1])

#Presence without subscales
stud.p.wide <- quest.raw.data %>%
                          filter(str_detect(scale,
                                        paste(c(
                                        "Presence: voice", 
                                        "Presence: verbal and non-verbal intervention", 
                                        "Presence: posture/gaze"),
                                         collapse = '|'))) %>% 
                          select(shortID, value) %>%
                          group_by(shortID) %>%
                          mutate(id=row_number()) %>%
                          spread(shortID, value)

stud.alpha.p <- alpha(stud.p.wide[,-1])

# ###############################################

# item analysis of a scale or index using the tab_itemscale() function of the sjPlot package

# # activation & support
# tab_itemscale(stud.as.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# 
# # classroom management
# tab_itemscale(stud.cm.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# 
# # clarity & structuredness
# tab_itemscale(stud.cs.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# 
# # natural behaviour
# tab_itemscale(stud.nb.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# 
# # positive clima and motivation
# tab_itemscale(stud.pcm.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# 
# # presence without subscales
# tab_itemscale(stud.p.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# 
# # presence: posture & gaze
# tab_itemscale(stud.ppg.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# # presence: voice
# tab_itemscale(stud.pv.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)
# # presence: verbal/non-verbal intervention
# tab_itemscale(stud.pvni.wide[,-1], show.shapiro = TRUE, show.kurtosis = TRUE)


##############################################
# #####correlation between all presences' items
# SELF-ASSESSMENT
# install.packages("Hmisc")
library("Hmisc")

# # function to format the correlation matrix
# flattenCorrMatrix <- function(cormat, pmat) {
#   ut <- upper.tri(cormat)
#   data.frame(
#     row = rownames(cormat)[row(cormat)[ut]],
#     column = rownames(cormat)[col(cormat)[ut]],
#     cor  =(cormat)[ut],
#     p = pmat[ut]
#     )
# }
# 
# res1.stud<-cor(stud.p.wide[,-1])

# res1.stud<-rcorr(as.matrix(stud.p.wide[,-1]))
# 
# flattenCorrMatrix(res1.stud$r, res1.stud$P)
# 
# res2.stud<-flattenCorrMatrix(res1.stud$r, res1.stud$P)

# Visualization correlation matrix
# Use corrplot() function: Draw a correlogram

# install.packages("corrplot")
library("corrplot")

# # Insignificant correlation are crossed
# corrplot(res1.stud$r, type="upper", order="hclust",
#          p.mat = res1.stud$P, sig.level = 0.01, insig = "blank")
# # Insignificant correlations are leaved blank
# corrplot(res1.stud$r, type="upper", order="hclust",
#          p.mat = res1.stud$P, sig.level = 0.01, insig = "blank")

##############################################

# add alphas to excel table 
# read in new data 
quest.raw.data.alpha <- read.table("./data/short_questionnaire_data_260221_alpha.txt", dec=",", sep="\t", header=T) 

# value sometimes contained text before filtering, we have to convert the numbers to numeric
quest.raw.data.alpha <- quest.raw.data.alpha %>%  mutate(alpha = as.numeric(alpha))

##############################################

# create a basic table (tibble) using tidyverse functions for teacher self assessment 
student.scale.quest.table <- quest.raw.data.alpha %>% # select data
  filter(perspective == "student")%>%
  group_by(scale) %>%
  summarise("N items" = n_distinct(shortID),
            "M" = round(mean(value), 2),
            "SD" = round(sd(value), 2),
            "Min" = min(value),
            "Max" = max(value),
            "Skewness" = skewness(value),
            "Kurtosis" = kurtosis(value),
            "Cronbach's α" = mean(alpha))

# format and insert table in manuscript
apa_table(
  student.scale.quest.table,
  caption = "Scale analysis for students' perspective",
  # note = "Write Note here", 
  escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
  placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
  font_size = "tiny" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)

```
\newpage
The individual items of a scale are further represented in graphs.

(1) Classroom management
```{r Line Plots Classroom Management, echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE, fig.cap="Items for Classroom Management"}

### classroom management 

# prepare data (selected from questionnaire data) - only equal items and without observer
quest.raw.data<-read.table("./data/short_questionnaire_data_150221.txt", dec=",", sep="\t", header=T) 

# filter by parameter variable, i.e. create a subset for classroom management without perspective "observer"
cm.data <- quest.raw.data %>% filter(scale == "Classroom management")
                                                 
view(cm.data)

# value sometimes contained text before filtering, we have to convert the numbers to numeric
cm.data <- cm.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
cm.plot.sd <- cm.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
cm.plot<-ggplot(data = cm.plot.sd,
                  aes(x = shortID, y = mean,
                      group = perspective, colour = perspective)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = cm.data, y = "value", x = NULL,
       title="Classroom management" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 6))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
cm.plot

```
\newpage
(2) Positive climate and motivation
```{r Positive climate and motivation line plots,  fig.width=6, fig.height = 7, message = FALSE, warning = FALSE , echo=FALSE, fig.cap = "Items for Positive climate and motivation"}

### Positive climate and motivation 

# filter by parameter variable, i.e. create a subset for Positive climate and motivation
pcm.data <- quest.raw.data %>% filter(scale == "Positive climate and motivation")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
pcm.data <- pcm.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
pcm.plot.sd <- pcm.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
pcm.plot<-ggplot(data = pcm.plot.sd,
                  aes(x = shortID, y = mean,
                      group = group, colour = group)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = pcm.data, y = "value", x = NULL,
       title="Positive climate and motivation" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 5))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
pcm.plot

```
\newpage
(3) Clarity and structuredness
```{r Clarity and structuredness line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE, fig.cap = "Items for Clarity and structuredness"}

### Clarity and structuredness 

# filter by parameter variable, i.e. create a subset for Clarity and structuredness
cs.data <- quest.raw.data %>% filter(scale == "Clarity and structuredness")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
cs.data <- cs.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
cs.plot.sd <- cs.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
cs.plot<-ggplot(data = cs.plot.sd,
                  aes(x = shortID, y = mean,
                      group = group, colour = group)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = cs.data, y = "value", x = NULL,
       title="Clarity and structuredness" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 6))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
cs.plot

```
\newpage
(4) Activation and support
```{r Activation and support line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE, fig.cap = "Items for Activation and support"}
### Activation and support 

# prepare data (selected from questionnaire data) - only equal items and without observer
quest.raw.data<-read.table("./data/short_questionnaire_data_150221.txt", dec=",", sep="\t", header=T) 

# filter by parameter variable, i.e. create a subset for Activation and support
as.data <- quest.raw.data %>% filter(scale == "Activation and support")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
as.data <- as.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
as.plot.sd <- as.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
as.plot<-ggplot(data = as.plot.sd,
                  aes(x = shortID, y = mean,
                      group = group, colour = group)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = as.data, y = "value", x = NULL,
       title="Activation and support" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 6))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
as.plot

```
\newpage

(5) Presence: posture and gaze 
```{r Presence posture and gaze line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE, fig.cap = "Items for Presence posture and gaze"}

# ### Presence: posture/gaze
#
# filter by parameter variable, i.e. create a subset for Presence: posture/gaze
ppg.data <- quest.raw.data %>% filter(scale == "Presence: posture/gaze")
#
# value sometimes contained text before filtering, we have to convert the numbers to numeric
ppg.data <- ppg.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
ppg.plot.sd <- ppg.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
ppg.plot<-ggplot(data = ppg.plot.sd,
                        aes(x = shortID, y = mean,
                        group = group, colour = group)) +
    geom_line()+
    geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
    theme_light() +
     ylim(1,4)+
     facet_grid(~perspective)+
     labs(data = ppg.data, y = "value", x = NULL,
         title="Presence: posture/gaze" ,
         subtitle=NULL)+
    theme(legend.position="bottom",
          panel.spacing.x = ,
          plot.title = element_text(hjust = 0.5),
          axis.text.y = element_text(size = 6))+
    scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
   coord_flip()
 ppg.plot

```

\newpage

(6) Presence: voice
```{r Presence voice line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE, fig.cap = "Items for Presence voice"}

### Presence: voice
# filter by parameter variable, i.e. create a subset for Presence: voice
pv.data <- quest.raw.data %>% filter(scale == "Presence: voice")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
pv.data <- pv.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
pv.plot.sd <- pv.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
pv.plot<-ggplot(data = pv.plot.sd,
                  aes(x = shortID, y = mean,
                      group = group, colour = group)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = pv.data, y = "value", x = NULL,
       title="Presence: voice" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 6))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
pv.plot

```
\newpage

(7) Presence: verbal and non-verbal intervention

```{r Presence verbal and non-verbal intervention line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE}

### Presence: verbal and non-verbal intervention
# filter by parameter variable, i.e. create a subset for Presence: verbal and non-verbal intervention
pvni.data <- quest.raw.data %>% filter(scale == "Presence: verbal and non-verbal intervention")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
pvni.data <- pvni.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
pvni.plot.sd <- pvni.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
pvni.plot<-ggplot(data = pvni.plot.sd,
                  aes(x = shortID, y = mean,
                      group = group, colour = group)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = pvni.data, y = "value", x = NULL,
       title="Presence: verbal and non-verbal intervention" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 6))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
pvni.plot

```
\newpage
(8) Natural behaviour
```{r Natural behaviour line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE, fig.cap = "Items for Natural Behaviour"}

### Natural behaviour 
# filter by parameter variable, i.e. create a subset for Natural behaviour
nb.data <- quest.raw.data %>% filter(scale == "Natural behaviour")

# value sometimes contained text before filtering, we have to convert the numbers to numeric
nb.data <- nb.data %>%  mutate(value = as.numeric(as.character(factor(value))))

# to create error bars, we need to summarize the data in a separate data frame
nb.plot.sd <- nb.data %>%
  group_by(group, shortID, .drop=TRUE) %>%
  summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )

# long plot
nb.plot<-ggplot(data = nb.plot.sd,
                  aes(x = shortID, y = mean,
                      group = group, colour = group)) +
  geom_line()+
  geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
  theme_light() +
  ylim(1,4)+
  facet_grid(~perspective)+
  labs(data = nb.data, y = "value", x = NULL,
       title="Natural behaviour" ,
       subtitle=NULL)+
  theme(legend.position="bottom",
        panel.spacing.x = ,
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 6))+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
  coord_flip()
nb.plot

```
\newpage
In addition, we plotted all scales. Graph provides boxplots and individual data for experts and novices.
```{r boxplot scales, fig.width=6, fig.height = 8, echo = FALSE, fig.cap = "Boxplots and individual data for experts and novices"}

# prepare data (selected from questionnaire data) - only equal items and without observer
quest.raw.data<-read.table("./data/short_questionnaire_data_150221.txt", dec=",", sep="\t", header=T) 

quest.plot <- quest.raw.data %>%
  ggplot(aes(x=scale, y=value, fill=scale)) +
    geom_boxplot() +
    scale_x_discrete(guide = guide_axis(angle = 70)) +
    geom_jitter(color="black", size=0.4, alpha=0.5) +
    theme_light() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11)) +
    facet_grid(~perspective)+
    ggtitle("Boxplot with individual points for all scales") +
    xlab("")
quest.plot

```
